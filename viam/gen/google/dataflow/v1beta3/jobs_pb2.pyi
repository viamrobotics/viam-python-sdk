"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import google.dataflow.v1beta3.environment_pb2
import google.protobuf.descriptor
import google.protobuf.duration_pb2
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import google.protobuf.struct_pb2
import google.protobuf.timestamp_pb2
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor = ...

class _KindType:
    ValueType = typing.NewType('ValueType', builtins.int)
    V: typing_extensions.TypeAlias = ValueType
class _KindTypeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_KindType.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
    UNKNOWN_KIND: KindType.ValueType = ...  # 0
    """Unrecognized transform type."""

    PAR_DO_KIND: KindType.ValueType = ...  # 1
    """ParDo transform."""

    GROUP_BY_KEY_KIND: KindType.ValueType = ...  # 2
    """Group By Key transform."""

    FLATTEN_KIND: KindType.ValueType = ...  # 3
    """Flatten transform."""

    READ_KIND: KindType.ValueType = ...  # 4
    """Read transform."""

    WRITE_KIND: KindType.ValueType = ...  # 5
    """Write transform."""

    CONSTANT_KIND: KindType.ValueType = ...  # 6
    """Constructs from a constant value, such as with Create.of."""

    SINGLETON_KIND: KindType.ValueType = ...  # 7
    """Creates a Singleton view of a collection."""

    SHUFFLE_KIND: KindType.ValueType = ...  # 8
    """Opening or closing a shuffle session, often as part of a GroupByKey."""

class KindType(_KindType, metaclass=_KindTypeEnumTypeWrapper):
    """Type of transform or stage operation."""
    pass

UNKNOWN_KIND: KindType.ValueType = ...  # 0
"""Unrecognized transform type."""

PAR_DO_KIND: KindType.ValueType = ...  # 1
"""ParDo transform."""

GROUP_BY_KEY_KIND: KindType.ValueType = ...  # 2
"""Group By Key transform."""

FLATTEN_KIND: KindType.ValueType = ...  # 3
"""Flatten transform."""

READ_KIND: KindType.ValueType = ...  # 4
"""Read transform."""

WRITE_KIND: KindType.ValueType = ...  # 5
"""Write transform."""

CONSTANT_KIND: KindType.ValueType = ...  # 6
"""Constructs from a constant value, such as with Create.of."""

SINGLETON_KIND: KindType.ValueType = ...  # 7
"""Creates a Singleton view of a collection."""

SHUFFLE_KIND: KindType.ValueType = ...  # 8
"""Opening or closing a shuffle session, often as part of a GroupByKey."""

global___KindType = KindType


class _JobState:
    ValueType = typing.NewType('ValueType', builtins.int)
    V: typing_extensions.TypeAlias = ValueType
class _JobStateEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_JobState.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
    JOB_STATE_UNKNOWN: JobState.ValueType = ...  # 0
    """The job's run state isn't specified."""

    JOB_STATE_STOPPED: JobState.ValueType = ...  # 1
    """`JOB_STATE_STOPPED` indicates that the job has not
    yet started to run.
    """

    JOB_STATE_RUNNING: JobState.ValueType = ...  # 2
    """`JOB_STATE_RUNNING` indicates that the job is currently running."""

    JOB_STATE_DONE: JobState.ValueType = ...  # 3
    """`JOB_STATE_DONE` indicates that the job has successfully completed.
    This is a terminal job state.  This state may be set by the Cloud Dataflow
    service, as a transition from `JOB_STATE_RUNNING`. It may also be set via a
    Cloud Dataflow `UpdateJob` call, if the job has not yet reached a terminal
    state.
    """

    JOB_STATE_FAILED: JobState.ValueType = ...  # 4
    """`JOB_STATE_FAILED` indicates that the job has failed.  This is a
    terminal job state.  This state may only be set by the Cloud Dataflow
    service, and only as a transition from `JOB_STATE_RUNNING`.
    """

    JOB_STATE_CANCELLED: JobState.ValueType = ...  # 5
    """`JOB_STATE_CANCELLED` indicates that the job has been explicitly
    cancelled. This is a terminal job state. This state may only be
    set via a Cloud Dataflow `UpdateJob` call, and only if the job has not
    yet reached another terminal state.
    """

    JOB_STATE_UPDATED: JobState.ValueType = ...  # 6
    """`JOB_STATE_UPDATED` indicates that the job was successfully updated,
    meaning that this job was stopped and another job was started, inheriting
    state from this one. This is a terminal job state. This state may only be
    set by the Cloud Dataflow service, and only as a transition from
    `JOB_STATE_RUNNING`.
    """

    JOB_STATE_DRAINING: JobState.ValueType = ...  # 7
    """`JOB_STATE_DRAINING` indicates that the job is in the process of draining.
    A draining job has stopped pulling from its input sources and is processing
    any data that remains in-flight. This state may be set via a Cloud Dataflow
    `UpdateJob` call, but only as a transition from `JOB_STATE_RUNNING`. Jobs
    that are draining may only transition to `JOB_STATE_DRAINED`,
    `JOB_STATE_CANCELLED`, or `JOB_STATE_FAILED`.
    """

    JOB_STATE_DRAINED: JobState.ValueType = ...  # 8
    """`JOB_STATE_DRAINED` indicates that the job has been drained.
    A drained job terminated by stopping pulling from its input sources and
    processing any data that remained in-flight when draining was requested.
    This state is a terminal state, may only be set by the Cloud Dataflow
    service, and only as a transition from `JOB_STATE_DRAINING`.
    """

    JOB_STATE_PENDING: JobState.ValueType = ...  # 9
    """`JOB_STATE_PENDING` indicates that the job has been created but is not yet
    running.  Jobs that are pending may only transition to `JOB_STATE_RUNNING`,
    or `JOB_STATE_FAILED`.
    """

    JOB_STATE_CANCELLING: JobState.ValueType = ...  # 10
    """`JOB_STATE_CANCELLING` indicates that the job has been explicitly cancelled
    and is in the process of stopping.  Jobs that are cancelling may only
    transition to `JOB_STATE_CANCELLED` or `JOB_STATE_FAILED`.
    """

    JOB_STATE_QUEUED: JobState.ValueType = ...  # 11
    """`JOB_STATE_QUEUED` indicates that the job has been created but is being
    delayed until launch. Jobs that are queued may only transition to
    `JOB_STATE_PENDING` or `JOB_STATE_CANCELLED`.
    """

    JOB_STATE_RESOURCE_CLEANING_UP: JobState.ValueType = ...  # 12
    """`JOB_STATE_RESOURCE_CLEANING_UP` indicates that the batch job's associated
    resources are currently being cleaned up after a successful run.
    Currently, this is an opt-in feature, please reach out to Cloud support
    team if you are interested.
    """

class JobState(_JobState, metaclass=_JobStateEnumTypeWrapper):
    """Describes the overall state of a [google.dataflow.v1beta3.Job][google.dataflow.v1beta3.Job]."""
    pass

JOB_STATE_UNKNOWN: JobState.ValueType = ...  # 0
"""The job's run state isn't specified."""

JOB_STATE_STOPPED: JobState.ValueType = ...  # 1
"""`JOB_STATE_STOPPED` indicates that the job has not
yet started to run.
"""

JOB_STATE_RUNNING: JobState.ValueType = ...  # 2
"""`JOB_STATE_RUNNING` indicates that the job is currently running."""

JOB_STATE_DONE: JobState.ValueType = ...  # 3
"""`JOB_STATE_DONE` indicates that the job has successfully completed.
This is a terminal job state.  This state may be set by the Cloud Dataflow
service, as a transition from `JOB_STATE_RUNNING`. It may also be set via a
Cloud Dataflow `UpdateJob` call, if the job has not yet reached a terminal
state.
"""

JOB_STATE_FAILED: JobState.ValueType = ...  # 4
"""`JOB_STATE_FAILED` indicates that the job has failed.  This is a
terminal job state.  This state may only be set by the Cloud Dataflow
service, and only as a transition from `JOB_STATE_RUNNING`.
"""

JOB_STATE_CANCELLED: JobState.ValueType = ...  # 5
"""`JOB_STATE_CANCELLED` indicates that the job has been explicitly
cancelled. This is a terminal job state. This state may only be
set via a Cloud Dataflow `UpdateJob` call, and only if the job has not
yet reached another terminal state.
"""

JOB_STATE_UPDATED: JobState.ValueType = ...  # 6
"""`JOB_STATE_UPDATED` indicates that the job was successfully updated,
meaning that this job was stopped and another job was started, inheriting
state from this one. This is a terminal job state. This state may only be
set by the Cloud Dataflow service, and only as a transition from
`JOB_STATE_RUNNING`.
"""

JOB_STATE_DRAINING: JobState.ValueType = ...  # 7
"""`JOB_STATE_DRAINING` indicates that the job is in the process of draining.
A draining job has stopped pulling from its input sources and is processing
any data that remains in-flight. This state may be set via a Cloud Dataflow
`UpdateJob` call, but only as a transition from `JOB_STATE_RUNNING`. Jobs
that are draining may only transition to `JOB_STATE_DRAINED`,
`JOB_STATE_CANCELLED`, or `JOB_STATE_FAILED`.
"""

JOB_STATE_DRAINED: JobState.ValueType = ...  # 8
"""`JOB_STATE_DRAINED` indicates that the job has been drained.
A drained job terminated by stopping pulling from its input sources and
processing any data that remained in-flight when draining was requested.
This state is a terminal state, may only be set by the Cloud Dataflow
service, and only as a transition from `JOB_STATE_DRAINING`.
"""

JOB_STATE_PENDING: JobState.ValueType = ...  # 9
"""`JOB_STATE_PENDING` indicates that the job has been created but is not yet
running.  Jobs that are pending may only transition to `JOB_STATE_RUNNING`,
or `JOB_STATE_FAILED`.
"""

JOB_STATE_CANCELLING: JobState.ValueType = ...  # 10
"""`JOB_STATE_CANCELLING` indicates that the job has been explicitly cancelled
and is in the process of stopping.  Jobs that are cancelling may only
transition to `JOB_STATE_CANCELLED` or `JOB_STATE_FAILED`.
"""

JOB_STATE_QUEUED: JobState.ValueType = ...  # 11
"""`JOB_STATE_QUEUED` indicates that the job has been created but is being
delayed until launch. Jobs that are queued may only transition to
`JOB_STATE_PENDING` or `JOB_STATE_CANCELLED`.
"""

JOB_STATE_RESOURCE_CLEANING_UP: JobState.ValueType = ...  # 12
"""`JOB_STATE_RESOURCE_CLEANING_UP` indicates that the batch job's associated
resources are currently being cleaned up after a successful run.
Currently, this is an opt-in feature, please reach out to Cloud support
team if you are interested.
"""

global___JobState = JobState


class _JobView:
    ValueType = typing.NewType('ValueType', builtins.int)
    V: typing_extensions.TypeAlias = ValueType
class _JobViewEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_JobView.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
    JOB_VIEW_UNKNOWN: JobView.ValueType = ...  # 0
    """The job view to return isn't specified, or is unknown.
    Responses will contain at least the `JOB_VIEW_SUMMARY` information,
    and may contain additional information.
    """

    JOB_VIEW_SUMMARY: JobView.ValueType = ...  # 1
    """Request summary information only:
    Project ID, Job ID, job name, job type, job status, start/end time,
    and Cloud SDK version details.
    """

    JOB_VIEW_ALL: JobView.ValueType = ...  # 2
    """Request all information available for this job."""

    JOB_VIEW_DESCRIPTION: JobView.ValueType = ...  # 3
    """Request summary info and limited job description data for steps, labels and
    environment.
    """

class JobView(_JobView, metaclass=_JobViewEnumTypeWrapper):
    """Selector for how much information is returned in Job responses."""
    pass

JOB_VIEW_UNKNOWN: JobView.ValueType = ...  # 0
"""The job view to return isn't specified, or is unknown.
Responses will contain at least the `JOB_VIEW_SUMMARY` information,
and may contain additional information.
"""

JOB_VIEW_SUMMARY: JobView.ValueType = ...  # 1
"""Request summary information only:
Project ID, Job ID, job name, job type, job status, start/end time,
and Cloud SDK version details.
"""

JOB_VIEW_ALL: JobView.ValueType = ...  # 2
"""Request all information available for this job."""

JOB_VIEW_DESCRIPTION: JobView.ValueType = ...  # 3
"""Request summary info and limited job description data for steps, labels and
environment.
"""

global___JobView = JobView


class Job(google.protobuf.message.Message):
    """Defines a job to be run by the Cloud Dataflow service.
    nextID: 26
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class TransformNameMappingEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: typing.Text = ...
        value: typing.Text = ...
        def __init__(self,
            *,
            key : typing.Text = ...,
            value : typing.Text = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

    class LabelsEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: typing.Text = ...
        value: typing.Text = ...
        def __init__(self,
            *,
            key : typing.Text = ...,
            value : typing.Text = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

    ID_FIELD_NUMBER: builtins.int
    PROJECT_ID_FIELD_NUMBER: builtins.int
    NAME_FIELD_NUMBER: builtins.int
    TYPE_FIELD_NUMBER: builtins.int
    ENVIRONMENT_FIELD_NUMBER: builtins.int
    STEPS_FIELD_NUMBER: builtins.int
    STEPS_LOCATION_FIELD_NUMBER: builtins.int
    CURRENT_STATE_FIELD_NUMBER: builtins.int
    CURRENT_STATE_TIME_FIELD_NUMBER: builtins.int
    REQUESTED_STATE_FIELD_NUMBER: builtins.int
    EXECUTION_INFO_FIELD_NUMBER: builtins.int
    CREATE_TIME_FIELD_NUMBER: builtins.int
    REPLACE_JOB_ID_FIELD_NUMBER: builtins.int
    TRANSFORM_NAME_MAPPING_FIELD_NUMBER: builtins.int
    CLIENT_REQUEST_ID_FIELD_NUMBER: builtins.int
    REPLACED_BY_JOB_ID_FIELD_NUMBER: builtins.int
    TEMP_FILES_FIELD_NUMBER: builtins.int
    LABELS_FIELD_NUMBER: builtins.int
    LOCATION_FIELD_NUMBER: builtins.int
    PIPELINE_DESCRIPTION_FIELD_NUMBER: builtins.int
    STAGE_STATES_FIELD_NUMBER: builtins.int
    JOB_METADATA_FIELD_NUMBER: builtins.int
    START_TIME_FIELD_NUMBER: builtins.int
    CREATED_FROM_SNAPSHOT_ID_FIELD_NUMBER: builtins.int
    SATISFIES_PZS_FIELD_NUMBER: builtins.int
    id: typing.Text = ...
    """The unique ID of this job.

    This field is set by the Cloud Dataflow service when the Job is
    created, and is immutable for the life of the job.
    """

    project_id: typing.Text = ...
    """The ID of the Cloud Platform project that the job belongs to."""

    name: typing.Text = ...
    """The user-specified Cloud Dataflow job name.

    Only one Job with a given name may exist in a project at any
    given time. If a caller attempts to create a Job with the same
    name as an already-existing Job, the attempt returns the
    existing Job.

    The name must match the regular expression
    `[a-z]([-a-z0-9]{0,38}[a-z0-9])?`
    """

    type: google.dataflow.v1beta3.environment_pb2.JobType.ValueType = ...
    """The type of Cloud Dataflow job."""

    @property
    def environment(self) -> google.dataflow.v1beta3.environment_pb2.Environment:
        """The environment for the job."""
        pass
    @property
    def steps(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Step]:
        """Exactly one of step or steps_location should be specified.

        The top-level steps that constitute the entire job. Only retrieved with
        JOB_VIEW_ALL.
        """
        pass
    steps_location: typing.Text = ...
    """The Cloud Storage location where the steps are stored."""

    current_state: global___JobState.ValueType = ...
    """The current state of the job.

    Jobs are created in the `JOB_STATE_STOPPED` state unless otherwise
    specified.

    A job in the `JOB_STATE_RUNNING` state may asynchronously enter a
    terminal state. After a job has reached a terminal state, no
    further state updates may be made.

    This field may be mutated by the Cloud Dataflow service;
    callers cannot mutate it.
    """

    @property
    def current_state_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """The timestamp associated with the current state."""
        pass
    requested_state: global___JobState.ValueType = ...
    """The job's requested state.

    `UpdateJob` may be used to switch between the `JOB_STATE_STOPPED` and
    `JOB_STATE_RUNNING` states, by setting requested_state.  `UpdateJob` may
    also be used to directly set a job's requested state to
    `JOB_STATE_CANCELLED` or `JOB_STATE_DONE`, irrevocably terminating the
    job if it has not already reached a terminal state.
    """

    @property
    def execution_info(self) -> global___JobExecutionInfo:
        """Deprecated."""
        pass
    @property
    def create_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """The timestamp when the job was initially created. Immutable and set by the
        Cloud Dataflow service.
        """
        pass
    replace_job_id: typing.Text = ...
    """If this job is an update of an existing job, this field is the job ID
    of the job it replaced.

    When sending a `CreateJobRequest`, you can update a job by specifying it
    here. The job named here is stopped, and its intermediate state is
    transferred to this job.
    """

    @property
    def transform_name_mapping(self) -> google.protobuf.internal.containers.ScalarMap[typing.Text, typing.Text]:
        """The map of transform name prefixes of the job to be replaced to the
        corresponding name prefixes of the new job.
        """
        pass
    client_request_id: typing.Text = ...
    """The client's unique identifier of the job, re-used across retried attempts.
    If this field is set, the service will ensure its uniqueness.
    The request to create a job will fail if the service has knowledge of a
    previously submitted job with the same client's ID and job name.
    The caller may use this field to ensure idempotence of job
    creation across retried attempts to create a job.
    By default, the field is empty and, in that case, the service ignores it.
    """

    replaced_by_job_id: typing.Text = ...
    """If another job is an update of this job (and thus, this job is in
    `JOB_STATE_UPDATED`), this field contains the ID of that job.
    """

    @property
    def temp_files(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
        """A set of files the system should be aware of that are used
        for temporary storage. These temporary files will be
        removed on job completion.
        No duplicates are allowed.
        No file patterns are supported.

        The supported files are:

        Google Cloud Storage:

           storage.googleapis.com/{bucket}/{object}
           bucket.storage.googleapis.com/{object}
        """
        pass
    @property
    def labels(self) -> google.protobuf.internal.containers.ScalarMap[typing.Text, typing.Text]:
        """User-defined labels for this job.

        The labels map can contain no more than 64 entries.  Entries of the labels
        map are UTF8 strings that comply with the following restrictions:

        * Keys must conform to regexp:  [\\p{Ll}\\p{Lo}][\\p{Ll}\\p{Lo}\\p{N}_-]{0,62}
        * Values must conform to regexp:  [\\p{Ll}\\p{Lo}\\p{N}_-]{0,63}
        * Both keys and values are additionally constrained to be <= 128 bytes in
        size.
        """
        pass
    location: typing.Text = ...
    """The [regional endpoint]
    (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints) that
    contains this job.
    """

    @property
    def pipeline_description(self) -> global___PipelineDescription:
        """Preliminary field: The format of this data may change at any time.
        A description of the user pipeline and stages through which it is executed.
        Created by Cloud Dataflow service.  Only retrieved with
        JOB_VIEW_DESCRIPTION or JOB_VIEW_ALL.
        """
        pass
    @property
    def stage_states(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ExecutionStageState]:
        """This field may be mutated by the Cloud Dataflow service;
        callers cannot mutate it.
        """
        pass
    @property
    def job_metadata(self) -> global___JobMetadata:
        """This field is populated by the Dataflow service to support filtering jobs
        by the metadata values provided here. Populated for ListJobs and all GetJob
        views SUMMARY and higher.
        """
        pass
    @property
    def start_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """The timestamp when the job was started (transitioned to JOB_STATE_PENDING).
        Flexible resource scheduling jobs are started with some delay after job
        creation, so start_time is unset before start and is updated when the
        job is started by the Cloud Dataflow service. For other jobs, start_time
        always equals to create_time and is immutable and set by the Cloud Dataflow
        service.
        """
        pass
    created_from_snapshot_id: typing.Text = ...
    """If this is specified, the job's initial state is populated from the given
    snapshot.
    """

    satisfies_pzs: builtins.bool = ...
    """Reserved for future use. This field is set only in responses from the
    server; it is ignored if it is set in any requests.
    """

    def __init__(self,
        *,
        id : typing.Text = ...,
        project_id : typing.Text = ...,
        name : typing.Text = ...,
        type : google.dataflow.v1beta3.environment_pb2.JobType.ValueType = ...,
        environment : typing.Optional[google.dataflow.v1beta3.environment_pb2.Environment] = ...,
        steps : typing.Optional[typing.Iterable[global___Step]] = ...,
        steps_location : typing.Text = ...,
        current_state : global___JobState.ValueType = ...,
        current_state_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        requested_state : global___JobState.ValueType = ...,
        execution_info : typing.Optional[global___JobExecutionInfo] = ...,
        create_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        replace_job_id : typing.Text = ...,
        transform_name_mapping : typing.Optional[typing.Mapping[typing.Text, typing.Text]] = ...,
        client_request_id : typing.Text = ...,
        replaced_by_job_id : typing.Text = ...,
        temp_files : typing.Optional[typing.Iterable[typing.Text]] = ...,
        labels : typing.Optional[typing.Mapping[typing.Text, typing.Text]] = ...,
        location : typing.Text = ...,
        pipeline_description : typing.Optional[global___PipelineDescription] = ...,
        stage_states : typing.Optional[typing.Iterable[global___ExecutionStageState]] = ...,
        job_metadata : typing.Optional[global___JobMetadata] = ...,
        start_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        created_from_snapshot_id : typing.Text = ...,
        satisfies_pzs : builtins.bool = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["create_time",b"create_time","current_state_time",b"current_state_time","environment",b"environment","execution_info",b"execution_info","job_metadata",b"job_metadata","pipeline_description",b"pipeline_description","start_time",b"start_time"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["client_request_id",b"client_request_id","create_time",b"create_time","created_from_snapshot_id",b"created_from_snapshot_id","current_state",b"current_state","current_state_time",b"current_state_time","environment",b"environment","execution_info",b"execution_info","id",b"id","job_metadata",b"job_metadata","labels",b"labels","location",b"location","name",b"name","pipeline_description",b"pipeline_description","project_id",b"project_id","replace_job_id",b"replace_job_id","replaced_by_job_id",b"replaced_by_job_id","requested_state",b"requested_state","satisfies_pzs",b"satisfies_pzs","stage_states",b"stage_states","start_time",b"start_time","steps",b"steps","steps_location",b"steps_location","temp_files",b"temp_files","transform_name_mapping",b"transform_name_mapping","type",b"type"]) -> None: ...
global___Job = Job

class DatastoreIODetails(google.protobuf.message.Message):
    """Metadata for a Datastore connector used by the job."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    NAMESPACE_FIELD_NUMBER: builtins.int
    PROJECT_ID_FIELD_NUMBER: builtins.int
    namespace: typing.Text = ...
    """Namespace used in the connection."""

    project_id: typing.Text = ...
    """ProjectId accessed in the connection."""

    def __init__(self,
        *,
        namespace : typing.Text = ...,
        project_id : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["namespace",b"namespace","project_id",b"project_id"]) -> None: ...
global___DatastoreIODetails = DatastoreIODetails

class PubSubIODetails(google.protobuf.message.Message):
    """Metadata for a Pub/Sub connector used by the job."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    TOPIC_FIELD_NUMBER: builtins.int
    SUBSCRIPTION_FIELD_NUMBER: builtins.int
    topic: typing.Text = ...
    """Topic accessed in the connection."""

    subscription: typing.Text = ...
    """Subscription used in the connection."""

    def __init__(self,
        *,
        topic : typing.Text = ...,
        subscription : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["subscription",b"subscription","topic",b"topic"]) -> None: ...
global___PubSubIODetails = PubSubIODetails

class FileIODetails(google.protobuf.message.Message):
    """Metadata for a File connector used by the job."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    FILE_PATTERN_FIELD_NUMBER: builtins.int
    file_pattern: typing.Text = ...
    """File Pattern used to access files by the connector."""

    def __init__(self,
        *,
        file_pattern : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["file_pattern",b"file_pattern"]) -> None: ...
global___FileIODetails = FileIODetails

class BigTableIODetails(google.protobuf.message.Message):
    """Metadata for a Cloud BigTable connector used by the job."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    PROJECT_ID_FIELD_NUMBER: builtins.int
    INSTANCE_ID_FIELD_NUMBER: builtins.int
    TABLE_ID_FIELD_NUMBER: builtins.int
    project_id: typing.Text = ...
    """ProjectId accessed in the connection."""

    instance_id: typing.Text = ...
    """InstanceId accessed in the connection."""

    table_id: typing.Text = ...
    """TableId accessed in the connection."""

    def __init__(self,
        *,
        project_id : typing.Text = ...,
        instance_id : typing.Text = ...,
        table_id : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["instance_id",b"instance_id","project_id",b"project_id","table_id",b"table_id"]) -> None: ...
global___BigTableIODetails = BigTableIODetails

class BigQueryIODetails(google.protobuf.message.Message):
    """Metadata for a BigQuery connector used by the job."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    TABLE_FIELD_NUMBER: builtins.int
    DATASET_FIELD_NUMBER: builtins.int
    PROJECT_ID_FIELD_NUMBER: builtins.int
    QUERY_FIELD_NUMBER: builtins.int
    table: typing.Text = ...
    """Table accessed in the connection."""

    dataset: typing.Text = ...
    """Dataset accessed in the connection."""

    project_id: typing.Text = ...
    """Project accessed in the connection."""

    query: typing.Text = ...
    """Query used to access data in the connection."""

    def __init__(self,
        *,
        table : typing.Text = ...,
        dataset : typing.Text = ...,
        project_id : typing.Text = ...,
        query : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["dataset",b"dataset","project_id",b"project_id","query",b"query","table",b"table"]) -> None: ...
global___BigQueryIODetails = BigQueryIODetails

class SpannerIODetails(google.protobuf.message.Message):
    """Metadata for a Spanner connector used by the job."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    PROJECT_ID_FIELD_NUMBER: builtins.int
    INSTANCE_ID_FIELD_NUMBER: builtins.int
    DATABASE_ID_FIELD_NUMBER: builtins.int
    project_id: typing.Text = ...
    """ProjectId accessed in the connection."""

    instance_id: typing.Text = ...
    """InstanceId accessed in the connection."""

    database_id: typing.Text = ...
    """DatabaseId accessed in the connection."""

    def __init__(self,
        *,
        project_id : typing.Text = ...,
        instance_id : typing.Text = ...,
        database_id : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["database_id",b"database_id","instance_id",b"instance_id","project_id",b"project_id"]) -> None: ...
global___SpannerIODetails = SpannerIODetails

class SdkVersion(google.protobuf.message.Message):
    """The version of the SDK used to run the job."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class _SdkSupportStatus:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _SdkSupportStatusEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_SdkSupportStatus.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        UNKNOWN: SdkVersion.SdkSupportStatus.ValueType = ...  # 0
        """Cloud Dataflow is unaware of this version."""

        SUPPORTED: SdkVersion.SdkSupportStatus.ValueType = ...  # 1
        """This is a known version of an SDK, and is supported."""

        STALE: SdkVersion.SdkSupportStatus.ValueType = ...  # 2
        """A newer version of the SDK family exists, and an update is recommended."""

        DEPRECATED: SdkVersion.SdkSupportStatus.ValueType = ...  # 3
        """This version of the SDK is deprecated and will eventually be
        unsupported.
        """

        UNSUPPORTED: SdkVersion.SdkSupportStatus.ValueType = ...  # 4
        """Support for this SDK version has ended and it should no longer be used."""

    class SdkSupportStatus(_SdkSupportStatus, metaclass=_SdkSupportStatusEnumTypeWrapper):
        """The support status of the SDK used to run the job."""
        pass

    UNKNOWN: SdkVersion.SdkSupportStatus.ValueType = ...  # 0
    """Cloud Dataflow is unaware of this version."""

    SUPPORTED: SdkVersion.SdkSupportStatus.ValueType = ...  # 1
    """This is a known version of an SDK, and is supported."""

    STALE: SdkVersion.SdkSupportStatus.ValueType = ...  # 2
    """A newer version of the SDK family exists, and an update is recommended."""

    DEPRECATED: SdkVersion.SdkSupportStatus.ValueType = ...  # 3
    """This version of the SDK is deprecated and will eventually be
    unsupported.
    """

    UNSUPPORTED: SdkVersion.SdkSupportStatus.ValueType = ...  # 4
    """Support for this SDK version has ended and it should no longer be used."""


    VERSION_FIELD_NUMBER: builtins.int
    VERSION_DISPLAY_NAME_FIELD_NUMBER: builtins.int
    SDK_SUPPORT_STATUS_FIELD_NUMBER: builtins.int
    version: typing.Text = ...
    """The version of the SDK used to run the job."""

    version_display_name: typing.Text = ...
    """A readable string describing the version of the SDK."""

    sdk_support_status: global___SdkVersion.SdkSupportStatus.ValueType = ...
    """The support status for this SDK version."""

    def __init__(self,
        *,
        version : typing.Text = ...,
        version_display_name : typing.Text = ...,
        sdk_support_status : global___SdkVersion.SdkSupportStatus.ValueType = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["sdk_support_status",b"sdk_support_status","version",b"version","version_display_name",b"version_display_name"]) -> None: ...
global___SdkVersion = SdkVersion

class JobMetadata(google.protobuf.message.Message):
    """Metadata available primarily for filtering jobs. Will be included in the
    ListJob response and Job SUMMARY view.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    SDK_VERSION_FIELD_NUMBER: builtins.int
    SPANNER_DETAILS_FIELD_NUMBER: builtins.int
    BIGQUERY_DETAILS_FIELD_NUMBER: builtins.int
    BIG_TABLE_DETAILS_FIELD_NUMBER: builtins.int
    PUBSUB_DETAILS_FIELD_NUMBER: builtins.int
    FILE_DETAILS_FIELD_NUMBER: builtins.int
    DATASTORE_DETAILS_FIELD_NUMBER: builtins.int
    @property
    def sdk_version(self) -> global___SdkVersion:
        """The SDK version used to run the job."""
        pass
    @property
    def spanner_details(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___SpannerIODetails]:
        """Identification of a Spanner source used in the Dataflow job."""
        pass
    @property
    def bigquery_details(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___BigQueryIODetails]:
        """Identification of a BigQuery source used in the Dataflow job."""
        pass
    @property
    def big_table_details(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___BigTableIODetails]:
        """Identification of a Cloud BigTable source used in the Dataflow job."""
        pass
    @property
    def pubsub_details(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___PubSubIODetails]:
        """Identification of a PubSub source used in the Dataflow job."""
        pass
    @property
    def file_details(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___FileIODetails]:
        """Identification of a File source used in the Dataflow job."""
        pass
    @property
    def datastore_details(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___DatastoreIODetails]:
        """Identification of a Datastore source used in the Dataflow job."""
        pass
    def __init__(self,
        *,
        sdk_version : typing.Optional[global___SdkVersion] = ...,
        spanner_details : typing.Optional[typing.Iterable[global___SpannerIODetails]] = ...,
        bigquery_details : typing.Optional[typing.Iterable[global___BigQueryIODetails]] = ...,
        big_table_details : typing.Optional[typing.Iterable[global___BigTableIODetails]] = ...,
        pubsub_details : typing.Optional[typing.Iterable[global___PubSubIODetails]] = ...,
        file_details : typing.Optional[typing.Iterable[global___FileIODetails]] = ...,
        datastore_details : typing.Optional[typing.Iterable[global___DatastoreIODetails]] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["sdk_version",b"sdk_version"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["big_table_details",b"big_table_details","bigquery_details",b"bigquery_details","datastore_details",b"datastore_details","file_details",b"file_details","pubsub_details",b"pubsub_details","sdk_version",b"sdk_version","spanner_details",b"spanner_details"]) -> None: ...
global___JobMetadata = JobMetadata

class ExecutionStageState(google.protobuf.message.Message):
    """A message describing the state of a particular execution stage."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    EXECUTION_STAGE_NAME_FIELD_NUMBER: builtins.int
    EXECUTION_STAGE_STATE_FIELD_NUMBER: builtins.int
    CURRENT_STATE_TIME_FIELD_NUMBER: builtins.int
    execution_stage_name: typing.Text = ...
    """The name of the execution stage."""

    execution_stage_state: global___JobState.ValueType = ...
    """Executions stage states allow the same set of values as JobState."""

    @property
    def current_state_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """The time at which the stage transitioned to this state."""
        pass
    def __init__(self,
        *,
        execution_stage_name : typing.Text = ...,
        execution_stage_state : global___JobState.ValueType = ...,
        current_state_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["current_state_time",b"current_state_time"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["current_state_time",b"current_state_time","execution_stage_name",b"execution_stage_name","execution_stage_state",b"execution_stage_state"]) -> None: ...
global___ExecutionStageState = ExecutionStageState

class PipelineDescription(google.protobuf.message.Message):
    """A descriptive representation of submitted pipeline as well as the executed
    form.  This data is provided by the Dataflow service for ease of visualizing
    the pipeline and interpreting Dataflow provided metrics.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    ORIGINAL_PIPELINE_TRANSFORM_FIELD_NUMBER: builtins.int
    EXECUTION_PIPELINE_STAGE_FIELD_NUMBER: builtins.int
    DISPLAY_DATA_FIELD_NUMBER: builtins.int
    @property
    def original_pipeline_transform(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___TransformSummary]:
        """Description of each transform in the pipeline and collections between them."""
        pass
    @property
    def execution_pipeline_stage(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ExecutionStageSummary]:
        """Description of each stage of execution of the pipeline."""
        pass
    @property
    def display_data(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___DisplayData]:
        """Pipeline level display data."""
        pass
    def __init__(self,
        *,
        original_pipeline_transform : typing.Optional[typing.Iterable[global___TransformSummary]] = ...,
        execution_pipeline_stage : typing.Optional[typing.Iterable[global___ExecutionStageSummary]] = ...,
        display_data : typing.Optional[typing.Iterable[global___DisplayData]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["display_data",b"display_data","execution_pipeline_stage",b"execution_pipeline_stage","original_pipeline_transform",b"original_pipeline_transform"]) -> None: ...
global___PipelineDescription = PipelineDescription

class TransformSummary(google.protobuf.message.Message):
    """Description of the type, names/ids, and input/outputs for a transform."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    KIND_FIELD_NUMBER: builtins.int
    ID_FIELD_NUMBER: builtins.int
    NAME_FIELD_NUMBER: builtins.int
    DISPLAY_DATA_FIELD_NUMBER: builtins.int
    OUTPUT_COLLECTION_NAME_FIELD_NUMBER: builtins.int
    INPUT_COLLECTION_NAME_FIELD_NUMBER: builtins.int
    kind: global___KindType.ValueType = ...
    """Type of transform."""

    id: typing.Text = ...
    """SDK generated id of this transform instance."""

    name: typing.Text = ...
    """User provided name for this transform instance."""

    @property
    def display_data(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___DisplayData]:
        """Transform-specific display data."""
        pass
    @property
    def output_collection_name(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
        """User  names for all collection outputs to this transform."""
        pass
    @property
    def input_collection_name(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
        """User names for all collection inputs to this transform."""
        pass
    def __init__(self,
        *,
        kind : global___KindType.ValueType = ...,
        id : typing.Text = ...,
        name : typing.Text = ...,
        display_data : typing.Optional[typing.Iterable[global___DisplayData]] = ...,
        output_collection_name : typing.Optional[typing.Iterable[typing.Text]] = ...,
        input_collection_name : typing.Optional[typing.Iterable[typing.Text]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["display_data",b"display_data","id",b"id","input_collection_name",b"input_collection_name","kind",b"kind","name",b"name","output_collection_name",b"output_collection_name"]) -> None: ...
global___TransformSummary = TransformSummary

class ExecutionStageSummary(google.protobuf.message.Message):
    """Description of the composing transforms, names/ids, and input/outputs of a
    stage of execution.  Some composing transforms and sources may have been
    generated by the Dataflow service during execution planning.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class StageSource(google.protobuf.message.Message):
        """Description of an input or output of an execution stage."""
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        USER_NAME_FIELD_NUMBER: builtins.int
        NAME_FIELD_NUMBER: builtins.int
        ORIGINAL_TRANSFORM_OR_COLLECTION_FIELD_NUMBER: builtins.int
        SIZE_BYTES_FIELD_NUMBER: builtins.int
        user_name: typing.Text = ...
        """Human-readable name for this source; may be user or system generated."""

        name: typing.Text = ...
        """Dataflow service generated name for this source."""

        original_transform_or_collection: typing.Text = ...
        """User name for the original user transform or collection with which this
        source is most closely associated.
        """

        size_bytes: builtins.int = ...
        """Size of the source, if measurable."""

        def __init__(self,
            *,
            user_name : typing.Text = ...,
            name : typing.Text = ...,
            original_transform_or_collection : typing.Text = ...,
            size_bytes : builtins.int = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["name",b"name","original_transform_or_collection",b"original_transform_or_collection","size_bytes",b"size_bytes","user_name",b"user_name"]) -> None: ...

    class ComponentTransform(google.protobuf.message.Message):
        """Description of a transform executed as part of an execution stage."""
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        USER_NAME_FIELD_NUMBER: builtins.int
        NAME_FIELD_NUMBER: builtins.int
        ORIGINAL_TRANSFORM_FIELD_NUMBER: builtins.int
        user_name: typing.Text = ...
        """Human-readable name for this transform; may be user or system generated."""

        name: typing.Text = ...
        """Dataflow service generated name for this source."""

        original_transform: typing.Text = ...
        """User name for the original user transform with which this transform is
        most closely associated.
        """

        def __init__(self,
            *,
            user_name : typing.Text = ...,
            name : typing.Text = ...,
            original_transform : typing.Text = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["name",b"name","original_transform",b"original_transform","user_name",b"user_name"]) -> None: ...

    class ComponentSource(google.protobuf.message.Message):
        """Description of an interstitial value between transforms in an execution
        stage.
        """
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        USER_NAME_FIELD_NUMBER: builtins.int
        NAME_FIELD_NUMBER: builtins.int
        ORIGINAL_TRANSFORM_OR_COLLECTION_FIELD_NUMBER: builtins.int
        user_name: typing.Text = ...
        """Human-readable name for this transform; may be user or system generated."""

        name: typing.Text = ...
        """Dataflow service generated name for this source."""

        original_transform_or_collection: typing.Text = ...
        """User name for the original user transform or collection with which this
        source is most closely associated.
        """

        def __init__(self,
            *,
            user_name : typing.Text = ...,
            name : typing.Text = ...,
            original_transform_or_collection : typing.Text = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["name",b"name","original_transform_or_collection",b"original_transform_or_collection","user_name",b"user_name"]) -> None: ...

    NAME_FIELD_NUMBER: builtins.int
    ID_FIELD_NUMBER: builtins.int
    KIND_FIELD_NUMBER: builtins.int
    INPUT_SOURCE_FIELD_NUMBER: builtins.int
    OUTPUT_SOURCE_FIELD_NUMBER: builtins.int
    PREREQUISITE_STAGE_FIELD_NUMBER: builtins.int
    COMPONENT_TRANSFORM_FIELD_NUMBER: builtins.int
    COMPONENT_SOURCE_FIELD_NUMBER: builtins.int
    name: typing.Text = ...
    """Dataflow service generated name for this stage."""

    id: typing.Text = ...
    """Dataflow service generated id for this stage."""

    kind: global___KindType.ValueType = ...
    """Type of transform this stage is executing."""

    @property
    def input_source(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ExecutionStageSummary.StageSource]:
        """Input sources for this stage."""
        pass
    @property
    def output_source(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ExecutionStageSummary.StageSource]:
        """Output sources for this stage."""
        pass
    @property
    def prerequisite_stage(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
        """Other stages that must complete before this stage can run."""
        pass
    @property
    def component_transform(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ExecutionStageSummary.ComponentTransform]:
        """Transforms that comprise this execution stage."""
        pass
    @property
    def component_source(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ExecutionStageSummary.ComponentSource]:
        """Collections produced and consumed by component transforms of this stage."""
        pass
    def __init__(self,
        *,
        name : typing.Text = ...,
        id : typing.Text = ...,
        kind : global___KindType.ValueType = ...,
        input_source : typing.Optional[typing.Iterable[global___ExecutionStageSummary.StageSource]] = ...,
        output_source : typing.Optional[typing.Iterable[global___ExecutionStageSummary.StageSource]] = ...,
        prerequisite_stage : typing.Optional[typing.Iterable[typing.Text]] = ...,
        component_transform : typing.Optional[typing.Iterable[global___ExecutionStageSummary.ComponentTransform]] = ...,
        component_source : typing.Optional[typing.Iterable[global___ExecutionStageSummary.ComponentSource]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["component_source",b"component_source","component_transform",b"component_transform","id",b"id","input_source",b"input_source","kind",b"kind","name",b"name","output_source",b"output_source","prerequisite_stage",b"prerequisite_stage"]) -> None: ...
global___ExecutionStageSummary = ExecutionStageSummary

class DisplayData(google.protobuf.message.Message):
    """Data provided with a pipeline or transform to provide descriptive info."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    KEY_FIELD_NUMBER: builtins.int
    NAMESPACE_FIELD_NUMBER: builtins.int
    STR_VALUE_FIELD_NUMBER: builtins.int
    INT64_VALUE_FIELD_NUMBER: builtins.int
    FLOAT_VALUE_FIELD_NUMBER: builtins.int
    JAVA_CLASS_VALUE_FIELD_NUMBER: builtins.int
    TIMESTAMP_VALUE_FIELD_NUMBER: builtins.int
    DURATION_VALUE_FIELD_NUMBER: builtins.int
    BOOL_VALUE_FIELD_NUMBER: builtins.int
    SHORT_STR_VALUE_FIELD_NUMBER: builtins.int
    URL_FIELD_NUMBER: builtins.int
    LABEL_FIELD_NUMBER: builtins.int
    key: typing.Text = ...
    """The key identifying the display data.
    This is intended to be used as a label for the display data
    when viewed in a dax monitoring system.
    """

    namespace: typing.Text = ...
    """The namespace for the key. This is usually a class name or programming
    language namespace (i.e. python module) which defines the display data.
    This allows a dax monitoring system to specially handle the data
    and perform custom rendering.
    """

    str_value: typing.Text = ...
    """Contains value if the data is of string type."""

    int64_value: builtins.int = ...
    """Contains value if the data is of int64 type."""

    float_value: builtins.float = ...
    """Contains value if the data is of float type."""

    java_class_value: typing.Text = ...
    """Contains value if the data is of java class type."""

    @property
    def timestamp_value(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Contains value if the data is of timestamp type."""
        pass
    @property
    def duration_value(self) -> google.protobuf.duration_pb2.Duration:
        """Contains value if the data is of duration type."""
        pass
    bool_value: builtins.bool = ...
    """Contains value if the data is of a boolean type."""

    short_str_value: typing.Text = ...
    """A possible additional shorter value to display.
    For example a java_class_name_value of com.mypackage.MyDoFn
    will be stored with MyDoFn as the short_str_value and
    com.mypackage.MyDoFn as the java_class_name value.
    short_str_value can be displayed and java_class_name_value
    will be displayed as a tooltip.
    """

    url: typing.Text = ...
    """An optional full URL."""

    label: typing.Text = ...
    """An optional label to display in a dax UI for the element."""

    def __init__(self,
        *,
        key : typing.Text = ...,
        namespace : typing.Text = ...,
        str_value : typing.Text = ...,
        int64_value : builtins.int = ...,
        float_value : builtins.float = ...,
        java_class_value : typing.Text = ...,
        timestamp_value : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        duration_value : typing.Optional[google.protobuf.duration_pb2.Duration] = ...,
        bool_value : builtins.bool = ...,
        short_str_value : typing.Text = ...,
        url : typing.Text = ...,
        label : typing.Text = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["Value",b"Value","bool_value",b"bool_value","duration_value",b"duration_value","float_value",b"float_value","int64_value",b"int64_value","java_class_value",b"java_class_value","str_value",b"str_value","timestamp_value",b"timestamp_value"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["Value",b"Value","bool_value",b"bool_value","duration_value",b"duration_value","float_value",b"float_value","int64_value",b"int64_value","java_class_value",b"java_class_value","key",b"key","label",b"label","namespace",b"namespace","short_str_value",b"short_str_value","str_value",b"str_value","timestamp_value",b"timestamp_value","url",b"url"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["Value",b"Value"]) -> typing.Optional[typing_extensions.Literal["str_value","int64_value","float_value","java_class_value","timestamp_value","duration_value","bool_value"]]: ...
global___DisplayData = DisplayData

class Step(google.protobuf.message.Message):
    """Defines a particular step within a Cloud Dataflow job.

    A job consists of multiple steps, each of which performs some
    specific operation as part of the overall job.  Data is typically
    passed from one step to another as part of the job.

    Here's an example of a sequence of steps which together implement a
    Map-Reduce job:

      * Read a collection of data from some source, parsing the
        collection's elements.

      * Validate the elements.

      * Apply a user-defined function to map each element to some value
        and extract an element-specific key value.

      * Group elements with the same key into a single element with
        that key, transforming a multiply-keyed collection into a
        uniquely-keyed collection.

      * Write the elements out to some data sink.

    Note that the Cloud Dataflow service may be used to run many different
    types of jobs, not just Map-Reduce.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    KIND_FIELD_NUMBER: builtins.int
    NAME_FIELD_NUMBER: builtins.int
    PROPERTIES_FIELD_NUMBER: builtins.int
    kind: typing.Text = ...
    """The kind of step in the Cloud Dataflow job."""

    name: typing.Text = ...
    """The name that identifies the step. This must be unique for each
    step with respect to all other steps in the Cloud Dataflow job.
    """

    @property
    def properties(self) -> google.protobuf.struct_pb2.Struct:
        """Named properties associated with the step. Each kind of
        predefined step has its own required set of properties.
        Must be provided on Create.  Only retrieved with JOB_VIEW_ALL.
        """
        pass
    def __init__(self,
        *,
        kind : typing.Text = ...,
        name : typing.Text = ...,
        properties : typing.Optional[google.protobuf.struct_pb2.Struct] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["properties",b"properties"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["kind",b"kind","name",b"name","properties",b"properties"]) -> None: ...
global___Step = Step

class JobExecutionInfo(google.protobuf.message.Message):
    """Additional information about how a Cloud Dataflow job will be executed that
    isn't contained in the submitted job.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class StagesEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: typing.Text = ...
        @property
        def value(self) -> global___JobExecutionStageInfo: ...
        def __init__(self,
            *,
            key : typing.Text = ...,
            value : typing.Optional[global___JobExecutionStageInfo] = ...,
            ) -> None: ...
        def HasField(self, field_name: typing_extensions.Literal["value",b"value"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

    STAGES_FIELD_NUMBER: builtins.int
    @property
    def stages(self) -> google.protobuf.internal.containers.MessageMap[typing.Text, global___JobExecutionStageInfo]:
        """A mapping from each stage to the information about that stage."""
        pass
    def __init__(self,
        *,
        stages : typing.Optional[typing.Mapping[typing.Text, global___JobExecutionStageInfo]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["stages",b"stages"]) -> None: ...
global___JobExecutionInfo = JobExecutionInfo

class JobExecutionStageInfo(google.protobuf.message.Message):
    """Contains information about how a particular
    [google.dataflow.v1beta3.Step][google.dataflow.v1beta3.Step] will be executed.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    STEP_NAME_FIELD_NUMBER: builtins.int
    @property
    def step_name(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
        """The steps associated with the execution stage.
        Note that stages may have several steps, and that a given step
        might be run by more than one stage.
        """
        pass
    def __init__(self,
        *,
        step_name : typing.Optional[typing.Iterable[typing.Text]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["step_name",b"step_name"]) -> None: ...
global___JobExecutionStageInfo = JobExecutionStageInfo

class CreateJobRequest(google.protobuf.message.Message):
    """Request to create a Cloud Dataflow job."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    PROJECT_ID_FIELD_NUMBER: builtins.int
    JOB_FIELD_NUMBER: builtins.int
    VIEW_FIELD_NUMBER: builtins.int
    REPLACE_JOB_ID_FIELD_NUMBER: builtins.int
    LOCATION_FIELD_NUMBER: builtins.int
    project_id: typing.Text = ...
    """The ID of the Cloud Platform project that the job belongs to."""

    @property
    def job(self) -> global___Job:
        """The job to create."""
        pass
    view: global___JobView.ValueType = ...
    """The level of information requested in response."""

    replace_job_id: typing.Text = ...
    """Deprecated. This field is now in the Job message."""

    location: typing.Text = ...
    """The [regional endpoint]
    (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints) that
    contains this job.
    """

    def __init__(self,
        *,
        project_id : typing.Text = ...,
        job : typing.Optional[global___Job] = ...,
        view : global___JobView.ValueType = ...,
        replace_job_id : typing.Text = ...,
        location : typing.Text = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["job",b"job"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["job",b"job","location",b"location","project_id",b"project_id","replace_job_id",b"replace_job_id","view",b"view"]) -> None: ...
global___CreateJobRequest = CreateJobRequest

class GetJobRequest(google.protobuf.message.Message):
    """Request to get the state of a Cloud Dataflow job."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    PROJECT_ID_FIELD_NUMBER: builtins.int
    JOB_ID_FIELD_NUMBER: builtins.int
    VIEW_FIELD_NUMBER: builtins.int
    LOCATION_FIELD_NUMBER: builtins.int
    project_id: typing.Text = ...
    """The ID of the Cloud Platform project that the job belongs to."""

    job_id: typing.Text = ...
    """The job ID."""

    view: global___JobView.ValueType = ...
    """The level of information requested in response."""

    location: typing.Text = ...
    """The [regional endpoint]
    (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints) that
    contains this job.
    """

    def __init__(self,
        *,
        project_id : typing.Text = ...,
        job_id : typing.Text = ...,
        view : global___JobView.ValueType = ...,
        location : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["job_id",b"job_id","location",b"location","project_id",b"project_id","view",b"view"]) -> None: ...
global___GetJobRequest = GetJobRequest

class UpdateJobRequest(google.protobuf.message.Message):
    """Request to update a Cloud Dataflow job."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    PROJECT_ID_FIELD_NUMBER: builtins.int
    JOB_ID_FIELD_NUMBER: builtins.int
    JOB_FIELD_NUMBER: builtins.int
    LOCATION_FIELD_NUMBER: builtins.int
    project_id: typing.Text = ...
    """The ID of the Cloud Platform project that the job belongs to."""

    job_id: typing.Text = ...
    """The job ID."""

    @property
    def job(self) -> global___Job:
        """The updated job.
        Only the job state is updatable; other fields will be ignored.
        """
        pass
    location: typing.Text = ...
    """The [regional endpoint]
    (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints) that
    contains this job.
    """

    def __init__(self,
        *,
        project_id : typing.Text = ...,
        job_id : typing.Text = ...,
        job : typing.Optional[global___Job] = ...,
        location : typing.Text = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["job",b"job"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["job",b"job","job_id",b"job_id","location",b"location","project_id",b"project_id"]) -> None: ...
global___UpdateJobRequest = UpdateJobRequest

class ListJobsRequest(google.protobuf.message.Message):
    """Request to list Cloud Dataflow jobs."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class _Filter:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _FilterEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_Filter.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        UNKNOWN: ListJobsRequest.Filter.ValueType = ...  # 0
        """The filter isn't specified, or is unknown. This returns all jobs ordered
        on descending `JobUuid`.
        """

        ALL: ListJobsRequest.Filter.ValueType = ...  # 1
        """Returns all running jobs first ordered on creation timestamp, then
        returns all terminated jobs ordered on the termination timestamp.
        """

        TERMINATED: ListJobsRequest.Filter.ValueType = ...  # 2
        """Filters the jobs that have a terminated state, ordered on the
        termination timestamp. Example terminated states: `JOB_STATE_STOPPED`,
        `JOB_STATE_UPDATED`, `JOB_STATE_DRAINED`, etc.
        """

        ACTIVE: ListJobsRequest.Filter.ValueType = ...  # 3
        """Filters the jobs that are running ordered on the creation timestamp."""

    class Filter(_Filter, metaclass=_FilterEnumTypeWrapper):
        """This field filters out and returns jobs in the specified job state. The
        order of data returned is determined by the filter used, and is subject to
        change.
        """
        pass

    UNKNOWN: ListJobsRequest.Filter.ValueType = ...  # 0
    """The filter isn't specified, or is unknown. This returns all jobs ordered
    on descending `JobUuid`.
    """

    ALL: ListJobsRequest.Filter.ValueType = ...  # 1
    """Returns all running jobs first ordered on creation timestamp, then
    returns all terminated jobs ordered on the termination timestamp.
    """

    TERMINATED: ListJobsRequest.Filter.ValueType = ...  # 2
    """Filters the jobs that have a terminated state, ordered on the
    termination timestamp. Example terminated states: `JOB_STATE_STOPPED`,
    `JOB_STATE_UPDATED`, `JOB_STATE_DRAINED`, etc.
    """

    ACTIVE: ListJobsRequest.Filter.ValueType = ...  # 3
    """Filters the jobs that are running ordered on the creation timestamp."""


    FILTER_FIELD_NUMBER: builtins.int
    PROJECT_ID_FIELD_NUMBER: builtins.int
    VIEW_FIELD_NUMBER: builtins.int
    PAGE_SIZE_FIELD_NUMBER: builtins.int
    PAGE_TOKEN_FIELD_NUMBER: builtins.int
    LOCATION_FIELD_NUMBER: builtins.int
    filter: global___ListJobsRequest.Filter.ValueType = ...
    """The kind of filter to use."""

    project_id: typing.Text = ...
    """The project which owns the jobs."""

    view: global___JobView.ValueType = ...
    """Deprecated. ListJobs always returns summaries now.
    Use GetJob for other JobViews.
    """

    page_size: builtins.int = ...
    """If there are many jobs, limit response to at most this many.
    The actual number of jobs returned will be the lesser of max_responses
    and an unspecified server-defined limit.
    """

    page_token: typing.Text = ...
    """Set this to the 'next_page_token' field of a previous response
    to request additional results in a long list.
    """

    location: typing.Text = ...
    """The [regional endpoint]
    (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints) that
    contains this job.
    """

    def __init__(self,
        *,
        filter : global___ListJobsRequest.Filter.ValueType = ...,
        project_id : typing.Text = ...,
        view : global___JobView.ValueType = ...,
        page_size : builtins.int = ...,
        page_token : typing.Text = ...,
        location : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["filter",b"filter","location",b"location","page_size",b"page_size","page_token",b"page_token","project_id",b"project_id","view",b"view"]) -> None: ...
global___ListJobsRequest = ListJobsRequest

class FailedLocation(google.protobuf.message.Message):
    """Indicates which [regional endpoint]
    (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints) failed
    to respond to a request for data.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    NAME_FIELD_NUMBER: builtins.int
    name: typing.Text = ...
    """The name of the [regional endpoint]
    (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints) that
    failed to respond.
    """

    def __init__(self,
        *,
        name : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["name",b"name"]) -> None: ...
global___FailedLocation = FailedLocation

class ListJobsResponse(google.protobuf.message.Message):
    """Response to a request to list Cloud Dataflow jobs in a project. This might
    be a partial response, depending on the page size in the ListJobsRequest.
    However, if the project does not have any jobs, an instance of
    ListJobsResponse is not returned and the requests's response
    body is empty {}.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    JOBS_FIELD_NUMBER: builtins.int
    NEXT_PAGE_TOKEN_FIELD_NUMBER: builtins.int
    FAILED_LOCATION_FIELD_NUMBER: builtins.int
    @property
    def jobs(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Job]:
        """A subset of the requested job information."""
        pass
    next_page_token: typing.Text = ...
    """Set if there may be more results than fit in this response."""

    @property
    def failed_location(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___FailedLocation]:
        """Zero or more messages describing the [regional endpoints]
        (https://cloud.google.com/dataflow/docs/concepts/regional-endpoints) that
        failed to respond.
        """
        pass
    def __init__(self,
        *,
        jobs : typing.Optional[typing.Iterable[global___Job]] = ...,
        next_page_token : typing.Text = ...,
        failed_location : typing.Optional[typing.Iterable[global___FailedLocation]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["failed_location",b"failed_location","jobs",b"jobs","next_page_token",b"next_page_token"]) -> None: ...
global___ListJobsResponse = ListJobsResponse

class SnapshotJobRequest(google.protobuf.message.Message):
    """Request to create a snapshot of a job."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    PROJECT_ID_FIELD_NUMBER: builtins.int
    JOB_ID_FIELD_NUMBER: builtins.int
    TTL_FIELD_NUMBER: builtins.int
    LOCATION_FIELD_NUMBER: builtins.int
    SNAPSHOT_SOURCES_FIELD_NUMBER: builtins.int
    DESCRIPTION_FIELD_NUMBER: builtins.int
    project_id: typing.Text = ...
    """The project which owns the job to be snapshotted."""

    job_id: typing.Text = ...
    """The job to be snapshotted."""

    @property
    def ttl(self) -> google.protobuf.duration_pb2.Duration:
        """TTL for the snapshot."""
        pass
    location: typing.Text = ...
    """The location that contains this job."""

    snapshot_sources: builtins.bool = ...
    """If true, perform snapshots for sources which support this."""

    description: typing.Text = ...
    """User specified description of the snapshot. Maybe empty."""

    def __init__(self,
        *,
        project_id : typing.Text = ...,
        job_id : typing.Text = ...,
        ttl : typing.Optional[google.protobuf.duration_pb2.Duration] = ...,
        location : typing.Text = ...,
        snapshot_sources : builtins.bool = ...,
        description : typing.Text = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["ttl",b"ttl"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["description",b"description","job_id",b"job_id","location",b"location","project_id",b"project_id","snapshot_sources",b"snapshot_sources","ttl",b"ttl"]) -> None: ...
global___SnapshotJobRequest = SnapshotJobRequest

class CheckActiveJobsRequest(google.protobuf.message.Message):
    """Request to check is active jobs exists for a project"""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    PROJECT_ID_FIELD_NUMBER: builtins.int
    project_id: typing.Text = ...
    """The project which owns the jobs."""

    def __init__(self,
        *,
        project_id : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["project_id",b"project_id"]) -> None: ...
global___CheckActiveJobsRequest = CheckActiveJobsRequest

class CheckActiveJobsResponse(google.protobuf.message.Message):
    """Response for CheckActiveJobsRequest."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    ACTIVE_JOBS_EXIST_FIELD_NUMBER: builtins.int
    active_jobs_exist: builtins.bool = ...
    """If True, active jobs exists for project. False otherwise."""

    def __init__(self,
        *,
        active_jobs_exist : builtins.bool = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["active_jobs_exist",b"active_jobs_exist"]) -> None: ...
global___CheckActiveJobsResponse = CheckActiveJobsResponse
