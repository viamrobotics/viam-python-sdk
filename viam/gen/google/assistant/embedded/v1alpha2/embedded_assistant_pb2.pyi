"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import google.protobuf.descriptor
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import google.type.latlng_pb2
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor = ...

class AssistRequest(google.protobuf.message.Message):
    """The top-level message sent by the client. Clients must send at least two, and
    typically numerous `AssistRequest` messages. The first message must
    contain a `config` message and must not contain `audio_in` data. All
    subsequent messages must contain `audio_in` data and must not contain a
    `config` message.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    CONFIG_FIELD_NUMBER: builtins.int
    AUDIO_IN_FIELD_NUMBER: builtins.int
    @property
    def config(self) -> global___AssistConfig:
        """The `config` message provides information to the recognizer that
        specifies how to process the request.
        The first `AssistRequest` message must contain a `config` message.
        """
        pass
    audio_in: builtins.bytes = ...
    """The audio data to be recognized. Sequential chunks of audio data are sent
    in sequential `AssistRequest` messages. The first `AssistRequest`
    message must not contain `audio_in` data and all subsequent
    `AssistRequest` messages must contain `audio_in` data. The audio bytes
    must be encoded as specified in `AudioInConfig`.
    Audio must be sent at approximately real-time (16000 samples per second).
    An error will be returned if audio is sent significantly faster or
    slower.
    """

    def __init__(self,
        *,
        config : typing.Optional[global___AssistConfig] = ...,
        audio_in : builtins.bytes = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["audio_in",b"audio_in","config",b"config","type",b"type"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["audio_in",b"audio_in","config",b"config","type",b"type"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["type",b"type"]) -> typing.Optional[typing_extensions.Literal["config","audio_in"]]: ...
global___AssistRequest = AssistRequest

class AssistResponse(google.protobuf.message.Message):
    """The top-level message received by the client. A series of one or more
    `AssistResponse` messages are streamed back to the client.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class _EventType:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _EventTypeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_EventType.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        EVENT_TYPE_UNSPECIFIED: AssistResponse.EventType.ValueType = ...  # 0
        """No event specified."""

        END_OF_UTTERANCE: AssistResponse.EventType.ValueType = ...  # 1
        """This event indicates that the server has detected the end of the user's
        speech utterance and expects no additional speech. Therefore, the server
        will not process additional audio (although it may subsequently return
        additional results). The client should stop sending additional audio
        data, half-close the gRPC connection, and wait for any additional results
        until the server closes the gRPC connection.
        """

    class EventType(_EventType, metaclass=_EventTypeEnumTypeWrapper):
        """Indicates the type of event."""
        pass

    EVENT_TYPE_UNSPECIFIED: AssistResponse.EventType.ValueType = ...  # 0
    """No event specified."""

    END_OF_UTTERANCE: AssistResponse.EventType.ValueType = ...  # 1
    """This event indicates that the server has detected the end of the user's
    speech utterance and expects no additional speech. Therefore, the server
    will not process additional audio (although it may subsequently return
    additional results). The client should stop sending additional audio
    data, half-close the gRPC connection, and wait for any additional results
    until the server closes the gRPC connection.
    """


    EVENT_TYPE_FIELD_NUMBER: builtins.int
    AUDIO_OUT_FIELD_NUMBER: builtins.int
    SCREEN_OUT_FIELD_NUMBER: builtins.int
    DEVICE_ACTION_FIELD_NUMBER: builtins.int
    SPEECH_RESULTS_FIELD_NUMBER: builtins.int
    DIALOG_STATE_OUT_FIELD_NUMBER: builtins.int
    DEBUG_INFO_FIELD_NUMBER: builtins.int
    event_type: global___AssistResponse.EventType.ValueType = ...
    """*Output-only* Indicates the type of event."""

    @property
    def audio_out(self) -> global___AudioOut:
        """*Output-only* The audio containing the Assistant's response to the query."""
        pass
    @property
    def screen_out(self) -> global___ScreenOut:
        """*Output-only* Contains the Assistant's visual response to the query."""
        pass
    @property
    def device_action(self) -> global___DeviceAction:
        """*Output-only* Contains the action triggered by the query with the
        appropriate payloads and semantic parsing.
        """
        pass
    @property
    def speech_results(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___SpeechRecognitionResult]:
        """*Output-only* This repeated list contains zero or more speech recognition
        results that correspond to consecutive portions of the audio currently
        being processed, starting with the portion corresponding to the earliest
        audio (and most stable portion) to the portion corresponding to the most
        recent audio. The strings can be concatenated to view the full
        in-progress response. When the speech recognition completes, this list
        will contain one item with `stability` of `1.0`.
        """
        pass
    @property
    def dialog_state_out(self) -> global___DialogStateOut:
        """*Output-only* Contains output related to the user's query."""
        pass
    @property
    def debug_info(self) -> global___DebugInfo:
        """*Output-only* Debugging info for developer. Only returned if request set
        `return_debug_info` to true.
        """
        pass
    def __init__(self,
        *,
        event_type : global___AssistResponse.EventType.ValueType = ...,
        audio_out : typing.Optional[global___AudioOut] = ...,
        screen_out : typing.Optional[global___ScreenOut] = ...,
        device_action : typing.Optional[global___DeviceAction] = ...,
        speech_results : typing.Optional[typing.Iterable[global___SpeechRecognitionResult]] = ...,
        dialog_state_out : typing.Optional[global___DialogStateOut] = ...,
        debug_info : typing.Optional[global___DebugInfo] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["audio_out",b"audio_out","debug_info",b"debug_info","device_action",b"device_action","dialog_state_out",b"dialog_state_out","screen_out",b"screen_out"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["audio_out",b"audio_out","debug_info",b"debug_info","device_action",b"device_action","dialog_state_out",b"dialog_state_out","event_type",b"event_type","screen_out",b"screen_out","speech_results",b"speech_results"]) -> None: ...
global___AssistResponse = AssistResponse

class DebugInfo(google.protobuf.message.Message):
    """Debug info for developer. Only returned if request set `return_debug_info`
    to true.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    AOG_AGENT_TO_ASSISTANT_JSON_FIELD_NUMBER: builtins.int
    aog_agent_to_assistant_json: typing.Text = ...
    """The original JSON response from an Action-on-Google agent to Google server.
    See
    https://developers.google.com/actions/reference/rest/Shared.Types/AppResponse.
    It will only be populated if the request maker owns the AoG project and the
    AoG project is in preview mode.
    """

    def __init__(self,
        *,
        aog_agent_to_assistant_json : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["aog_agent_to_assistant_json",b"aog_agent_to_assistant_json"]) -> None: ...
global___DebugInfo = DebugInfo

class AssistConfig(google.protobuf.message.Message):
    """Specifies how to process the `AssistRequest` messages."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    AUDIO_IN_CONFIG_FIELD_NUMBER: builtins.int
    TEXT_QUERY_FIELD_NUMBER: builtins.int
    AUDIO_OUT_CONFIG_FIELD_NUMBER: builtins.int
    SCREEN_OUT_CONFIG_FIELD_NUMBER: builtins.int
    DIALOG_STATE_IN_FIELD_NUMBER: builtins.int
    DEVICE_CONFIG_FIELD_NUMBER: builtins.int
    DEBUG_CONFIG_FIELD_NUMBER: builtins.int
    @property
    def audio_in_config(self) -> global___AudioInConfig:
        """Specifies how to process the subsequent incoming audio. Required if
        [AssistRequest.audio_in][google.assistant.embedded.v1alpha2.AssistRequest.audio_in]
        bytes will be provided in subsequent requests.
        """
        pass
    text_query: typing.Text = ...
    """The text input to be sent to the Assistant. This can be populated from a
    text interface if audio input is not available.
    """

    @property
    def audio_out_config(self) -> global___AudioOutConfig:
        """*Required* Specifies how to format the audio that will be returned."""
        pass
    @property
    def screen_out_config(self) -> global___ScreenOutConfig:
        """*Optional* Specifies the desired format to use when server returns a
        visual screen response.
        """
        pass
    @property
    def dialog_state_in(self) -> global___DialogStateIn:
        """*Required* Represents the current dialog state."""
        pass
    @property
    def device_config(self) -> global___DeviceConfig:
        """Device configuration that uniquely identifies a specific device."""
        pass
    @property
    def debug_config(self) -> global___DebugConfig:
        """*Optional* Debugging parameters for the whole `Assist` RPC."""
        pass
    def __init__(self,
        *,
        audio_in_config : typing.Optional[global___AudioInConfig] = ...,
        text_query : typing.Text = ...,
        audio_out_config : typing.Optional[global___AudioOutConfig] = ...,
        screen_out_config : typing.Optional[global___ScreenOutConfig] = ...,
        dialog_state_in : typing.Optional[global___DialogStateIn] = ...,
        device_config : typing.Optional[global___DeviceConfig] = ...,
        debug_config : typing.Optional[global___DebugConfig] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["audio_in_config",b"audio_in_config","audio_out_config",b"audio_out_config","debug_config",b"debug_config","device_config",b"device_config","dialog_state_in",b"dialog_state_in","screen_out_config",b"screen_out_config","text_query",b"text_query","type",b"type"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["audio_in_config",b"audio_in_config","audio_out_config",b"audio_out_config","debug_config",b"debug_config","device_config",b"device_config","dialog_state_in",b"dialog_state_in","screen_out_config",b"screen_out_config","text_query",b"text_query","type",b"type"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["type",b"type"]) -> typing.Optional[typing_extensions.Literal["audio_in_config","text_query"]]: ...
global___AssistConfig = AssistConfig

class AudioInConfig(google.protobuf.message.Message):
    """Specifies how to process the `audio_in` data that will be provided in
    subsequent requests. For recommended settings, see the Google Assistant SDK
    [best
    practices](https://developers.google.com/assistant/sdk/guides/service/python/best-practices/audio).
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class _Encoding:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _EncodingEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_Encoding.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        ENCODING_UNSPECIFIED: AudioInConfig.Encoding.ValueType = ...  # 0
        """Not specified. Will return result [google.rpc.Code.INVALID_ARGUMENT][]."""

        LINEAR16: AudioInConfig.Encoding.ValueType = ...  # 1
        """Uncompressed 16-bit signed little-endian samples (Linear PCM).
        This encoding includes no header, only the raw audio bytes.
        """

        FLAC: AudioInConfig.Encoding.ValueType = ...  # 2
        """[`FLAC`](https://xiph.org/flac/documentation.html) (Free Lossless Audio
        Codec) is the recommended encoding because it is
        lossless--therefore recognition is not compromised--and
        requires only about half the bandwidth of `LINEAR16`. This encoding
        includes the `FLAC` stream header followed by audio data. It supports
        16-bit and 24-bit samples, however, not all fields in `STREAMINFO` are
        supported.
        """

    class Encoding(_Encoding, metaclass=_EncodingEnumTypeWrapper):
        """Audio encoding of the data sent in the audio message.
        Audio must be one-channel (mono).
        """
        pass

    ENCODING_UNSPECIFIED: AudioInConfig.Encoding.ValueType = ...  # 0
    """Not specified. Will return result [google.rpc.Code.INVALID_ARGUMENT][]."""

    LINEAR16: AudioInConfig.Encoding.ValueType = ...  # 1
    """Uncompressed 16-bit signed little-endian samples (Linear PCM).
    This encoding includes no header, only the raw audio bytes.
    """

    FLAC: AudioInConfig.Encoding.ValueType = ...  # 2
    """[`FLAC`](https://xiph.org/flac/documentation.html) (Free Lossless Audio
    Codec) is the recommended encoding because it is
    lossless--therefore recognition is not compromised--and
    requires only about half the bandwidth of `LINEAR16`. This encoding
    includes the `FLAC` stream header followed by audio data. It supports
    16-bit and 24-bit samples, however, not all fields in `STREAMINFO` are
    supported.
    """


    ENCODING_FIELD_NUMBER: builtins.int
    SAMPLE_RATE_HERTZ_FIELD_NUMBER: builtins.int
    encoding: global___AudioInConfig.Encoding.ValueType = ...
    """*Required* Encoding of audio data sent in all `audio_in` messages."""

    sample_rate_hertz: builtins.int = ...
    """*Required* Sample rate (in Hertz) of the audio data sent in all `audio_in`
    messages. Valid values are from 16000-24000, but 16000 is optimal.
    For best results, set the sampling rate of the audio source to 16000 Hz.
    If that's not possible, use the native sample rate of the audio source
    (instead of re-sampling).
    """

    def __init__(self,
        *,
        encoding : global___AudioInConfig.Encoding.ValueType = ...,
        sample_rate_hertz : builtins.int = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["encoding",b"encoding","sample_rate_hertz",b"sample_rate_hertz"]) -> None: ...
global___AudioInConfig = AudioInConfig

class AudioOutConfig(google.protobuf.message.Message):
    """Specifies the desired format for the server to use when it returns
    `audio_out` messages.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class _Encoding:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _EncodingEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_Encoding.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        ENCODING_UNSPECIFIED: AudioOutConfig.Encoding.ValueType = ...  # 0
        """Not specified. Will return result [google.rpc.Code.INVALID_ARGUMENT][]."""

        LINEAR16: AudioOutConfig.Encoding.ValueType = ...  # 1
        """Uncompressed 16-bit signed little-endian samples (Linear PCM)."""

        MP3: AudioOutConfig.Encoding.ValueType = ...  # 2
        """MP3 audio encoding. The sample rate is encoded in the payload."""

        OPUS_IN_OGG: AudioOutConfig.Encoding.ValueType = ...  # 3
        """Opus-encoded audio wrapped in an ogg container. The result will be a
        file which can be played natively on Android and in some browsers (such
        as Chrome). The quality of the encoding is considerably higher than MP3
        while using the same bitrate. The sample rate is encoded in the payload.
        """

    class Encoding(_Encoding, metaclass=_EncodingEnumTypeWrapper):
        """Audio encoding of the data returned in the audio message. All encodings are
        raw audio bytes with no header, except as indicated below.
        """
        pass

    ENCODING_UNSPECIFIED: AudioOutConfig.Encoding.ValueType = ...  # 0
    """Not specified. Will return result [google.rpc.Code.INVALID_ARGUMENT][]."""

    LINEAR16: AudioOutConfig.Encoding.ValueType = ...  # 1
    """Uncompressed 16-bit signed little-endian samples (Linear PCM)."""

    MP3: AudioOutConfig.Encoding.ValueType = ...  # 2
    """MP3 audio encoding. The sample rate is encoded in the payload."""

    OPUS_IN_OGG: AudioOutConfig.Encoding.ValueType = ...  # 3
    """Opus-encoded audio wrapped in an ogg container. The result will be a
    file which can be played natively on Android and in some browsers (such
    as Chrome). The quality of the encoding is considerably higher than MP3
    while using the same bitrate. The sample rate is encoded in the payload.
    """


    ENCODING_FIELD_NUMBER: builtins.int
    SAMPLE_RATE_HERTZ_FIELD_NUMBER: builtins.int
    VOLUME_PERCENTAGE_FIELD_NUMBER: builtins.int
    encoding: global___AudioOutConfig.Encoding.ValueType = ...
    """*Required* The encoding of audio data to be returned in all `audio_out`
    messages.
    """

    sample_rate_hertz: builtins.int = ...
    """*Required* The sample rate in Hertz of the audio data returned in
    `audio_out` messages. Valid values are: 16000-24000.
    """

    volume_percentage: builtins.int = ...
    """*Required* Current volume setting of the device's audio output.
    Valid values are 1 to 100 (corresponding to 1% to 100%).
    """

    def __init__(self,
        *,
        encoding : global___AudioOutConfig.Encoding.ValueType = ...,
        sample_rate_hertz : builtins.int = ...,
        volume_percentage : builtins.int = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["encoding",b"encoding","sample_rate_hertz",b"sample_rate_hertz","volume_percentage",b"volume_percentage"]) -> None: ...
global___AudioOutConfig = AudioOutConfig

class ScreenOutConfig(google.protobuf.message.Message):
    """Specifies the desired format for the server to use when it returns
    `screen_out` response.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class _ScreenMode:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _ScreenModeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_ScreenMode.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        SCREEN_MODE_UNSPECIFIED: ScreenOutConfig.ScreenMode.ValueType = ...  # 0
        """No video mode specified.
        The Assistant may respond as if in `OFF` mode.
        """

        OFF: ScreenOutConfig.ScreenMode.ValueType = ...  # 1
        """Screen is off (or has brightness or other settings set so low it is
        not visible). The Assistant will typically not return a screen response
        in this mode.
        """

        PLAYING: ScreenOutConfig.ScreenMode.ValueType = ...  # 3
        """The Assistant will typically return a partial-screen response in this
        mode.
        """

    class ScreenMode(_ScreenMode, metaclass=_ScreenModeEnumTypeWrapper):
        """Possible modes for visual screen-output on the device."""
        pass

    SCREEN_MODE_UNSPECIFIED: ScreenOutConfig.ScreenMode.ValueType = ...  # 0
    """No video mode specified.
    The Assistant may respond as if in `OFF` mode.
    """

    OFF: ScreenOutConfig.ScreenMode.ValueType = ...  # 1
    """Screen is off (or has brightness or other settings set so low it is
    not visible). The Assistant will typically not return a screen response
    in this mode.
    """

    PLAYING: ScreenOutConfig.ScreenMode.ValueType = ...  # 3
    """The Assistant will typically return a partial-screen response in this
    mode.
    """


    SCREEN_MODE_FIELD_NUMBER: builtins.int
    screen_mode: global___ScreenOutConfig.ScreenMode.ValueType = ...
    """Current visual screen-mode for the device while issuing the query."""

    def __init__(self,
        *,
        screen_mode : global___ScreenOutConfig.ScreenMode.ValueType = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["screen_mode",b"screen_mode"]) -> None: ...
global___ScreenOutConfig = ScreenOutConfig

class DialogStateIn(google.protobuf.message.Message):
    """Provides information about the current dialog state."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    CONVERSATION_STATE_FIELD_NUMBER: builtins.int
    LANGUAGE_CODE_FIELD_NUMBER: builtins.int
    DEVICE_LOCATION_FIELD_NUMBER: builtins.int
    IS_NEW_CONVERSATION_FIELD_NUMBER: builtins.int
    conversation_state: builtins.bytes = ...
    """*Required* This field must always be set to the
    [DialogStateOut.conversation_state][google.assistant.embedded.v1alpha2.DialogStateOut.conversation_state]
    value that was returned in the prior `Assist` RPC. It should only be
    omitted (field not set) if there was no prior `Assist` RPC because this is
    the first `Assist` RPC made by this device after it was first setup and/or
    a factory-default reset.
    """

    language_code: typing.Text = ...
    """*Required* Language of the request in
    [IETF BCP 47 syntax](https://tools.ietf.org/html/bcp47) (for example,
    "en-US"). See [Language
    Support](https://developers.google.com/assistant/sdk/reference/rpc/languages)
    for more information. If you have selected a language for this `device_id`
    using the
    [Settings](https://developers.google.com/assistant/sdk/reference/assistant-app/assistant-settings)
    menu in your phone's Google Assistant app, that selection will override
    this value.
    """

    @property
    def device_location(self) -> global___DeviceLocation:
        """*Optional* Location of the device where the query originated."""
        pass
    is_new_conversation: builtins.bool = ...
    """*Optional* If true, the server will treat the request as a new conversation
    and not use state from the prior request. Set this field to true when the
    conversation should be restarted, such as after a device reboot, or after a
    significant lapse of time since the prior query.
    """

    def __init__(self,
        *,
        conversation_state : builtins.bytes = ...,
        language_code : typing.Text = ...,
        device_location : typing.Optional[global___DeviceLocation] = ...,
        is_new_conversation : builtins.bool = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["device_location",b"device_location"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["conversation_state",b"conversation_state","device_location",b"device_location","is_new_conversation",b"is_new_conversation","language_code",b"language_code"]) -> None: ...
global___DialogStateIn = DialogStateIn

class DeviceConfig(google.protobuf.message.Message):
    """*Required* Fields that identify the device to the Assistant.

    See also:

    *   [Register a Device - REST
    API](https://developers.google.com/assistant/sdk/reference/device-registration/register-device-manual)
    *   [Device Model and Instance
    Schemas](https://developers.google.com/assistant/sdk/reference/device-registration/model-and-instance-schemas)
    *   [Device
    Proto](https://developers.google.com/assistant/sdk/reference/rpc/google.assistant.devices.v1alpha2#device)
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    DEVICE_ID_FIELD_NUMBER: builtins.int
    DEVICE_MODEL_ID_FIELD_NUMBER: builtins.int
    device_id: typing.Text = ...
    """*Required* Unique identifier for the device. The id length must be 128
    characters or less. Example: DBCDW098234. This MUST match the device_id
    returned from device registration. This device_id is used to match against
    the user's registered devices to lookup the supported traits and
    capabilities of this device. This information should not change across
    device reboots. However, it should not be saved across
    factory-default resets.
    """

    device_model_id: typing.Text = ...
    """*Required* Unique identifier for the device model. The combination of
    device_model_id and device_id must have been previously associated through
    device registration.
    """

    def __init__(self,
        *,
        device_id : typing.Text = ...,
        device_model_id : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["device_id",b"device_id","device_model_id",b"device_model_id"]) -> None: ...
global___DeviceConfig = DeviceConfig

class AudioOut(google.protobuf.message.Message):
    """The audio containing the Assistant's response to the query. Sequential chunks
    of audio data are received in sequential `AssistResponse` messages.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    AUDIO_DATA_FIELD_NUMBER: builtins.int
    audio_data: builtins.bytes = ...
    """*Output-only* The audio data containing the Assistant's response to the
    query. Sequential chunks of audio data are received in sequential
    `AssistResponse` messages.
    """

    def __init__(self,
        *,
        audio_data : builtins.bytes = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["audio_data",b"audio_data"]) -> None: ...
global___AudioOut = AudioOut

class ScreenOut(google.protobuf.message.Message):
    """The Assistant's visual output response to query. Enabled by
    `screen_out_config`.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class _Format:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _FormatEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_Format.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        FORMAT_UNSPECIFIED: ScreenOut.Format.ValueType = ...  # 0
        """No format specified."""

        HTML: ScreenOut.Format.ValueType = ...  # 1
        """Data will contain a fully-formed HTML5 layout encoded in UTF-8, e.g.
        `<html><body><div>...</div></body></html>`. It is intended to be rendered
        along with the audio response. Note that HTML5 doctype should be included
        in the actual HTML data.
        """

    class Format(_Format, metaclass=_FormatEnumTypeWrapper):
        """Possible formats of the screen data."""
        pass

    FORMAT_UNSPECIFIED: ScreenOut.Format.ValueType = ...  # 0
    """No format specified."""

    HTML: ScreenOut.Format.ValueType = ...  # 1
    """Data will contain a fully-formed HTML5 layout encoded in UTF-8, e.g.
    `<html><body><div>...</div></body></html>`. It is intended to be rendered
    along with the audio response. Note that HTML5 doctype should be included
    in the actual HTML data.
    """


    FORMAT_FIELD_NUMBER: builtins.int
    DATA_FIELD_NUMBER: builtins.int
    format: global___ScreenOut.Format.ValueType = ...
    """*Output-only* The format of the provided screen data."""

    data: builtins.bytes = ...
    """*Output-only* The raw screen data to be displayed as the result of the
    Assistant query.
    """

    def __init__(self,
        *,
        format : global___ScreenOut.Format.ValueType = ...,
        data : builtins.bytes = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["data",b"data","format",b"format"]) -> None: ...
global___ScreenOut = ScreenOut

class DeviceAction(google.protobuf.message.Message):
    """The response returned to the device if the user has triggered a Device
    Action. For example, a device which supports the query *Turn on the light*
    would receive a `DeviceAction` with a JSON payload containing the semantics
    of the request.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    DEVICE_REQUEST_JSON_FIELD_NUMBER: builtins.int
    device_request_json: typing.Text = ...
    """JSON containing the device command response generated from the triggered
    Device Action grammar. The format is given by the
    `action.devices.EXECUTE` intent for a given
    [trait](https://developers.google.com/assistant/sdk/reference/traits/).
    """

    def __init__(self,
        *,
        device_request_json : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["device_request_json",b"device_request_json"]) -> None: ...
global___DeviceAction = DeviceAction

class SpeechRecognitionResult(google.protobuf.message.Message):
    """The estimated transcription of a phrase the user has spoken. This could be
    a single segment or the full guess of the user's spoken query.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    TRANSCRIPT_FIELD_NUMBER: builtins.int
    STABILITY_FIELD_NUMBER: builtins.int
    transcript: typing.Text = ...
    """*Output-only* Transcript text representing the words that the user spoke."""

    stability: builtins.float = ...
    """*Output-only* An estimate of the likelihood that the Assistant will not
    change its guess about this result. Values range from 0.0 (completely
    unstable) to 1.0 (completely stable and final). The default of 0.0 is a
    sentinel value indicating `stability` was not set.
    """

    def __init__(self,
        *,
        transcript : typing.Text = ...,
        stability : builtins.float = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["stability",b"stability","transcript",b"transcript"]) -> None: ...
global___SpeechRecognitionResult = SpeechRecognitionResult

class DialogStateOut(google.protobuf.message.Message):
    """The dialog state resulting from the user's query. Multiple of these messages
    may be received.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class _MicrophoneMode:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _MicrophoneModeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_MicrophoneMode.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        MICROPHONE_MODE_UNSPECIFIED: DialogStateOut.MicrophoneMode.ValueType = ...  # 0
        """No mode specified."""

        CLOSE_MICROPHONE: DialogStateOut.MicrophoneMode.ValueType = ...  # 1
        """The service is not expecting a follow-on question from the user.
        The microphone should remain off until the user re-activates it.
        """

        DIALOG_FOLLOW_ON: DialogStateOut.MicrophoneMode.ValueType = ...  # 2
        """The service is expecting a follow-on question from the user. The
        microphone should be re-opened when the `AudioOut` playback completes
        (by starting a new `Assist` RPC call to send the new audio).
        """

    class MicrophoneMode(_MicrophoneMode, metaclass=_MicrophoneModeEnumTypeWrapper):
        """Possible states of the microphone after a `Assist` RPC completes."""
        pass

    MICROPHONE_MODE_UNSPECIFIED: DialogStateOut.MicrophoneMode.ValueType = ...  # 0
    """No mode specified."""

    CLOSE_MICROPHONE: DialogStateOut.MicrophoneMode.ValueType = ...  # 1
    """The service is not expecting a follow-on question from the user.
    The microphone should remain off until the user re-activates it.
    """

    DIALOG_FOLLOW_ON: DialogStateOut.MicrophoneMode.ValueType = ...  # 2
    """The service is expecting a follow-on question from the user. The
    microphone should be re-opened when the `AudioOut` playback completes
    (by starting a new `Assist` RPC call to send the new audio).
    """


    SUPPLEMENTAL_DISPLAY_TEXT_FIELD_NUMBER: builtins.int
    CONVERSATION_STATE_FIELD_NUMBER: builtins.int
    MICROPHONE_MODE_FIELD_NUMBER: builtins.int
    VOLUME_PERCENTAGE_FIELD_NUMBER: builtins.int
    supplemental_display_text: typing.Text = ...
    """*Output-only* Supplemental display text from the Assistant. This could be
    the same as the speech spoken in `AssistResponse.audio_out` or it could
    be some additional information which aids the user's understanding.
    """

    conversation_state: builtins.bytes = ...
    """*Output-only* State information for the subsequent `Assist` RPC. This
    value should be saved in the client and returned in the
    [`DialogStateIn.conversation_state`](#dialogstatein) field with the next
    `Assist` RPC. (The client does not need to interpret or otherwise use this
    value.) This information should be saved across device reboots. However,
    this value should be cleared (not saved in the client) during a
    factory-default reset.
    """

    microphone_mode: global___DialogStateOut.MicrophoneMode.ValueType = ...
    """*Output-only* Specifies the mode of the microphone after this `Assist`
    RPC is processed.
    """

    volume_percentage: builtins.int = ...
    """*Output-only* Updated volume level. The value will be 0 or omitted
    (indicating no change) unless a voice command such as *Increase the volume*
    or *Set volume level 4* was recognized, in which case the value will be
    between 1 and 100 (corresponding to the new volume level of 1% to 100%).
    Typically, a client should use this volume level when playing the
    `audio_out` data, and retain this value as the current volume level and
    supply it in the `AudioOutConfig` of the next `AssistRequest`. (Some
    clients may also implement other ways to allow the current volume level to
    be changed, for example, by providing a knob that the user can turn.)
    """

    def __init__(self,
        *,
        supplemental_display_text : typing.Text = ...,
        conversation_state : builtins.bytes = ...,
        microphone_mode : global___DialogStateOut.MicrophoneMode.ValueType = ...,
        volume_percentage : builtins.int = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["conversation_state",b"conversation_state","microphone_mode",b"microphone_mode","supplemental_display_text",b"supplemental_display_text","volume_percentage",b"volume_percentage"]) -> None: ...
global___DialogStateOut = DialogStateOut

class DebugConfig(google.protobuf.message.Message):
    """Debugging parameters for the current request."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    RETURN_DEBUG_INFO_FIELD_NUMBER: builtins.int
    return_debug_info: builtins.bool = ...
    """When this field is set to true, the `debug_info` field in `AssistResponse`
    may be populated. However it will significantly increase latency of
    responses. Do not set this field true in production code.
    """

    def __init__(self,
        *,
        return_debug_info : builtins.bool = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["return_debug_info",b"return_debug_info"]) -> None: ...
global___DebugConfig = DebugConfig

class DeviceLocation(google.protobuf.message.Message):
    """There are three sources of locations. They are used with this precedence:

    1. This `DeviceLocation`, which is primarily used for mobile devices with
       GPS .
    2. Location specified by the user during device setup; this is per-user, per
       device. This location is used if `DeviceLocation` is not specified.
    3. Inferred location based on IP address. This is used only if neither of the
       above are specified.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    COORDINATES_FIELD_NUMBER: builtins.int
    @property
    def coordinates(self) -> google.type.latlng_pb2.LatLng:
        """Latitude and longitude of device."""
        pass
    def __init__(self,
        *,
        coordinates : typing.Optional[google.type.latlng_pb2.LatLng] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["coordinates",b"coordinates","type",b"type"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["coordinates",b"coordinates","type",b"type"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["type",b"type"]) -> typing.Optional[typing_extensions.Literal["coordinates"]]: ...
global___DeviceLocation = DeviceLocation
