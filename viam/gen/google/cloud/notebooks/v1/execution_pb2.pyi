"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import google.protobuf.descriptor
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import google.protobuf.timestamp_pb2
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor = ...

class ExecutionTemplate(google.protobuf.message.Message):
    """The description a notebook execution workload."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class _ScaleTier:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _ScaleTierEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_ScaleTier.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        SCALE_TIER_UNSPECIFIED: ExecutionTemplate.ScaleTier.ValueType = ...  # 0
        """Unspecified Scale Tier."""

        BASIC: ExecutionTemplate.ScaleTier.ValueType = ...  # 1
        """A single worker instance. This tier is suitable for learning how to use
        Cloud ML, and for experimenting with new models using small datasets.
        """

        STANDARD_1: ExecutionTemplate.ScaleTier.ValueType = ...  # 2
        """Many workers and a few parameter servers."""

        PREMIUM_1: ExecutionTemplate.ScaleTier.ValueType = ...  # 3
        """A large number of workers with many parameter servers."""

        BASIC_GPU: ExecutionTemplate.ScaleTier.ValueType = ...  # 4
        """A single worker instance with a K80 GPU."""

        BASIC_TPU: ExecutionTemplate.ScaleTier.ValueType = ...  # 5
        """A single worker instance with a Cloud TPU."""

        CUSTOM: ExecutionTemplate.ScaleTier.ValueType = ...  # 6
        """The CUSTOM tier is not a set tier, but rather enables you to use your
        own cluster specification. When you use this tier, set values to
        configure your processing cluster according to these guidelines:

        *   You _must_ set `TrainingInput.masterType` to specify the type
            of machine to use for your master node. This is the only required
            setting.

        *   You _may_ set `TrainingInput.workerCount` to specify the number of
            workers to use. If you specify one or more workers, you _must_ also
            set `TrainingInput.workerType` to specify the type of machine to use
            for your worker nodes.

        *   You _may_ set `TrainingInput.parameterServerCount` to specify the
            number of parameter servers to use. If you specify one or more
            parameter servers, you _must_ also set
            `TrainingInput.parameterServerType` to specify the type of machine to
            use for your parameter servers.

        Note that all of your workers must use the same machine type, which can
        be different from your parameter server type and master type. Your
        parameter servers must likewise use the same machine type, which can be
        different from your worker type and master type.
        """

    class ScaleTier(_ScaleTier, metaclass=_ScaleTierEnumTypeWrapper):
        """Required. Specifies the machine types, the number of replicas for workers
        and parameter servers.
        """
        pass

    SCALE_TIER_UNSPECIFIED: ExecutionTemplate.ScaleTier.ValueType = ...  # 0
    """Unspecified Scale Tier."""

    BASIC: ExecutionTemplate.ScaleTier.ValueType = ...  # 1
    """A single worker instance. This tier is suitable for learning how to use
    Cloud ML, and for experimenting with new models using small datasets.
    """

    STANDARD_1: ExecutionTemplate.ScaleTier.ValueType = ...  # 2
    """Many workers and a few parameter servers."""

    PREMIUM_1: ExecutionTemplate.ScaleTier.ValueType = ...  # 3
    """A large number of workers with many parameter servers."""

    BASIC_GPU: ExecutionTemplate.ScaleTier.ValueType = ...  # 4
    """A single worker instance with a K80 GPU."""

    BASIC_TPU: ExecutionTemplate.ScaleTier.ValueType = ...  # 5
    """A single worker instance with a Cloud TPU."""

    CUSTOM: ExecutionTemplate.ScaleTier.ValueType = ...  # 6
    """The CUSTOM tier is not a set tier, but rather enables you to use your
    own cluster specification. When you use this tier, set values to
    configure your processing cluster according to these guidelines:

    *   You _must_ set `TrainingInput.masterType` to specify the type
        of machine to use for your master node. This is the only required
        setting.

    *   You _may_ set `TrainingInput.workerCount` to specify the number of
        workers to use. If you specify one or more workers, you _must_ also
        set `TrainingInput.workerType` to specify the type of machine to use
        for your worker nodes.

    *   You _may_ set `TrainingInput.parameterServerCount` to specify the
        number of parameter servers to use. If you specify one or more
        parameter servers, you _must_ also set
        `TrainingInput.parameterServerType` to specify the type of machine to
        use for your parameter servers.

    Note that all of your workers must use the same machine type, which can
    be different from your parameter server type and master type. Your
    parameter servers must likewise use the same machine type, which can be
    different from your worker type and master type.
    """


    class _SchedulerAcceleratorType:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _SchedulerAcceleratorTypeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_SchedulerAcceleratorType.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        SCHEDULER_ACCELERATOR_TYPE_UNSPECIFIED: ExecutionTemplate.SchedulerAcceleratorType.ValueType = ...  # 0
        """Unspecified accelerator type. Default to no GPU."""

        NVIDIA_TESLA_K80: ExecutionTemplate.SchedulerAcceleratorType.ValueType = ...  # 1
        """Nvidia Tesla K80 GPU."""

        NVIDIA_TESLA_P100: ExecutionTemplate.SchedulerAcceleratorType.ValueType = ...  # 2
        """Nvidia Tesla P100 GPU."""

        NVIDIA_TESLA_V100: ExecutionTemplate.SchedulerAcceleratorType.ValueType = ...  # 3
        """Nvidia Tesla V100 GPU."""

        NVIDIA_TESLA_P4: ExecutionTemplate.SchedulerAcceleratorType.ValueType = ...  # 4
        """Nvidia Tesla P4 GPU."""

        NVIDIA_TESLA_T4: ExecutionTemplate.SchedulerAcceleratorType.ValueType = ...  # 5
        """Nvidia Tesla T4 GPU."""

        TPU_V2: ExecutionTemplate.SchedulerAcceleratorType.ValueType = ...  # 6
        """TPU v2."""

        TPU_V3: ExecutionTemplate.SchedulerAcceleratorType.ValueType = ...  # 7
        """TPU v3."""

    class SchedulerAcceleratorType(_SchedulerAcceleratorType, metaclass=_SchedulerAcceleratorTypeEnumTypeWrapper):
        """Hardware accelerator types for AI Platform Training jobs."""
        pass

    SCHEDULER_ACCELERATOR_TYPE_UNSPECIFIED: ExecutionTemplate.SchedulerAcceleratorType.ValueType = ...  # 0
    """Unspecified accelerator type. Default to no GPU."""

    NVIDIA_TESLA_K80: ExecutionTemplate.SchedulerAcceleratorType.ValueType = ...  # 1
    """Nvidia Tesla K80 GPU."""

    NVIDIA_TESLA_P100: ExecutionTemplate.SchedulerAcceleratorType.ValueType = ...  # 2
    """Nvidia Tesla P100 GPU."""

    NVIDIA_TESLA_V100: ExecutionTemplate.SchedulerAcceleratorType.ValueType = ...  # 3
    """Nvidia Tesla V100 GPU."""

    NVIDIA_TESLA_P4: ExecutionTemplate.SchedulerAcceleratorType.ValueType = ...  # 4
    """Nvidia Tesla P4 GPU."""

    NVIDIA_TESLA_T4: ExecutionTemplate.SchedulerAcceleratorType.ValueType = ...  # 5
    """Nvidia Tesla T4 GPU."""

    TPU_V2: ExecutionTemplate.SchedulerAcceleratorType.ValueType = ...  # 6
    """TPU v2."""

    TPU_V3: ExecutionTemplate.SchedulerAcceleratorType.ValueType = ...  # 7
    """TPU v3."""


    class _JobType:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _JobTypeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_JobType.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        JOB_TYPE_UNSPECIFIED: ExecutionTemplate.JobType.ValueType = ...  # 0
        """No type specified."""

        VERTEX_AI: ExecutionTemplate.JobType.ValueType = ...  # 1
        """Custom Job in `aiplatform.googleapis.com`.
        Default value for an execution.
        """

        DATAPROC: ExecutionTemplate.JobType.ValueType = ...  # 2
        """Run execution on a cluster with Dataproc as a job.
        https://cloud.google.com/dataproc/docs/reference/rest/v1/projects.regions.jobs
        """

    class JobType(_JobType, metaclass=_JobTypeEnumTypeWrapper):
        """The backend used for this execution."""
        pass

    JOB_TYPE_UNSPECIFIED: ExecutionTemplate.JobType.ValueType = ...  # 0
    """No type specified."""

    VERTEX_AI: ExecutionTemplate.JobType.ValueType = ...  # 1
    """Custom Job in `aiplatform.googleapis.com`.
    Default value for an execution.
    """

    DATAPROC: ExecutionTemplate.JobType.ValueType = ...  # 2
    """Run execution on a cluster with Dataproc as a job.
    https://cloud.google.com/dataproc/docs/reference/rest/v1/projects.regions.jobs
    """


    class SchedulerAcceleratorConfig(google.protobuf.message.Message):
        """Definition of a hardware accelerator. Note that not all combinations
        of `type` and `core_count` are valid. Check GPUs on
        Compute Engine to find a valid
        combination. TPUs are not supported.
        """
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        TYPE_FIELD_NUMBER: builtins.int
        CORE_COUNT_FIELD_NUMBER: builtins.int
        type: global___ExecutionTemplate.SchedulerAcceleratorType.ValueType = ...
        """Type of this accelerator."""

        core_count: builtins.int = ...
        """Count of cores of this accelerator."""

        def __init__(self,
            *,
            type : global___ExecutionTemplate.SchedulerAcceleratorType.ValueType = ...,
            core_count : builtins.int = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["core_count",b"core_count","type",b"type"]) -> None: ...

    class DataprocParameters(google.protobuf.message.Message):
        """Parameters used in Dataproc JobType executions."""
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        CLUSTER_FIELD_NUMBER: builtins.int
        cluster: typing.Text = ...
        """URI for cluster used to run Dataproc execution.
        Format: `projects/{PROJECT_ID}/regions/{REGION}/clusters/{CLUSTER_NAME}`
        """

        def __init__(self,
            *,
            cluster : typing.Text = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["cluster",b"cluster"]) -> None: ...

    class LabelsEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: typing.Text = ...
        value: typing.Text = ...
        def __init__(self,
            *,
            key : typing.Text = ...,
            value : typing.Text = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

    SCALE_TIER_FIELD_NUMBER: builtins.int
    MASTER_TYPE_FIELD_NUMBER: builtins.int
    ACCELERATOR_CONFIG_FIELD_NUMBER: builtins.int
    LABELS_FIELD_NUMBER: builtins.int
    INPUT_NOTEBOOK_FILE_FIELD_NUMBER: builtins.int
    CONTAINER_IMAGE_URI_FIELD_NUMBER: builtins.int
    OUTPUT_NOTEBOOK_FOLDER_FIELD_NUMBER: builtins.int
    PARAMS_YAML_FILE_FIELD_NUMBER: builtins.int
    PARAMETERS_FIELD_NUMBER: builtins.int
    SERVICE_ACCOUNT_FIELD_NUMBER: builtins.int
    JOB_TYPE_FIELD_NUMBER: builtins.int
    DATAPROC_PARAMETERS_FIELD_NUMBER: builtins.int
    scale_tier: global___ExecutionTemplate.ScaleTier.ValueType = ...
    """Required. Scale tier of the hardware used for notebook execution.
    DEPRECATED Will be discontinued. As right now only CUSTOM is supported.
    """

    master_type: typing.Text = ...
    """Specifies the type of virtual machine to use for your training
    job's master worker. You must specify this field when `scaleTier` is set to
    `CUSTOM`.

    You can use certain Compute Engine machine types directly in this field.
    The following types are supported:

    - `n1-standard-4`
    - `n1-standard-8`
    - `n1-standard-16`
    - `n1-standard-32`
    - `n1-standard-64`
    - `n1-standard-96`
    - `n1-highmem-2`
    - `n1-highmem-4`
    - `n1-highmem-8`
    - `n1-highmem-16`
    - `n1-highmem-32`
    - `n1-highmem-64`
    - `n1-highmem-96`
    - `n1-highcpu-16`
    - `n1-highcpu-32`
    - `n1-highcpu-64`
    - `n1-highcpu-96`


    Alternatively, you can use the following legacy machine types:

    - `standard`
    - `large_model`
    - `complex_model_s`
    - `complex_model_m`
    - `complex_model_l`
    - `standard_gpu`
    - `complex_model_m_gpu`
    - `complex_model_l_gpu`
    - `standard_p100`
    - `complex_model_m_p100`
    - `standard_v100`
    - `large_model_v100`
    - `complex_model_m_v100`
    - `complex_model_l_v100`


    Finally, if you want to use a TPU for training, specify `cloud_tpu` in this
    field. Learn more about the [special configuration options for training
    with TPU.
    """

    @property
    def accelerator_config(self) -> global___ExecutionTemplate.SchedulerAcceleratorConfig:
        """Configuration (count and accelerator type) for hardware running notebook
        execution.
        """
        pass
    @property
    def labels(self) -> google.protobuf.internal.containers.ScalarMap[typing.Text, typing.Text]:
        """Labels for execution.
        If execution is scheduled, a field included will be 'nbs-scheduled'.
        Otherwise, it is an immediate execution, and an included field will be
        'nbs-immediate'. Use fields to efficiently index between various types of
        executions.
        """
        pass
    input_notebook_file: typing.Text = ...
    """Path to the notebook file to execute.
    Must be in a Google Cloud Storage bucket.
    Format: `gs://{project_id}/{folder}/{notebook_file_name}`
    Ex: `gs://notebook_user/scheduled_notebooks/sentiment_notebook.ipynb`
    """

    container_image_uri: typing.Text = ...
    """Container Image URI to a DLVM
    Example: 'gcr.io/deeplearning-platform-release/base-cu100'
    More examples can be found at:
    https://cloud.google.com/ai-platform/deep-learning-containers/docs/choosing-container
    """

    output_notebook_folder: typing.Text = ...
    """Path to the notebook folder to write to.
    Must be in a Google Cloud Storage bucket path.
    Format: `gs://{project_id}/{folder}`
    Ex: `gs://notebook_user/scheduled_notebooks`
    """

    params_yaml_file: typing.Text = ...
    """Parameters to be overridden in the notebook during execution.
    Ref https://papermill.readthedocs.io/en/latest/usage-parameterize.html on
    how to specifying parameters in the input notebook and pass them here
    in an YAML file.
    Ex: `gs://notebook_user/scheduled_notebooks/sentiment_notebook_params.yaml`
    """

    parameters: typing.Text = ...
    """Parameters used within the 'input_notebook_file' notebook."""

    service_account: typing.Text = ...
    """The email address of a service account to use when running the execution.
    You must have the `iam.serviceAccounts.actAs` permission for the specified
    service account.
    """

    job_type: global___ExecutionTemplate.JobType.ValueType = ...
    """The type of Job to be used on this execution."""

    @property
    def dataproc_parameters(self) -> global___ExecutionTemplate.DataprocParameters:
        """Parameters used in Dataproc JobType executions."""
        pass
    def __init__(self,
        *,
        scale_tier : global___ExecutionTemplate.ScaleTier.ValueType = ...,
        master_type : typing.Text = ...,
        accelerator_config : typing.Optional[global___ExecutionTemplate.SchedulerAcceleratorConfig] = ...,
        labels : typing.Optional[typing.Mapping[typing.Text, typing.Text]] = ...,
        input_notebook_file : typing.Text = ...,
        container_image_uri : typing.Text = ...,
        output_notebook_folder : typing.Text = ...,
        params_yaml_file : typing.Text = ...,
        parameters : typing.Text = ...,
        service_account : typing.Text = ...,
        job_type : global___ExecutionTemplate.JobType.ValueType = ...,
        dataproc_parameters : typing.Optional[global___ExecutionTemplate.DataprocParameters] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["accelerator_config",b"accelerator_config","dataproc_parameters",b"dataproc_parameters","job_parameters",b"job_parameters"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["accelerator_config",b"accelerator_config","container_image_uri",b"container_image_uri","dataproc_parameters",b"dataproc_parameters","input_notebook_file",b"input_notebook_file","job_parameters",b"job_parameters","job_type",b"job_type","labels",b"labels","master_type",b"master_type","output_notebook_folder",b"output_notebook_folder","parameters",b"parameters","params_yaml_file",b"params_yaml_file","scale_tier",b"scale_tier","service_account",b"service_account"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["job_parameters",b"job_parameters"]) -> typing.Optional[typing_extensions.Literal["dataproc_parameters"]]: ...
global___ExecutionTemplate = ExecutionTemplate

class Execution(google.protobuf.message.Message):
    """The definition of a single executed notebook."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class _State:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _StateEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_State.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        STATE_UNSPECIFIED: Execution.State.ValueType = ...  # 0
        """The job state is unspecified."""

        QUEUED: Execution.State.ValueType = ...  # 1
        """The job has been just created and processing has not yet begun."""

        PREPARING: Execution.State.ValueType = ...  # 2
        """The service is preparing to execution the job."""

        RUNNING: Execution.State.ValueType = ...  # 3
        """The job is in progress."""

        SUCCEEDED: Execution.State.ValueType = ...  # 4
        """The job completed successfully."""

        FAILED: Execution.State.ValueType = ...  # 5
        """The job failed.
        `error_message` should contain the details of the failure.
        """

        CANCELLING: Execution.State.ValueType = ...  # 6
        """The job is being cancelled.
        `error_message` should describe the reason for the cancellation.
        """

        CANCELLED: Execution.State.ValueType = ...  # 7
        """The job has been cancelled.
        `error_message` should describe the reason for the cancellation.
        """

        EXPIRED: Execution.State.ValueType = ...  # 9
        """The jobs has become expired (added for uCAIP jobs)
        https://cloud.google.com/vertex-ai/docs/reference/rest/v1/JobState
        """

        INITIALIZING: Execution.State.ValueType = ...  # 10
        """The Execution is being created."""

    class State(_State, metaclass=_StateEnumTypeWrapper):
        """Enum description of the state of the underlying AIP job."""
        pass

    STATE_UNSPECIFIED: Execution.State.ValueType = ...  # 0
    """The job state is unspecified."""

    QUEUED: Execution.State.ValueType = ...  # 1
    """The job has been just created and processing has not yet begun."""

    PREPARING: Execution.State.ValueType = ...  # 2
    """The service is preparing to execution the job."""

    RUNNING: Execution.State.ValueType = ...  # 3
    """The job is in progress."""

    SUCCEEDED: Execution.State.ValueType = ...  # 4
    """The job completed successfully."""

    FAILED: Execution.State.ValueType = ...  # 5
    """The job failed.
    `error_message` should contain the details of the failure.
    """

    CANCELLING: Execution.State.ValueType = ...  # 6
    """The job is being cancelled.
    `error_message` should describe the reason for the cancellation.
    """

    CANCELLED: Execution.State.ValueType = ...  # 7
    """The job has been cancelled.
    `error_message` should describe the reason for the cancellation.
    """

    EXPIRED: Execution.State.ValueType = ...  # 9
    """The jobs has become expired (added for uCAIP jobs)
    https://cloud.google.com/vertex-ai/docs/reference/rest/v1/JobState
    """

    INITIALIZING: Execution.State.ValueType = ...  # 10
    """The Execution is being created."""


    EXECUTION_TEMPLATE_FIELD_NUMBER: builtins.int
    NAME_FIELD_NUMBER: builtins.int
    DISPLAY_NAME_FIELD_NUMBER: builtins.int
    DESCRIPTION_FIELD_NUMBER: builtins.int
    CREATE_TIME_FIELD_NUMBER: builtins.int
    UPDATE_TIME_FIELD_NUMBER: builtins.int
    STATE_FIELD_NUMBER: builtins.int
    OUTPUT_NOTEBOOK_FILE_FIELD_NUMBER: builtins.int
    JOB_URI_FIELD_NUMBER: builtins.int
    @property
    def execution_template(self) -> global___ExecutionTemplate:
        """execute metadata including name, hardware spec, region, labels, etc."""
        pass
    name: typing.Text = ...
    """Output only. The resource name of the execute. Format:
    `projects/{project_id}/locations/{location}/execution/{execution_id}`
    """

    display_name: typing.Text = ...
    """Output only. Name used for UI purposes.
    Name can only contain alphanumeric characters and underscores '_'.
    """

    description: typing.Text = ...
    """A brief description of this execution."""

    @property
    def create_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Output only. Time the Execution was instantiated."""
        pass
    @property
    def update_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Output only. Time the Execution was last updated."""
        pass
    state: global___Execution.State.ValueType = ...
    """Output only. State of the underlying AI Platform job."""

    output_notebook_file: typing.Text = ...
    """Output notebook file generated by this execution"""

    job_uri: typing.Text = ...
    """Output only. The URI of the external job used to execute the notebook."""

    def __init__(self,
        *,
        execution_template : typing.Optional[global___ExecutionTemplate] = ...,
        name : typing.Text = ...,
        display_name : typing.Text = ...,
        description : typing.Text = ...,
        create_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        update_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        state : global___Execution.State.ValueType = ...,
        output_notebook_file : typing.Text = ...,
        job_uri : typing.Text = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["create_time",b"create_time","execution_template",b"execution_template","update_time",b"update_time"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["create_time",b"create_time","description",b"description","display_name",b"display_name","execution_template",b"execution_template","job_uri",b"job_uri","name",b"name","output_notebook_file",b"output_notebook_file","state",b"state","update_time",b"update_time"]) -> None: ...
global___Execution = Execution
