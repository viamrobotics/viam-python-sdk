"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import google.protobuf.descriptor
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import google.rpc.status_pb2
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor = ...

class TranslateSpeechConfig(google.protobuf.message.Message):
    """Provides information to the speech translation that specifies how to process
    the request.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    AUDIO_ENCODING_FIELD_NUMBER: builtins.int
    SOURCE_LANGUAGE_CODE_FIELD_NUMBER: builtins.int
    TARGET_LANGUAGE_CODE_FIELD_NUMBER: builtins.int
    SAMPLE_RATE_HERTZ_FIELD_NUMBER: builtins.int
    MODEL_FIELD_NUMBER: builtins.int
    audio_encoding: typing.Text = ...
    """Required. Encoding of audio data.
    Supported formats:

    - `linear16`

      Uncompressed 16-bit signed little-endian samples (Linear PCM).

    - `flac`

      `flac` (Free Lossless Audio Codec) is the recommended encoding
      because it is lossless--therefore recognition is not compromised--and
      requires only about half the bandwidth of `linear16`.

    - `mulaw`

      8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.

    - `amr`

      Adaptive Multi-Rate Narrowband codec. `sample_rate_hertz` must be 8000.

    - `amr-wb`

      Adaptive Multi-Rate Wideband codec. `sample_rate_hertz` must be 16000.

    - `ogg-opus`

      Opus encoded audio frames in [Ogg](https://wikipedia.org/wiki/Ogg)
      container. `sample_rate_hertz` must be one of 8000, 12000, 16000, 24000,
      or 48000.

    - `mp3`

      MP3 audio. Support all standard MP3 bitrates (which range from 32-320
      kbps). When using this encoding, `sample_rate_hertz` has to match the
      sample rate of the file being used.
    """

    source_language_code: typing.Text = ...
    """Required. Source language code (BCP-47) of the input audio."""

    target_language_code: typing.Text = ...
    """Required. Target language code (BCP-47) of the output."""

    sample_rate_hertz: builtins.int = ...
    """Optional. Sample rate in Hertz of the audio data. Valid values are:
    8000-48000. 16000 is optimal. For best results, set the sampling rate of
    the audio source to 16000 Hz. If that's not possible, use the native sample
    rate of the audio source (instead of re-sampling).
    """

    model: typing.Text = ...
    """Optional. `google-provided-model/video` and
    `google-provided-model/enhanced-phone-call` are premium models.
    `google-provided-model/phone-call` is not premium model.
    """

    def __init__(self,
        *,
        audio_encoding : typing.Text = ...,
        source_language_code : typing.Text = ...,
        target_language_code : typing.Text = ...,
        sample_rate_hertz : builtins.int = ...,
        model : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["audio_encoding",b"audio_encoding","model",b"model","sample_rate_hertz",b"sample_rate_hertz","source_language_code",b"source_language_code","target_language_code",b"target_language_code"]) -> None: ...
global___TranslateSpeechConfig = TranslateSpeechConfig

class StreamingTranslateSpeechConfig(google.protobuf.message.Message):
    """Config used for streaming translation."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    AUDIO_CONFIG_FIELD_NUMBER: builtins.int
    SINGLE_UTTERANCE_FIELD_NUMBER: builtins.int
    @property
    def audio_config(self) -> global___TranslateSpeechConfig:
        """Required. The common config for all the following audio contents."""
        pass
    single_utterance: builtins.bool = ...
    """Optional. If `false` or omitted, the system performs
    continuous translation (continuing to wait for and process audio even if
    the user pauses speaking) until the client closes the input stream (gRPC
    API) or until the maximum time limit has been reached. May return multiple
    `StreamingTranslateSpeechResult`s with the `is_final` flag set to `true`.

    If `true`, the speech translator will detect a single spoken utterance.
    When it detects that the user has paused or stopped speaking, it will
    return an `END_OF_SINGLE_UTTERANCE` event and cease translation.
    When the client receives 'END_OF_SINGLE_UTTERANCE' event, the client should
    stop sending the requests. However, clients should keep receiving remaining
    responses until the stream is terminated. To construct the complete
    sentence in a streaming way, one should override (if 'is_final' of previous
    response is false), or append (if 'is_final' of previous response is true).
    """

    def __init__(self,
        *,
        audio_config : typing.Optional[global___TranslateSpeechConfig] = ...,
        single_utterance : builtins.bool = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["audio_config",b"audio_config"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["audio_config",b"audio_config","single_utterance",b"single_utterance"]) -> None: ...
global___StreamingTranslateSpeechConfig = StreamingTranslateSpeechConfig

class StreamingTranslateSpeechRequest(google.protobuf.message.Message):
    """The top-level message sent by the client for the `StreamingTranslateSpeech`
    method. Multiple `StreamingTranslateSpeechRequest` messages are sent. The
    first message must contain a `streaming_config` message and must not contain
    `audio_content` data. All subsequent messages must contain `audio_content`
    data and must not contain a `streaming_config` message.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    STREAMING_CONFIG_FIELD_NUMBER: builtins.int
    AUDIO_CONTENT_FIELD_NUMBER: builtins.int
    @property
    def streaming_config(self) -> global___StreamingTranslateSpeechConfig:
        """Provides information to the recognizer that specifies how to process the
        request. The first `StreamingTranslateSpeechRequest` message must contain
        a `streaming_config` message.
        """
        pass
    audio_content: builtins.bytes = ...
    """The audio data to be translated. Sequential chunks of audio data are sent
    in sequential `StreamingTranslateSpeechRequest` messages. The first
    `StreamingTranslateSpeechRequest` message must not contain
    `audio_content` data and all subsequent `StreamingTranslateSpeechRequest`
    messages must contain `audio_content` data. The audio bytes must be
    encoded as specified in `StreamingTranslateSpeechConfig`. Note: as with
    all bytes fields, protobuffers use a pure binary representation (not
    base64).
    """

    def __init__(self,
        *,
        streaming_config : typing.Optional[global___StreamingTranslateSpeechConfig] = ...,
        audio_content : builtins.bytes = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["audio_content",b"audio_content","streaming_config",b"streaming_config","streaming_request",b"streaming_request"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["audio_content",b"audio_content","streaming_config",b"streaming_config","streaming_request",b"streaming_request"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["streaming_request",b"streaming_request"]) -> typing.Optional[typing_extensions.Literal["streaming_config","audio_content"]]: ...
global___StreamingTranslateSpeechRequest = StreamingTranslateSpeechRequest

class StreamingTranslateSpeechResult(google.protobuf.message.Message):
    """A streaming speech translation result corresponding to a portion of the audio
    that is currently being processed.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class TextTranslationResult(google.protobuf.message.Message):
        """Text translation result."""
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        TRANSLATION_FIELD_NUMBER: builtins.int
        IS_FINAL_FIELD_NUMBER: builtins.int
        translation: typing.Text = ...
        """Output only. The translated sentence."""

        is_final: builtins.bool = ...
        """Output only. If `false`, this `StreamingTranslateSpeechResult` represents
        an interim result that may change. If `true`, this is the final time the
        translation service will return this particular
        `StreamingTranslateSpeechResult`, the streaming translator will not
        return any further hypotheses for this portion of the transcript and
        corresponding audio.
        """

        def __init__(self,
            *,
            translation : typing.Text = ...,
            is_final : builtins.bool = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["is_final",b"is_final","translation",b"translation"]) -> None: ...

    TEXT_TRANSLATION_RESULT_FIELD_NUMBER: builtins.int
    @property
    def text_translation_result(self) -> global___StreamingTranslateSpeechResult.TextTranslationResult:
        """Text translation result."""
        pass
    def __init__(self,
        *,
        text_translation_result : typing.Optional[global___StreamingTranslateSpeechResult.TextTranslationResult] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["result",b"result","text_translation_result",b"text_translation_result"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["result",b"result","text_translation_result",b"text_translation_result"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["result",b"result"]) -> typing.Optional[typing_extensions.Literal["text_translation_result"]]: ...
global___StreamingTranslateSpeechResult = StreamingTranslateSpeechResult

class StreamingTranslateSpeechResponse(google.protobuf.message.Message):
    """A streaming speech translation response corresponding to a portion of
    the audio currently processed.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class _SpeechEventType:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _SpeechEventTypeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_SpeechEventType.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        SPEECH_EVENT_TYPE_UNSPECIFIED: StreamingTranslateSpeechResponse.SpeechEventType.ValueType = ...  # 0
        """No speech event specified."""

        END_OF_SINGLE_UTTERANCE: StreamingTranslateSpeechResponse.SpeechEventType.ValueType = ...  # 1
        """This event indicates that the server has detected the end of the user's
        speech utterance and expects no additional speech. Therefore, the server
        will not process additional audio (although it may subsequently return
        additional results). When the client receives 'END_OF_SINGLE_UTTERANCE'
        event, the client should stop sending the requests. However, clients
        should keep receiving remaining responses until the stream is terminated.
        To construct the complete sentence in a streaming way, one should
        override (if 'is_final' of previous response is false), or append (if
        'is_final' of previous response is true). This event is only sent if
        `single_utterance` was set to `true`, and is not used otherwise.
        """

    class SpeechEventType(_SpeechEventType, metaclass=_SpeechEventTypeEnumTypeWrapper):
        """Indicates the type of speech event."""
        pass

    SPEECH_EVENT_TYPE_UNSPECIFIED: StreamingTranslateSpeechResponse.SpeechEventType.ValueType = ...  # 0
    """No speech event specified."""

    END_OF_SINGLE_UTTERANCE: StreamingTranslateSpeechResponse.SpeechEventType.ValueType = ...  # 1
    """This event indicates that the server has detected the end of the user's
    speech utterance and expects no additional speech. Therefore, the server
    will not process additional audio (although it may subsequently return
    additional results). When the client receives 'END_OF_SINGLE_UTTERANCE'
    event, the client should stop sending the requests. However, clients
    should keep receiving remaining responses until the stream is terminated.
    To construct the complete sentence in a streaming way, one should
    override (if 'is_final' of previous response is false), or append (if
    'is_final' of previous response is true). This event is only sent if
    `single_utterance` was set to `true`, and is not used otherwise.
    """


    ERROR_FIELD_NUMBER: builtins.int
    RESULT_FIELD_NUMBER: builtins.int
    SPEECH_EVENT_TYPE_FIELD_NUMBER: builtins.int
    @property
    def error(self) -> google.rpc.status_pb2.Status:
        """Output only. If set, returns a [google.rpc.Status][google.rpc.Status] message that
        specifies the error for the operation.
        """
        pass
    @property
    def result(self) -> global___StreamingTranslateSpeechResult:
        """Output only. The translation result that is currently being processed (is_final could be
        true or false).
        """
        pass
    speech_event_type: global___StreamingTranslateSpeechResponse.SpeechEventType.ValueType = ...
    """Output only. Indicates the type of speech event."""

    def __init__(self,
        *,
        error : typing.Optional[google.rpc.status_pb2.Status] = ...,
        result : typing.Optional[global___StreamingTranslateSpeechResult] = ...,
        speech_event_type : global___StreamingTranslateSpeechResponse.SpeechEventType.ValueType = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["error",b"error","result",b"result"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["error",b"error","result",b"result","speech_event_type",b"speech_event_type"]) -> None: ...
global___StreamingTranslateSpeechResponse = StreamingTranslateSpeechResponse
