"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import google.protobuf.descriptor
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor = ...

class TranslationFileMapping(google.protobuf.message.Message):
    """Mapping between an input and output file to be translated in a subtask."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    INPUT_PATH_FIELD_NUMBER: builtins.int
    OUTPUT_PATH_FIELD_NUMBER: builtins.int
    input_path: typing.Text = ...
    """The Cloud Storage path for a file to translation in a subtask."""

    output_path: typing.Text = ...
    """The Cloud Storage path to write back the corresponding input file to."""

    def __init__(self,
        *,
        input_path : typing.Text = ...,
        output_path : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["input_path",b"input_path","output_path",b"output_path"]) -> None: ...
global___TranslationFileMapping = TranslationFileMapping

class TranslationTaskDetails(google.protobuf.message.Message):
    """The translation task config to capture necessary settings for a translation
    task and subtask.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class _FileEncoding:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _FileEncodingEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_FileEncoding.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        FILE_ENCODING_UNSPECIFIED: TranslationTaskDetails.FileEncoding.ValueType = ...  # 0
        """File encoding setting is not specified."""

        UTF_8: TranslationTaskDetails.FileEncoding.ValueType = ...  # 1
        """File encoding is UTF_8."""

        ISO_8859_1: TranslationTaskDetails.FileEncoding.ValueType = ...  # 2
        """File encoding is ISO_8859_1."""

        US_ASCII: TranslationTaskDetails.FileEncoding.ValueType = ...  # 3
        """File encoding is US_ASCII."""

        UTF_16: TranslationTaskDetails.FileEncoding.ValueType = ...  # 4
        """File encoding is UTF_16."""

        UTF_16LE: TranslationTaskDetails.FileEncoding.ValueType = ...  # 5
        """File encoding is UTF_16LE."""

        UTF_16BE: TranslationTaskDetails.FileEncoding.ValueType = ...  # 6
        """File encoding is UTF_16BE."""

    class FileEncoding(_FileEncoding, metaclass=_FileEncodingEnumTypeWrapper):
        """The file encoding types."""
        pass

    FILE_ENCODING_UNSPECIFIED: TranslationTaskDetails.FileEncoding.ValueType = ...  # 0
    """File encoding setting is not specified."""

    UTF_8: TranslationTaskDetails.FileEncoding.ValueType = ...  # 1
    """File encoding is UTF_8."""

    ISO_8859_1: TranslationTaskDetails.FileEncoding.ValueType = ...  # 2
    """File encoding is ISO_8859_1."""

    US_ASCII: TranslationTaskDetails.FileEncoding.ValueType = ...  # 3
    """File encoding is US_ASCII."""

    UTF_16: TranslationTaskDetails.FileEncoding.ValueType = ...  # 4
    """File encoding is UTF_16."""

    UTF_16LE: TranslationTaskDetails.FileEncoding.ValueType = ...  # 5
    """File encoding is UTF_16LE."""

    UTF_16BE: TranslationTaskDetails.FileEncoding.ValueType = ...  # 6
    """File encoding is UTF_16BE."""


    class _TokenType:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _TokenTypeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_TokenType.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        TOKEN_TYPE_UNSPECIFIED: TranslationTaskDetails.TokenType.ValueType = ...  # 0
        """Token type is not specified."""

        STRING: TranslationTaskDetails.TokenType.ValueType = ...  # 1
        """Token type as string."""

        INT64: TranslationTaskDetails.TokenType.ValueType = ...  # 2
        """Token type as integer."""

        NUMERIC: TranslationTaskDetails.TokenType.ValueType = ...  # 3
        """Token type as numeric."""

        BOOL: TranslationTaskDetails.TokenType.ValueType = ...  # 4
        """Token type as boolean."""

        FLOAT64: TranslationTaskDetails.TokenType.ValueType = ...  # 5
        """Token type as float."""

        DATE: TranslationTaskDetails.TokenType.ValueType = ...  # 6
        """Token type as date."""

        TIMESTAMP: TranslationTaskDetails.TokenType.ValueType = ...  # 7
        """Token type as timestamp."""

    class TokenType(_TokenType, metaclass=_TokenTypeEnumTypeWrapper):
        """The special token data type."""
        pass

    TOKEN_TYPE_UNSPECIFIED: TranslationTaskDetails.TokenType.ValueType = ...  # 0
    """Token type is not specified."""

    STRING: TranslationTaskDetails.TokenType.ValueType = ...  # 1
    """Token type as string."""

    INT64: TranslationTaskDetails.TokenType.ValueType = ...  # 2
    """Token type as integer."""

    NUMERIC: TranslationTaskDetails.TokenType.ValueType = ...  # 3
    """Token type as numeric."""

    BOOL: TranslationTaskDetails.TokenType.ValueType = ...  # 4
    """Token type as boolean."""

    FLOAT64: TranslationTaskDetails.TokenType.ValueType = ...  # 5
    """Token type as float."""

    DATE: TranslationTaskDetails.TokenType.ValueType = ...  # 6
    """Token type as date."""

    TIMESTAMP: TranslationTaskDetails.TokenType.ValueType = ...  # 7
    """Token type as timestamp."""


    class SpecialTokenMapEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: typing.Text = ...
        value: global___TranslationTaskDetails.TokenType.ValueType = ...
        def __init__(self,
            *,
            key : typing.Text = ...,
            value : global___TranslationTaskDetails.TokenType.ValueType = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

    TERADATA_OPTIONS_FIELD_NUMBER: builtins.int
    BTEQ_OPTIONS_FIELD_NUMBER: builtins.int
    INPUT_PATH_FIELD_NUMBER: builtins.int
    OUTPUT_PATH_FIELD_NUMBER: builtins.int
    FILE_PATHS_FIELD_NUMBER: builtins.int
    SCHEMA_PATH_FIELD_NUMBER: builtins.int
    FILE_ENCODING_FIELD_NUMBER: builtins.int
    IDENTIFIER_SETTINGS_FIELD_NUMBER: builtins.int
    SPECIAL_TOKEN_MAP_FIELD_NUMBER: builtins.int
    FILTER_FIELD_NUMBER: builtins.int
    TRANSLATION_EXCEPTION_TABLE_FIELD_NUMBER: builtins.int
    @property
    def teradata_options(self) -> global___TeradataOptions:
        """The Teradata SQL specific settings for the translation task."""
        pass
    @property
    def bteq_options(self) -> global___BteqOptions:
        """The BTEQ specific settings for the translation task."""
        pass
    input_path: typing.Text = ...
    """The Cloud Storage path for translation input files."""

    output_path: typing.Text = ...
    """The Cloud Storage path for translation output files."""

    @property
    def file_paths(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___TranslationFileMapping]:
        """Cloud Storage files to be processed for translation."""
        pass
    schema_path: typing.Text = ...
    """The Cloud Storage path to DDL files as table schema to assist semantic
    translation.
    """

    file_encoding: global___TranslationTaskDetails.FileEncoding.ValueType = ...
    """The file encoding type."""

    @property
    def identifier_settings(self) -> global___IdentifierSettings:
        """The settings for SQL identifiers."""
        pass
    @property
    def special_token_map(self) -> google.protobuf.internal.containers.ScalarMap[typing.Text, global___TranslationTaskDetails.TokenType.ValueType]:
        """The map capturing special tokens to be replaced during translation. The key
        is special token in string. The value is the token data type. This is used
        to translate SQL query template which contains special token as place
        holder. The special token makes a query invalid to parse. This map will be
        applied to annotate those special token with types to let parser understand
        how to parse them into proper structure with type information.
        """
        pass
    @property
    def filter(self) -> global___Filter:
        """The filter applied to translation details."""
        pass
    translation_exception_table: typing.Text = ...
    """Specifies the exact name of the bigquery table ("dataset.table") to be used
    for surfacing raw translation errors. If the table does not exist, we will
    create it. If it already exists and the schema is the same, we will re-use.
    If the table exists and the schema is different, we will throw an error.
    """

    def __init__(self,
        *,
        teradata_options : typing.Optional[global___TeradataOptions] = ...,
        bteq_options : typing.Optional[global___BteqOptions] = ...,
        input_path : typing.Text = ...,
        output_path : typing.Text = ...,
        file_paths : typing.Optional[typing.Iterable[global___TranslationFileMapping]] = ...,
        schema_path : typing.Text = ...,
        file_encoding : global___TranslationTaskDetails.FileEncoding.ValueType = ...,
        identifier_settings : typing.Optional[global___IdentifierSettings] = ...,
        special_token_map : typing.Optional[typing.Mapping[typing.Text, global___TranslationTaskDetails.TokenType.ValueType]] = ...,
        filter : typing.Optional[global___Filter] = ...,
        translation_exception_table : typing.Text = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["bteq_options",b"bteq_options","filter",b"filter","identifier_settings",b"identifier_settings","language_options",b"language_options","teradata_options",b"teradata_options"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["bteq_options",b"bteq_options","file_encoding",b"file_encoding","file_paths",b"file_paths","filter",b"filter","identifier_settings",b"identifier_settings","input_path",b"input_path","language_options",b"language_options","output_path",b"output_path","schema_path",b"schema_path","special_token_map",b"special_token_map","teradata_options",b"teradata_options","translation_exception_table",b"translation_exception_table"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["language_options",b"language_options"]) -> typing.Optional[typing_extensions.Literal["teradata_options","bteq_options"]]: ...
global___TranslationTaskDetails = TranslationTaskDetails

class Filter(google.protobuf.message.Message):
    """The filter applied to fields of translation details."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    INPUT_FILE_EXCLUSION_PREFIXES_FIELD_NUMBER: builtins.int
    @property
    def input_file_exclusion_prefixes(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
        """The list of prefixes used to exclude processing for input files."""
        pass
    def __init__(self,
        *,
        input_file_exclusion_prefixes : typing.Optional[typing.Iterable[typing.Text]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["input_file_exclusion_prefixes",b"input_file_exclusion_prefixes"]) -> None: ...
global___Filter = Filter

class IdentifierSettings(google.protobuf.message.Message):
    """Settings related to SQL identifiers."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class _IdentifierCase:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _IdentifierCaseEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_IdentifierCase.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        IDENTIFIER_CASE_UNSPECIFIED: IdentifierSettings.IdentifierCase.ValueType = ...  # 0
        """The identifier case is not specified."""

        ORIGINAL: IdentifierSettings.IdentifierCase.ValueType = ...  # 1
        """Identifiers' cases will be kept as the original cases."""

        UPPER: IdentifierSettings.IdentifierCase.ValueType = ...  # 2
        """Identifiers will be in upper cases."""

        LOWER: IdentifierSettings.IdentifierCase.ValueType = ...  # 3
        """Identifiers will be in lower cases."""

    class IdentifierCase(_IdentifierCase, metaclass=_IdentifierCaseEnumTypeWrapper):
        """The identifier case type."""
        pass

    IDENTIFIER_CASE_UNSPECIFIED: IdentifierSettings.IdentifierCase.ValueType = ...  # 0
    """The identifier case is not specified."""

    ORIGINAL: IdentifierSettings.IdentifierCase.ValueType = ...  # 1
    """Identifiers' cases will be kept as the original cases."""

    UPPER: IdentifierSettings.IdentifierCase.ValueType = ...  # 2
    """Identifiers will be in upper cases."""

    LOWER: IdentifierSettings.IdentifierCase.ValueType = ...  # 3
    """Identifiers will be in lower cases."""


    class _IdentifierRewriteMode:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _IdentifierRewriteModeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_IdentifierRewriteMode.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        IDENTIFIER_REWRITE_MODE_UNSPECIFIED: IdentifierSettings.IdentifierRewriteMode.ValueType = ...  # 0
        """SQL Identifier rewrite mode is unspecified."""

        NONE: IdentifierSettings.IdentifierRewriteMode.ValueType = ...  # 1
        """SQL identifiers won't be rewrite."""

        REWRITE_ALL: IdentifierSettings.IdentifierRewriteMode.ValueType = ...  # 2
        """All SQL identifiers will be rewrite."""

    class IdentifierRewriteMode(_IdentifierRewriteMode, metaclass=_IdentifierRewriteModeEnumTypeWrapper):
        """The SQL identifier rewrite mode."""
        pass

    IDENTIFIER_REWRITE_MODE_UNSPECIFIED: IdentifierSettings.IdentifierRewriteMode.ValueType = ...  # 0
    """SQL Identifier rewrite mode is unspecified."""

    NONE: IdentifierSettings.IdentifierRewriteMode.ValueType = ...  # 1
    """SQL identifiers won't be rewrite."""

    REWRITE_ALL: IdentifierSettings.IdentifierRewriteMode.ValueType = ...  # 2
    """All SQL identifiers will be rewrite."""


    OUTPUT_IDENTIFIER_CASE_FIELD_NUMBER: builtins.int
    IDENTIFIER_REWRITE_MODE_FIELD_NUMBER: builtins.int
    output_identifier_case: global___IdentifierSettings.IdentifierCase.ValueType = ...
    """The setting to control output queries' identifier case."""

    identifier_rewrite_mode: global___IdentifierSettings.IdentifierRewriteMode.ValueType = ...
    """Specifies the rewrite mode for SQL identifiers."""

    def __init__(self,
        *,
        output_identifier_case : global___IdentifierSettings.IdentifierCase.ValueType = ...,
        identifier_rewrite_mode : global___IdentifierSettings.IdentifierRewriteMode.ValueType = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["identifier_rewrite_mode",b"identifier_rewrite_mode","output_identifier_case",b"output_identifier_case"]) -> None: ...
global___IdentifierSettings = IdentifierSettings

class TeradataOptions(google.protobuf.message.Message):
    """Teradata SQL specific translation task related settings."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    def __init__(self,
        ) -> None: ...
global___TeradataOptions = TeradataOptions

class BteqOptions(google.protobuf.message.Message):
    """BTEQ translation task related settings."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class FileReplacementMapEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: typing.Text = ...
        value: typing.Text = ...
        def __init__(self,
            *,
            key : typing.Text = ...,
            value : typing.Text = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

    PROJECT_DATASET_FIELD_NUMBER: builtins.int
    DEFAULT_PATH_URI_FIELD_NUMBER: builtins.int
    FILE_REPLACEMENT_MAP_FIELD_NUMBER: builtins.int
    @property
    def project_dataset(self) -> global___DatasetReference:
        """Specifies the project and dataset in BigQuery that will be used for
        external table creation during the translation.
        """
        pass
    default_path_uri: typing.Text = ...
    """The Cloud Storage location to be used as the default path for files that
    are not otherwise specified in the file replacement map.
    """

    @property
    def file_replacement_map(self) -> google.protobuf.internal.containers.ScalarMap[typing.Text, typing.Text]:
        """Maps the local paths that are used in BTEQ scripts (the keys) to the paths
        in Cloud Storage that should be used in their stead in the translation (the
        value).
        """
        pass
    def __init__(self,
        *,
        project_dataset : typing.Optional[global___DatasetReference] = ...,
        default_path_uri : typing.Text = ...,
        file_replacement_map : typing.Optional[typing.Mapping[typing.Text, typing.Text]] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["project_dataset",b"project_dataset"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["default_path_uri",b"default_path_uri","file_replacement_map",b"file_replacement_map","project_dataset",b"project_dataset"]) -> None: ...
global___BteqOptions = BteqOptions

class DatasetReference(google.protobuf.message.Message):
    """Reference to a BigQuery dataset."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    DATASET_ID_FIELD_NUMBER: builtins.int
    PROJECT_ID_FIELD_NUMBER: builtins.int
    dataset_id: typing.Text = ...
    """A unique ID for this dataset, without the project name. The ID
    must contain only letters (a-z, A-Z), numbers (0-9), or underscores (_).
    The maximum length is 1,024 characters.
    """

    project_id: typing.Text = ...
    """The ID of the project containing this dataset."""

    def __init__(self,
        *,
        dataset_id : typing.Text = ...,
        project_id : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["dataset_id",b"dataset_id","project_id",b"project_id"]) -> None: ...
global___DatasetReference = DatasetReference
