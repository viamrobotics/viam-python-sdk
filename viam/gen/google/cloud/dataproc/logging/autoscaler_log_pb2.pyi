"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import google.protobuf.descriptor
import google.protobuf.duration_pb2
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor = ...

class _AutoscalerState:
    ValueType = typing.NewType('ValueType', builtins.int)
    V: typing_extensions.TypeAlias = ValueType
class _AutoscalerStateEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_AutoscalerState.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
    AUTOSCALER_STATE_UNSPECIFIED: AutoscalerState.ValueType = ...  # 0
    COOLDOWN: AutoscalerState.ValueType = ...  # 1
    """The Autoscaler is sleeping and waiting for the next update."""

    RECOMMENDING: AutoscalerState.ValueType = ...  # 6
    """The Autoscaler is in the process of calculating its recommendation on
    whether to scale the cluster, and if so, how to autoscale.
    """

    SCALING: AutoscalerState.ValueType = ...  # 2
    """The Autoscaler is scaling the cluster."""

    STOPPED: AutoscalerState.ValueType = ...  # 3
    """The Autoscaler has stopped."""

    FAILED: AutoscalerState.ValueType = ...  # 4
    """The Autoscaler has failed."""

    INITIALIZING: AutoscalerState.ValueType = ...  # 5
    """The Autoscaler is initializing."""

class AutoscalerState(_AutoscalerState, metaclass=_AutoscalerStateEnumTypeWrapper):
    """The Autoscaler state."""
    pass

AUTOSCALER_STATE_UNSPECIFIED: AutoscalerState.ValueType = ...  # 0
COOLDOWN: AutoscalerState.ValueType = ...  # 1
"""The Autoscaler is sleeping and waiting for the next update."""

RECOMMENDING: AutoscalerState.ValueType = ...  # 6
"""The Autoscaler is in the process of calculating its recommendation on
whether to scale the cluster, and if so, how to autoscale.
"""

SCALING: AutoscalerState.ValueType = ...  # 2
"""The Autoscaler is scaling the cluster."""

STOPPED: AutoscalerState.ValueType = ...  # 3
"""The Autoscaler has stopped."""

FAILED: AutoscalerState.ValueType = ...  # 4
"""The Autoscaler has failed."""

INITIALIZING: AutoscalerState.ValueType = ...  # 5
"""The Autoscaler is initializing."""

global___AutoscalerState = AutoscalerState


class _ScalingDecisionType:
    ValueType = typing.NewType('ValueType', builtins.int)
    V: typing_extensions.TypeAlias = ValueType
class _ScalingDecisionTypeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_ScalingDecisionType.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
    SCALING_DECISION_TYPE_UNSPECIFIED: ScalingDecisionType.ValueType = ...  # 0
    SCALE_UP: ScalingDecisionType.ValueType = ...  # 1
    """Increase the number of primary and/or secondary workers."""

    SCALE_DOWN: ScalingDecisionType.ValueType = ...  # 2
    """Decrease the number of primary and/or secondary workers."""

    NO_SCALE: ScalingDecisionType.ValueType = ...  # 3
    """Not changing the number of primary or secondary workers."""

    MIXED: ScalingDecisionType.ValueType = ...  # 4
    """Scale the primary and secondary worker groups in different directions."""

class ScalingDecisionType(_ScalingDecisionType, metaclass=_ScalingDecisionTypeEnumTypeWrapper):
    """The Autoscaling decision type."""
    pass

SCALING_DECISION_TYPE_UNSPECIFIED: ScalingDecisionType.ValueType = ...  # 0
SCALE_UP: ScalingDecisionType.ValueType = ...  # 1
"""Increase the number of primary and/or secondary workers."""

SCALE_DOWN: ScalingDecisionType.ValueType = ...  # 2
"""Decrease the number of primary and/or secondary workers."""

NO_SCALE: ScalingDecisionType.ValueType = ...  # 3
"""Not changing the number of primary or secondary workers."""

MIXED: ScalingDecisionType.ValueType = ...  # 4
"""Scale the primary and secondary worker groups in different directions."""

global___ScalingDecisionType = ScalingDecisionType


class _ConstrainingFactor:
    ValueType = typing.NewType('ValueType', builtins.int)
    V: typing_extensions.TypeAlias = ValueType
class _ConstrainingFactorEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_ConstrainingFactor.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
    CONSTRAINING_FACTOR_UNSPECIFIED: ConstrainingFactor.ValueType = ...  # 0
    SCALING_CAPPED_DUE_TO_LACK_OF_QUOTA: ConstrainingFactor.ValueType = ...  # 1
    """The project does not have sufficient regional, global, and or preemptible
    quota to allocate a new VM.
    """

    REACHED_MAXIMUM_CLUSTER_SIZE: ConstrainingFactor.ValueType = ...  # 2
    """All worker groups have reached maximum size. This message will not be
    issued if one group reached maximum size, but workers were able to be
    allocated to another group.
    """

    REACHED_MINIMUM_CLUSTER_SIZE: ConstrainingFactor.ValueType = ...  # 3
    """All worker groups have reached minimum size. This message will not be
    issued if workers were able to be removed from another group that had not
    reached minimum size.
    """

class ConstrainingFactor(_ConstrainingFactor, metaclass=_ConstrainingFactorEnumTypeWrapper):
    pass

CONSTRAINING_FACTOR_UNSPECIFIED: ConstrainingFactor.ValueType = ...  # 0
SCALING_CAPPED_DUE_TO_LACK_OF_QUOTA: ConstrainingFactor.ValueType = ...  # 1
"""The project does not have sufficient regional, global, and or preemptible
quota to allocate a new VM.
"""

REACHED_MAXIMUM_CLUSTER_SIZE: ConstrainingFactor.ValueType = ...  # 2
"""All worker groups have reached maximum size. This message will not be
issued if one group reached maximum size, but workers were able to be
allocated to another group.
"""

REACHED_MINIMUM_CLUSTER_SIZE: ConstrainingFactor.ValueType = ...  # 3
"""All worker groups have reached minimum size. This message will not be
issued if workers were able to be removed from another group that had not
reached minimum size.
"""

global___ConstrainingFactor = ConstrainingFactor


class ClusterSize(google.protobuf.message.Message):
    """The short version of cluster configuration for Cloud logging."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    PRIMARY_WORKER_COUNT_FIELD_NUMBER: builtins.int
    SECONDARY_WORKER_COUNT_FIELD_NUMBER: builtins.int
    primary_worker_count: builtins.int = ...
    """The number of primary workers in the cluster."""

    secondary_worker_count: builtins.int = ...
    """The number of secondary workers in the cluster."""

    def __init__(self,
        *,
        primary_worker_count : builtins.int = ...,
        secondary_worker_count : builtins.int = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["primary_worker_count",b"primary_worker_count","secondary_worker_count",b"secondary_worker_count"]) -> None: ...
global___ClusterSize = ClusterSize

class AutoscalerLog(google.protobuf.message.Message):
    """The main proto that will be converted to JSON format and then written to
    Logging.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    STATUS_FIELD_NUMBER: builtins.int
    RECOMMENDATION_FIELD_NUMBER: builtins.int
    @property
    def status(self) -> global___AutoscalerStatus:
        """The current Autoscaler status."""
        pass
    @property
    def recommendation(self) -> global___AutoscalerRecommendation:
        """Optional. The autoscaling recommendation including its inputs, outputs,
        scaling decision, and detailed explanation.
        """
        pass
    def __init__(self,
        *,
        status : typing.Optional[global___AutoscalerStatus] = ...,
        recommendation : typing.Optional[global___AutoscalerRecommendation] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["recommendation",b"recommendation","status",b"status"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["recommendation",b"recommendation","status",b"status"]) -> None: ...
global___AutoscalerLog = AutoscalerLog

class AutoscalerStatus(google.protobuf.message.Message):
    """The Autoscaler's status, including its state and other details."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    STATE_FIELD_NUMBER: builtins.int
    DETAILS_FIELD_NUMBER: builtins.int
    UPDATE_CLUSTER_OPERATION_ID_FIELD_NUMBER: builtins.int
    ERROR_FIELD_NUMBER: builtins.int
    state: global___AutoscalerState.ValueType = ...
    """The high-level Autoscaler state."""

    details: typing.Text = ...
    """The detailed description of Autoscaler status."""

    update_cluster_operation_id: typing.Text = ...
    """The cluster update operation ID."""

    error: typing.Text = ...
    """Error message from an Autoscaler exception, if any."""

    def __init__(self,
        *,
        state : global___AutoscalerState.ValueType = ...,
        details : typing.Text = ...,
        update_cluster_operation_id : typing.Text = ...,
        error : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["details",b"details","error",b"error","state",b"state","update_cluster_operation_id",b"update_cluster_operation_id"]) -> None: ...
global___AutoscalerStatus = AutoscalerStatus

class AutoscalerRecommendation(google.protobuf.message.Message):
    """The inputs, outputs, and detailed explanation of the Autoscaling
    recommendation.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class Inputs(google.protobuf.message.Message):
        """The input values for the Autoscaling recommendation alogirthm."""
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        class ClusterMetricsEntry(google.protobuf.message.Message):
            DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
            KEY_FIELD_NUMBER: builtins.int
            VALUE_FIELD_NUMBER: builtins.int
            key: typing.Text = ...
            value: typing.Text = ...
            def __init__(self,
                *,
                key : typing.Text = ...,
                value : typing.Text = ...,
                ) -> None: ...
            def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

        CLUSTER_METRICS_FIELD_NUMBER: builtins.int
        CURRENT_CLUSTER_SIZE_FIELD_NUMBER: builtins.int
        MIN_WORKER_COUNTS_FIELD_NUMBER: builtins.int
        MAX_WORKER_COUNTS_FIELD_NUMBER: builtins.int
        @property
        def cluster_metrics(self) -> google.protobuf.internal.containers.ScalarMap[typing.Text, typing.Text]:
            """The metrics collected by the Dataproc agent running on the cluster.
            For example, {"avg-yarn-pending-memory": "1040 MB"}
            """
            pass
        @property
        def current_cluster_size(self) -> global___ClusterSize:
            """The cluster configuration before updating the cluster."""
            pass
        @property
        def min_worker_counts(self) -> global___ClusterSize:
            """The minimum worker counts for each instance group."""
            pass
        @property
        def max_worker_counts(self) -> global___ClusterSize:
            """The maximum worker counts for each instance group."""
            pass
        def __init__(self,
            *,
            cluster_metrics : typing.Optional[typing.Mapping[typing.Text, typing.Text]] = ...,
            current_cluster_size : typing.Optional[global___ClusterSize] = ...,
            min_worker_counts : typing.Optional[global___ClusterSize] = ...,
            max_worker_counts : typing.Optional[global___ClusterSize] = ...,
            ) -> None: ...
        def HasField(self, field_name: typing_extensions.Literal["current_cluster_size",b"current_cluster_size","max_worker_counts",b"max_worker_counts","min_worker_counts",b"min_worker_counts"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing_extensions.Literal["cluster_metrics",b"cluster_metrics","current_cluster_size",b"current_cluster_size","max_worker_counts",b"max_worker_counts","min_worker_counts",b"min_worker_counts"]) -> None: ...

    class Outputs(google.protobuf.message.Message):
        """Autoscaler recommendations."""
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        DECISION_FIELD_NUMBER: builtins.int
        RECOMMENDED_CLUSTER_SIZE_FIELD_NUMBER: builtins.int
        GRACEFUL_DECOMMISSION_TIMEOUT_FIELD_NUMBER: builtins.int
        CONSTRAINTS_REACHED_FIELD_NUMBER: builtins.int
        ADDITIONAL_RECOMMENDATION_DETAILS_FIELD_NUMBER: builtins.int
        RECOMMENDATION_ID_FIELD_NUMBER: builtins.int
        decision: global___ScalingDecisionType.ValueType = ...
        """The high-level autoscaling decision, such as SCALE_UP, SCALE_DOWN,
        NO_OP.
        """

        @property
        def recommended_cluster_size(self) -> global___ClusterSize:
            """The recommended cluster size."""
            pass
        @property
        def graceful_decommission_timeout(self) -> google.protobuf.duration_pb2.Duration:
            """The graceful decommission timeout for downscaling operations."""
            pass
        @property
        def constraints_reached(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[global___ConstrainingFactor.ValueType]:
            """Reasons why the Autoscaler didn't add or remove more workers."""
            pass
        @property
        def additional_recommendation_details(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
            """Less significant recommendations that are not included in the
            `AutoscalerStatus.details` message.
            """
            pass
        recommendation_id: typing.Text = ...
        """A unique id for this recommendation that should be included when opening
        a support ticket.
        """

        def __init__(self,
            *,
            decision : global___ScalingDecisionType.ValueType = ...,
            recommended_cluster_size : typing.Optional[global___ClusterSize] = ...,
            graceful_decommission_timeout : typing.Optional[google.protobuf.duration_pb2.Duration] = ...,
            constraints_reached : typing.Optional[typing.Iterable[global___ConstrainingFactor.ValueType]] = ...,
            additional_recommendation_details : typing.Optional[typing.Iterable[typing.Text]] = ...,
            recommendation_id : typing.Text = ...,
            ) -> None: ...
        def HasField(self, field_name: typing_extensions.Literal["graceful_decommission_timeout",b"graceful_decommission_timeout","recommended_cluster_size",b"recommended_cluster_size"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing_extensions.Literal["additional_recommendation_details",b"additional_recommendation_details","constraints_reached",b"constraints_reached","decision",b"decision","graceful_decommission_timeout",b"graceful_decommission_timeout","recommendation_id",b"recommendation_id","recommended_cluster_size",b"recommended_cluster_size"]) -> None: ...

    INPUTS_FIELD_NUMBER: builtins.int
    OUTPUTS_FIELD_NUMBER: builtins.int
    @property
    def inputs(self) -> global___AutoscalerRecommendation.Inputs:
        """The autoscaling algorithm inputs."""
        pass
    @property
    def outputs(self) -> global___AutoscalerRecommendation.Outputs:
        """The algorithm outputs for the recommended cluster size."""
        pass
    def __init__(self,
        *,
        inputs : typing.Optional[global___AutoscalerRecommendation.Inputs] = ...,
        outputs : typing.Optional[global___AutoscalerRecommendation.Outputs] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["inputs",b"inputs","outputs",b"outputs"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["inputs",b"inputs","outputs",b"outputs"]) -> None: ...
global___AutoscalerRecommendation = AutoscalerRecommendation
