"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import google.cloud.aiplatform.v1beta1.explanation_metadata_pb2
import google.cloud.aiplatform.v1beta1.io_pb2
import google.protobuf.descriptor
import google.protobuf.internal.containers
import google.protobuf.message
import google.protobuf.struct_pb2
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor = ...

class Explanation(google.protobuf.message.Message):
    """Explanation of a prediction (provided in [PredictResponse.predictions][google.cloud.aiplatform.v1beta1.PredictResponse.predictions])
    produced by the Model on a given [instance][google.cloud.aiplatform.v1beta1.ExplainRequest.instances].
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    ATTRIBUTIONS_FIELD_NUMBER: builtins.int
    @property
    def attributions(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Attribution]:
        """Output only. Feature attributions grouped by predicted outputs.

        For Models that predict only one output, such as regression Models that
        predict only one score, there is only one attibution that explains the
        predicted output. For Models that predict multiple outputs, such as
        multiclass Models that predict multiple classes, each element explains one
        specific item. [Attribution.output_index][google.cloud.aiplatform.v1beta1.Attribution.output_index] can be used to identify which
        output this attribution is explaining.

        If users set [ExplanationParameters.top_k][google.cloud.aiplatform.v1beta1.ExplanationParameters.top_k], the attributions are sorted
        by [instance_output_value][Attributions.instance_output_value] in
        descending order. If [ExplanationParameters.output_indices][google.cloud.aiplatform.v1beta1.ExplanationParameters.output_indices] is specified,
        the attributions are stored by [Attribution.output_index][google.cloud.aiplatform.v1beta1.Attribution.output_index] in the same
        order as they appear in the output_indices.
        """
        pass
    def __init__(self,
        *,
        attributions : typing.Optional[typing.Iterable[global___Attribution]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["attributions",b"attributions"]) -> None: ...
global___Explanation = Explanation

class ModelExplanation(google.protobuf.message.Message):
    """Aggregated explanation metrics for a Model over a set of instances."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    MEAN_ATTRIBUTIONS_FIELD_NUMBER: builtins.int
    @property
    def mean_attributions(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Attribution]:
        """Output only. Aggregated attributions explaining the Model's prediction outputs over the
        set of instances. The attributions are grouped by outputs.

        For Models that predict only one output, such as regression Models that
        predict only one score, there is only one attibution that explains the
        predicted output. For Models that predict multiple outputs, such as
        multiclass Models that predict multiple classes, each element explains one
        specific item. [Attribution.output_index][google.cloud.aiplatform.v1beta1.Attribution.output_index] can be used to identify which
        output this attribution is explaining.

        The [baselineOutputValue][google.cloud.aiplatform.v1beta1.Attribution.baseline_output_value],
        [instanceOutputValue][google.cloud.aiplatform.v1beta1.Attribution.instance_output_value] and
        [featureAttributions][google.cloud.aiplatform.v1beta1.Attribution.feature_attributions] fields are
        averaged over the test data.

        NOTE: Currently AutoML tabular classification Models produce only one
        attribution, which averages attributions over all the classes it predicts.
        [Attribution.approximation_error][google.cloud.aiplatform.v1beta1.Attribution.approximation_error] is not populated.
        """
        pass
    def __init__(self,
        *,
        mean_attributions : typing.Optional[typing.Iterable[global___Attribution]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["mean_attributions",b"mean_attributions"]) -> None: ...
global___ModelExplanation = ModelExplanation

class Attribution(google.protobuf.message.Message):
    """Attribution that explains a particular prediction output."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    BASELINE_OUTPUT_VALUE_FIELD_NUMBER: builtins.int
    INSTANCE_OUTPUT_VALUE_FIELD_NUMBER: builtins.int
    FEATURE_ATTRIBUTIONS_FIELD_NUMBER: builtins.int
    OUTPUT_INDEX_FIELD_NUMBER: builtins.int
    OUTPUT_DISPLAY_NAME_FIELD_NUMBER: builtins.int
    APPROXIMATION_ERROR_FIELD_NUMBER: builtins.int
    OUTPUT_NAME_FIELD_NUMBER: builtins.int
    baseline_output_value: builtins.float = ...
    """Output only. Model predicted output if the input instance is constructed from the
    baselines of all the features defined in [ExplanationMetadata.inputs][google.cloud.aiplatform.v1beta1.ExplanationMetadata.inputs].
    The field name of the output is determined by the key in
    [ExplanationMetadata.outputs][google.cloud.aiplatform.v1beta1.ExplanationMetadata.outputs].

    If the Model's predicted output has multiple dimensions (rank > 1), this is
    the value in the output located by [output_index][google.cloud.aiplatform.v1beta1.Attribution.output_index].

    If there are multiple baselines, their output values are averaged.
    """

    instance_output_value: builtins.float = ...
    """Output only. Model predicted output on the corresponding [explanation
    instance][ExplainRequest.instances]. The field name of the output is
    determined by the key in [ExplanationMetadata.outputs][google.cloud.aiplatform.v1beta1.ExplanationMetadata.outputs].

    If the Model predicted output has multiple dimensions, this is the value in
    the output located by [output_index][google.cloud.aiplatform.v1beta1.Attribution.output_index].
    """

    @property
    def feature_attributions(self) -> google.protobuf.struct_pb2.Value:
        """Output only. Attributions of each explained feature. Features are extracted from
        the [prediction instances][google.cloud.aiplatform.v1beta1.ExplainRequest.instances] according to
        [explanation metadata for inputs][google.cloud.aiplatform.v1beta1.ExplanationMetadata.inputs].

        The value is a struct, whose keys are the name of the feature. The values
        are how much the feature in the [instance][google.cloud.aiplatform.v1beta1.ExplainRequest.instances]
        contributed to the predicted result.

        The format of the value is determined by the feature's input format:

          * If the feature is a scalar value, the attribution value is a
            [floating number][google.protobuf.Value.number_value].

          * If the feature is an array of scalar values, the attribution value is
            an [array][google.protobuf.Value.list_value].

          * If the feature is a struct, the attribution value is a
            [struct][google.protobuf.Value.struct_value]. The keys in the
            attribution value struct are the same as the keys in the feature
            struct. The formats of the values in the attribution struct are
            determined by the formats of the values in the feature struct.

        The [ExplanationMetadata.feature_attributions_schema_uri][google.cloud.aiplatform.v1beta1.ExplanationMetadata.feature_attributions_schema_uri] field,
        pointed to by the [ExplanationSpec][google.cloud.aiplatform.v1beta1.ExplanationSpec] field of the
        [Endpoint.deployed_models][google.cloud.aiplatform.v1beta1.Endpoint.deployed_models] object, points to the schema file that
        describes the features and their attribution values (if it is populated).
        """
        pass
    @property
    def output_index(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.int]:
        """Output only. The index that locates the explained prediction output.

        If the prediction output is a scalar value, output_index is not populated.
        If the prediction output has multiple dimensions, the length of the
        output_index list is the same as the number of dimensions of the output.
        The i-th element in output_index is the element index of the i-th dimension
        of the output vector. Indices start from 0.
        """
        pass
    output_display_name: typing.Text = ...
    """Output only. The display name of the output identified by [output_index][google.cloud.aiplatform.v1beta1.Attribution.output_index]. For example,
    the predicted class name by a multi-classification Model.

    This field is only populated iff the Model predicts display names as a
    separate field along with the explained output. The predicted display name
    must has the same shape of the explained output, and can be located using
    output_index.
    """

    approximation_error: builtins.float = ...
    """Output only. Error of [feature_attributions][google.cloud.aiplatform.v1beta1.Attribution.feature_attributions] caused by approximation used in the
    explanation method. Lower value means more precise attributions.

    * For Sampled Shapley
    [attribution][google.cloud.aiplatform.v1beta1.ExplanationParameters.sampled_shapley_attribution],
    increasing [path_count][google.cloud.aiplatform.v1beta1.SampledShapleyAttribution.path_count] might reduce
    the error.
    * For Integrated Gradients
    [attribution][google.cloud.aiplatform.v1beta1.ExplanationParameters.integrated_gradients_attribution],
    increasing [step_count][google.cloud.aiplatform.v1beta1.IntegratedGradientsAttribution.step_count] might
    reduce the error.
    * For [XRAI attribution][google.cloud.aiplatform.v1beta1.ExplanationParameters.xrai_attribution],
    increasing
    [step_count][google.cloud.aiplatform.v1beta1.XraiAttribution.step_count] might reduce the error.

    See [this introduction](/vertex-ai/docs/explainable-ai/overview)
    for more information.
    """

    output_name: typing.Text = ...
    """Output only. Name of the explain output. Specified as the key in
    [ExplanationMetadata.outputs][google.cloud.aiplatform.v1beta1.ExplanationMetadata.outputs].
    """

    def __init__(self,
        *,
        baseline_output_value : builtins.float = ...,
        instance_output_value : builtins.float = ...,
        feature_attributions : typing.Optional[google.protobuf.struct_pb2.Value] = ...,
        output_index : typing.Optional[typing.Iterable[builtins.int]] = ...,
        output_display_name : typing.Text = ...,
        approximation_error : builtins.float = ...,
        output_name : typing.Text = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["feature_attributions",b"feature_attributions"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["approximation_error",b"approximation_error","baseline_output_value",b"baseline_output_value","feature_attributions",b"feature_attributions","instance_output_value",b"instance_output_value","output_display_name",b"output_display_name","output_index",b"output_index","output_name",b"output_name"]) -> None: ...
global___Attribution = Attribution

class ExplanationSpec(google.protobuf.message.Message):
    """Specification of Model explanation."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    PARAMETERS_FIELD_NUMBER: builtins.int
    METADATA_FIELD_NUMBER: builtins.int
    @property
    def parameters(self) -> global___ExplanationParameters:
        """Required. Parameters that configure explaining of the Model's predictions."""
        pass
    @property
    def metadata(self) -> google.cloud.aiplatform.v1beta1.explanation_metadata_pb2.ExplanationMetadata:
        """Required. Metadata describing the Model's input and output for explanation."""
        pass
    def __init__(self,
        *,
        parameters : typing.Optional[global___ExplanationParameters] = ...,
        metadata : typing.Optional[google.cloud.aiplatform.v1beta1.explanation_metadata_pb2.ExplanationMetadata] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["metadata",b"metadata","parameters",b"parameters"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["metadata",b"metadata","parameters",b"parameters"]) -> None: ...
global___ExplanationSpec = ExplanationSpec

class ExplanationParameters(google.protobuf.message.Message):
    """Parameters to configure explaining for Model's predictions."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    SAMPLED_SHAPLEY_ATTRIBUTION_FIELD_NUMBER: builtins.int
    INTEGRATED_GRADIENTS_ATTRIBUTION_FIELD_NUMBER: builtins.int
    XRAI_ATTRIBUTION_FIELD_NUMBER: builtins.int
    SIMILARITY_FIELD_NUMBER: builtins.int
    TOP_K_FIELD_NUMBER: builtins.int
    OUTPUT_INDICES_FIELD_NUMBER: builtins.int
    @property
    def sampled_shapley_attribution(self) -> global___SampledShapleyAttribution:
        """An attribution method that approximates Shapley values for features that
        contribute to the label being predicted. A sampling strategy is used to
        approximate the value rather than considering all subsets of features.
        Refer to this paper for model details: https://arxiv.org/abs/1306.4265.
        """
        pass
    @property
    def integrated_gradients_attribution(self) -> global___IntegratedGradientsAttribution:
        """An attribution method that computes Aumann-Shapley values taking
        advantage of the model's fully differentiable structure. Refer to this
        paper for more details: https://arxiv.org/abs/1703.01365
        """
        pass
    @property
    def xrai_attribution(self) -> global___XraiAttribution:
        """An attribution method that redistributes Integrated Gradients
        attribution to segmented regions, taking advantage of the model's fully
        differentiable structure. Refer to this paper for
        more details: https://arxiv.org/abs/1906.02825

        XRAI currently performs better on natural images, like a picture of a
        house or an animal. If the images are taken in artificial environments,
        like a lab or manufacturing line, or from diagnostic equipment, like
        x-rays or quality-control cameras, use Integrated Gradients instead.
        """
        pass
    @property
    def similarity(self) -> global___Similarity:
        """Similarity explainability that returns the nearest neighbors from the
        provided dataset.
        """
        pass
    top_k: builtins.int = ...
    """If populated, returns attributions for top K indices of outputs
    (defaults to 1). Only applies to Models that predicts more than one outputs
    (e,g, multi-class Models). When set to -1, returns explanations for all
    outputs.
    """

    @property
    def output_indices(self) -> google.protobuf.struct_pb2.ListValue:
        """If populated, only returns attributions that have
        [output_index][google.cloud.aiplatform.v1beta1.Attribution.output_index] contained in output_indices. It
        must be an ndarray of integers, with the same shape of the output it's
        explaining.

        If not populated, returns attributions for [top_k][google.cloud.aiplatform.v1beta1.ExplanationParameters.top_k] indices of outputs.
        If neither top_k nor output_indeices is populated, returns the argmax
        index of the outputs.

        Only applicable to Models that predict multiple outputs (e,g, multi-class
        Models that predict multiple classes).
        """
        pass
    def __init__(self,
        *,
        sampled_shapley_attribution : typing.Optional[global___SampledShapleyAttribution] = ...,
        integrated_gradients_attribution : typing.Optional[global___IntegratedGradientsAttribution] = ...,
        xrai_attribution : typing.Optional[global___XraiAttribution] = ...,
        similarity : typing.Optional[global___Similarity] = ...,
        top_k : builtins.int = ...,
        output_indices : typing.Optional[google.protobuf.struct_pb2.ListValue] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["integrated_gradients_attribution",b"integrated_gradients_attribution","method",b"method","output_indices",b"output_indices","sampled_shapley_attribution",b"sampled_shapley_attribution","similarity",b"similarity","xrai_attribution",b"xrai_attribution"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["integrated_gradients_attribution",b"integrated_gradients_attribution","method",b"method","output_indices",b"output_indices","sampled_shapley_attribution",b"sampled_shapley_attribution","similarity",b"similarity","top_k",b"top_k","xrai_attribution",b"xrai_attribution"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["method",b"method"]) -> typing.Optional[typing_extensions.Literal["sampled_shapley_attribution","integrated_gradients_attribution","xrai_attribution","similarity"]]: ...
global___ExplanationParameters = ExplanationParameters

class SampledShapleyAttribution(google.protobuf.message.Message):
    """An attribution method that approximates Shapley values for features that
    contribute to the label being predicted. A sampling strategy is used to
    approximate the value rather than considering all subsets of features.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    PATH_COUNT_FIELD_NUMBER: builtins.int
    path_count: builtins.int = ...
    """Required. The number of feature permutations to consider when approximating the
    Shapley values.

    Valid range of its value is [1, 50], inclusively.
    """

    def __init__(self,
        *,
        path_count : builtins.int = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["path_count",b"path_count"]) -> None: ...
global___SampledShapleyAttribution = SampledShapleyAttribution

class IntegratedGradientsAttribution(google.protobuf.message.Message):
    """An attribution method that computes the Aumann-Shapley value taking advantage
    of the model's fully differentiable structure. Refer to this paper for
    more details: https://arxiv.org/abs/1703.01365
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    STEP_COUNT_FIELD_NUMBER: builtins.int
    SMOOTH_GRAD_CONFIG_FIELD_NUMBER: builtins.int
    BLUR_BASELINE_CONFIG_FIELD_NUMBER: builtins.int
    step_count: builtins.int = ...
    """Required. The number of steps for approximating the path integral.
    A good value to start is 50 and gradually increase until the
    sum to diff property is within the desired error range.

    Valid range of its value is [1, 100], inclusively.
    """

    @property
    def smooth_grad_config(self) -> global___SmoothGradConfig:
        """Config for SmoothGrad approximation of gradients.

        When enabled, the gradients are approximated by averaging the gradients
        from noisy samples in the vicinity of the inputs. Adding
        noise can help improve the computed gradients. Refer to this paper for more
        details: https://arxiv.org/pdf/1706.03825.pdf
        """
        pass
    @property
    def blur_baseline_config(self) -> global___BlurBaselineConfig:
        """Config for IG with blur baseline.

        When enabled, a linear path from the maximally blurred image to the input
        image is created. Using a blurred baseline instead of zero (black image) is
        motivated by the BlurIG approach explained here:
        https://arxiv.org/abs/2004.03383
        """
        pass
    def __init__(self,
        *,
        step_count : builtins.int = ...,
        smooth_grad_config : typing.Optional[global___SmoothGradConfig] = ...,
        blur_baseline_config : typing.Optional[global___BlurBaselineConfig] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["blur_baseline_config",b"blur_baseline_config","smooth_grad_config",b"smooth_grad_config"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["blur_baseline_config",b"blur_baseline_config","smooth_grad_config",b"smooth_grad_config","step_count",b"step_count"]) -> None: ...
global___IntegratedGradientsAttribution = IntegratedGradientsAttribution

class XraiAttribution(google.protobuf.message.Message):
    """An explanation method that redistributes Integrated Gradients
    attributions to segmented regions, taking advantage of the model's fully
    differentiable structure. Refer to this paper for more details:
    https://arxiv.org/abs/1906.02825

    Supported only by image Models.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    STEP_COUNT_FIELD_NUMBER: builtins.int
    SMOOTH_GRAD_CONFIG_FIELD_NUMBER: builtins.int
    BLUR_BASELINE_CONFIG_FIELD_NUMBER: builtins.int
    step_count: builtins.int = ...
    """Required. The number of steps for approximating the path integral.
    A good value to start is 50 and gradually increase until the
    sum to diff property is met within the desired error range.

    Valid range of its value is [1, 100], inclusively.
    """

    @property
    def smooth_grad_config(self) -> global___SmoothGradConfig:
        """Config for SmoothGrad approximation of gradients.

        When enabled, the gradients are approximated by averaging the gradients
        from noisy samples in the vicinity of the inputs. Adding
        noise can help improve the computed gradients. Refer to this paper for more
        details: https://arxiv.org/pdf/1706.03825.pdf
        """
        pass
    @property
    def blur_baseline_config(self) -> global___BlurBaselineConfig:
        """Config for XRAI with blur baseline.

        When enabled, a linear path from the maximally blurred image to the input
        image is created. Using a blurred baseline instead of zero (black image) is
        motivated by the BlurIG approach explained here:
        https://arxiv.org/abs/2004.03383
        """
        pass
    def __init__(self,
        *,
        step_count : builtins.int = ...,
        smooth_grad_config : typing.Optional[global___SmoothGradConfig] = ...,
        blur_baseline_config : typing.Optional[global___BlurBaselineConfig] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["blur_baseline_config",b"blur_baseline_config","smooth_grad_config",b"smooth_grad_config"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["blur_baseline_config",b"blur_baseline_config","smooth_grad_config",b"smooth_grad_config","step_count",b"step_count"]) -> None: ...
global___XraiAttribution = XraiAttribution

class SmoothGradConfig(google.protobuf.message.Message):
    """Config for SmoothGrad approximation of gradients.

    When enabled, the gradients are approximated by averaging the gradients from
    noisy samples in the vicinity of the inputs. Adding noise can help improve
    the computed gradients. Refer to this paper for more details:
    https://arxiv.org/pdf/1706.03825.pdf
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    NOISE_SIGMA_FIELD_NUMBER: builtins.int
    FEATURE_NOISE_SIGMA_FIELD_NUMBER: builtins.int
    NOISY_SAMPLE_COUNT_FIELD_NUMBER: builtins.int
    noise_sigma: builtins.float = ...
    """This is a single float value and will be used to add noise to all the
    features. Use this field when all features are normalized to have the
    same distribution: scale to range [0, 1], [-1, 1] or z-scoring, where
    features are normalized to have 0-mean and 1-variance. Learn more about
    [normalization](https://developers.google.com/machine-learning/data-prep/transform/normalization).

    For best results the recommended value is about 10% - 20% of the standard
    deviation of the input feature. Refer to section 3.2 of the SmoothGrad
    paper: https://arxiv.org/pdf/1706.03825.pdf. Defaults to 0.1.

    If the distribution is different per feature, set
    [feature_noise_sigma][google.cloud.aiplatform.v1beta1.SmoothGradConfig.feature_noise_sigma] instead
    for each feature.
    """

    @property
    def feature_noise_sigma(self) -> global___FeatureNoiseSigma:
        """This is similar to [noise_sigma][google.cloud.aiplatform.v1beta1.SmoothGradConfig.noise_sigma], but
        provides additional flexibility. A separate noise sigma can be provided
        for each feature, which is useful if their distributions are different.
        No noise is added to features that are not set. If this field is unset,
        [noise_sigma][google.cloud.aiplatform.v1beta1.SmoothGradConfig.noise_sigma] will be used for all
        features.
        """
        pass
    noisy_sample_count: builtins.int = ...
    """The number of gradient samples to use for
    approximation. The higher this number, the more accurate the gradient
    is, but the runtime complexity increases by this factor as well.
    Valid range of its value is [1, 50]. Defaults to 3.
    """

    def __init__(self,
        *,
        noise_sigma : builtins.float = ...,
        feature_noise_sigma : typing.Optional[global___FeatureNoiseSigma] = ...,
        noisy_sample_count : builtins.int = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["GradientNoiseSigma",b"GradientNoiseSigma","feature_noise_sigma",b"feature_noise_sigma","noise_sigma",b"noise_sigma"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["GradientNoiseSigma",b"GradientNoiseSigma","feature_noise_sigma",b"feature_noise_sigma","noise_sigma",b"noise_sigma","noisy_sample_count",b"noisy_sample_count"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["GradientNoiseSigma",b"GradientNoiseSigma"]) -> typing.Optional[typing_extensions.Literal["noise_sigma","feature_noise_sigma"]]: ...
global___SmoothGradConfig = SmoothGradConfig

class FeatureNoiseSigma(google.protobuf.message.Message):
    """Noise sigma by features. Noise sigma represents the standard deviation of the
    gaussian kernel that will be used to add noise to interpolated inputs prior
    to computing gradients.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class NoiseSigmaForFeature(google.protobuf.message.Message):
        """Noise sigma for a single feature."""
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        NAME_FIELD_NUMBER: builtins.int
        SIGMA_FIELD_NUMBER: builtins.int
        name: typing.Text = ...
        """The name of the input feature for which noise sigma is provided. The
        features are defined in
        [explanation metadata inputs][google.cloud.aiplatform.v1beta1.ExplanationMetadata.inputs].
        """

        sigma: builtins.float = ...
        """This represents the standard deviation of the Gaussian kernel that will
        be used to add noise to the feature prior to computing gradients. Similar
        to [noise_sigma][google.cloud.aiplatform.v1beta1.SmoothGradConfig.noise_sigma] but represents the
        noise added to the current feature. Defaults to 0.1.
        """

        def __init__(self,
            *,
            name : typing.Text = ...,
            sigma : builtins.float = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["name",b"name","sigma",b"sigma"]) -> None: ...

    NOISE_SIGMA_FIELD_NUMBER: builtins.int
    @property
    def noise_sigma(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___FeatureNoiseSigma.NoiseSigmaForFeature]:
        """Noise sigma per feature. No noise is added to features that are not set."""
        pass
    def __init__(self,
        *,
        noise_sigma : typing.Optional[typing.Iterable[global___FeatureNoiseSigma.NoiseSigmaForFeature]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["noise_sigma",b"noise_sigma"]) -> None: ...
global___FeatureNoiseSigma = FeatureNoiseSigma

class BlurBaselineConfig(google.protobuf.message.Message):
    """Config for blur baseline.

    When enabled, a linear path from the maximally blurred image to the input
    image is created. Using a blurred baseline instead of zero (black image) is
    motivated by the BlurIG approach explained here:
    https://arxiv.org/abs/2004.03383
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    MAX_BLUR_SIGMA_FIELD_NUMBER: builtins.int
    max_blur_sigma: builtins.float = ...
    """The standard deviation of the blur kernel for the blurred baseline. The
    same blurring parameter is used for both the height and the width
    dimension. If not set, the method defaults to the zero (i.e. black for
    images) baseline.
    """

    def __init__(self,
        *,
        max_blur_sigma : builtins.float = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["max_blur_sigma",b"max_blur_sigma"]) -> None: ...
global___BlurBaselineConfig = BlurBaselineConfig

class Similarity(google.protobuf.message.Message):
    """Similarity explainability that returns the nearest neighbors from the
    provided dataset.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    GCS_SOURCE_FIELD_NUMBER: builtins.int
    NEAREST_NEIGHBOR_SEARCH_CONFIG_FIELD_NUMBER: builtins.int
    @property
    def gcs_source(self) -> google.cloud.aiplatform.v1beta1.io_pb2.GcsSource:
        """The Cloud Storage location for the input instances."""
        pass
    @property
    def nearest_neighbor_search_config(self) -> google.protobuf.struct_pb2.Value:
        """The configuration for the generated index, the semantics are the same as
        [metadata][google.cloud.aiplatform.v1beta1.Index.metadata] and should match NearestNeighborSearchConfig.
        """
        pass
    def __init__(self,
        *,
        gcs_source : typing.Optional[google.cloud.aiplatform.v1beta1.io_pb2.GcsSource] = ...,
        nearest_neighbor_search_config : typing.Optional[google.protobuf.struct_pb2.Value] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["gcs_source",b"gcs_source","nearest_neighbor_search_config",b"nearest_neighbor_search_config"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["gcs_source",b"gcs_source","nearest_neighbor_search_config",b"nearest_neighbor_search_config"]) -> None: ...
global___Similarity = Similarity

class ExplanationSpecOverride(google.protobuf.message.Message):
    """The [ExplanationSpec][google.cloud.aiplatform.v1beta1.ExplanationSpec] entries that can be overridden at
    [online explanation][google.cloud.aiplatform.v1beta1.PredictionService.Explain] time.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    PARAMETERS_FIELD_NUMBER: builtins.int
    METADATA_FIELD_NUMBER: builtins.int
    @property
    def parameters(self) -> global___ExplanationParameters:
        """The parameters to be overridden. Note that the
        [method][google.cloud.aiplatform.v1beta1.ExplanationParameters.method] cannot be changed. If not specified,
        no parameter is overridden.
        """
        pass
    @property
    def metadata(self) -> global___ExplanationMetadataOverride:
        """The metadata to be overridden. If not specified, no metadata is overridden."""
        pass
    def __init__(self,
        *,
        parameters : typing.Optional[global___ExplanationParameters] = ...,
        metadata : typing.Optional[global___ExplanationMetadataOverride] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["metadata",b"metadata","parameters",b"parameters"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["metadata",b"metadata","parameters",b"parameters"]) -> None: ...
global___ExplanationSpecOverride = ExplanationSpecOverride

class ExplanationMetadataOverride(google.protobuf.message.Message):
    """The [ExplanationMetadata][google.cloud.aiplatform.v1beta1.ExplanationMetadata] entries that can be overridden at
    [online explanation][google.cloud.aiplatform.v1beta1.PredictionService.Explain] time.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class InputMetadataOverride(google.protobuf.message.Message):
        """The [input metadata][google.cloud.aiplatform.v1beta1.ExplanationMetadata.InputMetadata] entries to be
        overridden.
        """
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        INPUT_BASELINES_FIELD_NUMBER: builtins.int
        @property
        def input_baselines(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[google.protobuf.struct_pb2.Value]:
            """Baseline inputs for this feature.

            This overrides the `input_baseline` field of the
            [ExplanationMetadata.InputMetadata][google.cloud.aiplatform.v1beta1.ExplanationMetadata.InputMetadata]
            object of the corresponding feature's input metadata. If it's not
            specified, the original baselines are not overridden.
            """
            pass
        def __init__(self,
            *,
            input_baselines : typing.Optional[typing.Iterable[google.protobuf.struct_pb2.Value]] = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["input_baselines",b"input_baselines"]) -> None: ...

    class InputsEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: typing.Text = ...
        @property
        def value(self) -> global___ExplanationMetadataOverride.InputMetadataOverride: ...
        def __init__(self,
            *,
            key : typing.Text = ...,
            value : typing.Optional[global___ExplanationMetadataOverride.InputMetadataOverride] = ...,
            ) -> None: ...
        def HasField(self, field_name: typing_extensions.Literal["value",b"value"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

    INPUTS_FIELD_NUMBER: builtins.int
    @property
    def inputs(self) -> google.protobuf.internal.containers.MessageMap[typing.Text, global___ExplanationMetadataOverride.InputMetadataOverride]:
        """Required. Overrides the [input metadata][google.cloud.aiplatform.v1beta1.ExplanationMetadata.inputs] of the features.
        The key is the name of the feature to be overridden. The keys specified
        here must exist in the input metadata to be overridden. If a feature is
        not specified here, the corresponding feature's input metadata is not
        overridden.
        """
        pass
    def __init__(self,
        *,
        inputs : typing.Optional[typing.Mapping[typing.Text, global___ExplanationMetadataOverride.InputMetadataOverride]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["inputs",b"inputs"]) -> None: ...
global___ExplanationMetadataOverride = ExplanationMetadataOverride
