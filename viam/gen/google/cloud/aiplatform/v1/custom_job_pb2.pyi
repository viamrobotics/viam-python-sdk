"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import google.cloud.aiplatform.v1.encryption_spec_pb2
import google.cloud.aiplatform.v1.env_var_pb2
import google.cloud.aiplatform.v1.io_pb2
import google.cloud.aiplatform.v1.job_state_pb2
import google.cloud.aiplatform.v1.machine_resources_pb2
import google.protobuf.descriptor
import google.protobuf.duration_pb2
import google.protobuf.internal.containers
import google.protobuf.message
import google.protobuf.timestamp_pb2
import google.rpc.status_pb2
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor = ...

class CustomJob(google.protobuf.message.Message):
    """Represents a job that runs custom workloads such as a Docker container or a
    Python package. A CustomJob can have multiple worker pools and each worker
    pool can have its own machine and input spec. A CustomJob will be cleaned up
    once the job enters terminal state (failed or succeeded).
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class LabelsEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: typing.Text = ...
        value: typing.Text = ...
        def __init__(self,
            *,
            key : typing.Text = ...,
            value : typing.Text = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

    class WebAccessUrisEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: typing.Text = ...
        value: typing.Text = ...
        def __init__(self,
            *,
            key : typing.Text = ...,
            value : typing.Text = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

    NAME_FIELD_NUMBER: builtins.int
    DISPLAY_NAME_FIELD_NUMBER: builtins.int
    JOB_SPEC_FIELD_NUMBER: builtins.int
    STATE_FIELD_NUMBER: builtins.int
    CREATE_TIME_FIELD_NUMBER: builtins.int
    START_TIME_FIELD_NUMBER: builtins.int
    END_TIME_FIELD_NUMBER: builtins.int
    UPDATE_TIME_FIELD_NUMBER: builtins.int
    ERROR_FIELD_NUMBER: builtins.int
    LABELS_FIELD_NUMBER: builtins.int
    ENCRYPTION_SPEC_FIELD_NUMBER: builtins.int
    WEB_ACCESS_URIS_FIELD_NUMBER: builtins.int
    name: typing.Text = ...
    """Output only. Resource name of a CustomJob."""

    display_name: typing.Text = ...
    """Required. The display name of the CustomJob.
    The name can be up to 128 characters long and can be consist of any UTF-8
    characters.
    """

    @property
    def job_spec(self) -> global___CustomJobSpec:
        """Required. Job spec."""
        pass
    state: google.cloud.aiplatform.v1.job_state_pb2.JobState.ValueType = ...
    """Output only. The detailed state of the job."""

    @property
    def create_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Output only. Time when the CustomJob was created."""
        pass
    @property
    def start_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Output only. Time when the CustomJob for the first time entered the
        `JOB_STATE_RUNNING` state.
        """
        pass
    @property
    def end_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Output only. Time when the CustomJob entered any of the following states:
        `JOB_STATE_SUCCEEDED`, `JOB_STATE_FAILED`, `JOB_STATE_CANCELLED`.
        """
        pass
    @property
    def update_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Output only. Time when the CustomJob was most recently updated."""
        pass
    @property
    def error(self) -> google.rpc.status_pb2.Status:
        """Output only. Only populated when job's state is `JOB_STATE_FAILED` or
        `JOB_STATE_CANCELLED`.
        """
        pass
    @property
    def labels(self) -> google.protobuf.internal.containers.ScalarMap[typing.Text, typing.Text]:
        """The labels with user-defined metadata to organize CustomJobs.

        Label keys and values can be no longer than 64 characters
        (Unicode codepoints), can only contain lowercase letters, numeric
        characters, underscores and dashes. International characters are allowed.

        See https://goo.gl/xmQnxf for more information and examples of labels.
        """
        pass
    @property
    def encryption_spec(self) -> google.cloud.aiplatform.v1.encryption_spec_pb2.EncryptionSpec:
        """Customer-managed encryption key options for a CustomJob. If this is set,
        then all resources created by the CustomJob will be encrypted with the
        provided encryption key.
        """
        pass
    @property
    def web_access_uris(self) -> google.protobuf.internal.containers.ScalarMap[typing.Text, typing.Text]:
        """Output only. URIs for accessing [interactive
        shells](https://cloud.google.com/vertex-ai/docs/training/monitor-debug-interactive-shell)
        (one URI for each training node). Only available if
        [job_spec.enable_web_access][google.cloud.aiplatform.v1.CustomJobSpec.enable_web_access] is `true`.

        The keys are names of each node in the training job; for example,
        `workerpool0-0` for the primary node, `workerpool1-0` for the first node in
        the second worker pool, and `workerpool1-1` for the second node in the
        second worker pool.

        The values are the URIs for each node's interactive shell.
        """
        pass
    def __init__(self,
        *,
        name : typing.Text = ...,
        display_name : typing.Text = ...,
        job_spec : typing.Optional[global___CustomJobSpec] = ...,
        state : google.cloud.aiplatform.v1.job_state_pb2.JobState.ValueType = ...,
        create_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        start_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        end_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        update_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        error : typing.Optional[google.rpc.status_pb2.Status] = ...,
        labels : typing.Optional[typing.Mapping[typing.Text, typing.Text]] = ...,
        encryption_spec : typing.Optional[google.cloud.aiplatform.v1.encryption_spec_pb2.EncryptionSpec] = ...,
        web_access_uris : typing.Optional[typing.Mapping[typing.Text, typing.Text]] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["create_time",b"create_time","encryption_spec",b"encryption_spec","end_time",b"end_time","error",b"error","job_spec",b"job_spec","start_time",b"start_time","update_time",b"update_time"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["create_time",b"create_time","display_name",b"display_name","encryption_spec",b"encryption_spec","end_time",b"end_time","error",b"error","job_spec",b"job_spec","labels",b"labels","name",b"name","start_time",b"start_time","state",b"state","update_time",b"update_time","web_access_uris",b"web_access_uris"]) -> None: ...
global___CustomJob = CustomJob

class CustomJobSpec(google.protobuf.message.Message):
    """Represents the spec of a CustomJob."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    WORKER_POOL_SPECS_FIELD_NUMBER: builtins.int
    SCHEDULING_FIELD_NUMBER: builtins.int
    SERVICE_ACCOUNT_FIELD_NUMBER: builtins.int
    NETWORK_FIELD_NUMBER: builtins.int
    BASE_OUTPUT_DIRECTORY_FIELD_NUMBER: builtins.int
    TENSORBOARD_FIELD_NUMBER: builtins.int
    ENABLE_WEB_ACCESS_FIELD_NUMBER: builtins.int
    @property
    def worker_pool_specs(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___WorkerPoolSpec]:
        """Required. The spec of the worker pools including machine type and Docker image.
        All worker pools except the first one are optional and can be skipped by
        providing an empty value.
        """
        pass
    @property
    def scheduling(self) -> global___Scheduling:
        """Scheduling options for a CustomJob."""
        pass
    service_account: typing.Text = ...
    """Specifies the service account for workload run-as account.
    Users submitting jobs must have act-as permission on this run-as account.
    If unspecified, the [Vertex AI Custom Code Service
    Agent](https://cloud.google.com/vertex-ai/docs/general/access-control#service-agents)
    for the CustomJob's project is used.
    """

    network: typing.Text = ...
    """The full name of the Compute Engine
    [network](/compute/docs/networks-and-firewalls#networks) to which the Job
    should be peered. For example, `projects/12345/global/networks/myVPC`.
    [Format](/compute/docs/reference/rest/v1/networks/insert)
    is of the form `projects/{project}/global/networks/{network}`.
    Where {project} is a project number, as in `12345`, and {network} is a
    network name.

    To specify this field, you must have already [configured VPC Network
    Peering for Vertex
    AI](https://cloud.google.com/vertex-ai/docs/general/vpc-peering).

    If this field is left unspecified, the job is not peered with any network.
    """

    @property
    def base_output_directory(self) -> google.cloud.aiplatform.v1.io_pb2.GcsDestination:
        """The Cloud Storage location to store the output of this CustomJob or
        HyperparameterTuningJob. For HyperparameterTuningJob,
        the baseOutputDirectory of
        each child CustomJob backing a Trial is set to a subdirectory of name
        [id][google.cloud.aiplatform.v1.Trial.id] under its parent HyperparameterTuningJob's
        baseOutputDirectory.

        The following Vertex AI environment variables will be passed to
        containers or python modules when this field is set:

          For CustomJob:

          * AIP_MODEL_DIR = `<base_output_directory>/model/`
          * AIP_CHECKPOINT_DIR = `<base_output_directory>/checkpoints/`
          * AIP_TENSORBOARD_LOG_DIR = `<base_output_directory>/logs/`

          For CustomJob backing a Trial of HyperparameterTuningJob:

          * AIP_MODEL_DIR = `<base_output_directory>/<trial_id>/model/`
          * AIP_CHECKPOINT_DIR = `<base_output_directory>/<trial_id>/checkpoints/`
          * AIP_TENSORBOARD_LOG_DIR = `<base_output_directory>/<trial_id>/logs/`
        """
        pass
    tensorboard: typing.Text = ...
    """Optional. The name of a Vertex AI [Tensorboard][google.cloud.aiplatform.v1.Tensorboard] resource to which this CustomJob
    will upload Tensorboard logs.
    Format:
    `projects/{project}/locations/{location}/tensorboards/{tensorboard}`
    """

    enable_web_access: builtins.bool = ...
    """Optional. Whether you want Vertex AI to enable [interactive shell
    access](https://cloud.google.com/vertex-ai/docs/training/monitor-debug-interactive-shell)
    to training containers.

    If set to `true`, you can access interactive shells at the URIs given
    by [CustomJob.web_access_uris][google.cloud.aiplatform.v1.CustomJob.web_access_uris] or [Trial.web_access_uris][google.cloud.aiplatform.v1.Trial.web_access_uris] (within
    [HyperparameterTuningJob.trials][google.cloud.aiplatform.v1.HyperparameterTuningJob.trials]).
    """

    def __init__(self,
        *,
        worker_pool_specs : typing.Optional[typing.Iterable[global___WorkerPoolSpec]] = ...,
        scheduling : typing.Optional[global___Scheduling] = ...,
        service_account : typing.Text = ...,
        network : typing.Text = ...,
        base_output_directory : typing.Optional[google.cloud.aiplatform.v1.io_pb2.GcsDestination] = ...,
        tensorboard : typing.Text = ...,
        enable_web_access : builtins.bool = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["base_output_directory",b"base_output_directory","scheduling",b"scheduling"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["base_output_directory",b"base_output_directory","enable_web_access",b"enable_web_access","network",b"network","scheduling",b"scheduling","service_account",b"service_account","tensorboard",b"tensorboard","worker_pool_specs",b"worker_pool_specs"]) -> None: ...
global___CustomJobSpec = CustomJobSpec

class WorkerPoolSpec(google.protobuf.message.Message):
    """Represents the spec of a worker pool in a job."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    CONTAINER_SPEC_FIELD_NUMBER: builtins.int
    PYTHON_PACKAGE_SPEC_FIELD_NUMBER: builtins.int
    MACHINE_SPEC_FIELD_NUMBER: builtins.int
    REPLICA_COUNT_FIELD_NUMBER: builtins.int
    DISK_SPEC_FIELD_NUMBER: builtins.int
    @property
    def container_spec(self) -> global___ContainerSpec:
        """The custom container task."""
        pass
    @property
    def python_package_spec(self) -> global___PythonPackageSpec:
        """The Python packaged task."""
        pass
    @property
    def machine_spec(self) -> google.cloud.aiplatform.v1.machine_resources_pb2.MachineSpec:
        """Optional. Immutable. The specification of a single machine."""
        pass
    replica_count: builtins.int = ...
    """Optional. The number of worker replicas to use for this worker pool."""

    @property
    def disk_spec(self) -> google.cloud.aiplatform.v1.machine_resources_pb2.DiskSpec:
        """Disk spec."""
        pass
    def __init__(self,
        *,
        container_spec : typing.Optional[global___ContainerSpec] = ...,
        python_package_spec : typing.Optional[global___PythonPackageSpec] = ...,
        machine_spec : typing.Optional[google.cloud.aiplatform.v1.machine_resources_pb2.MachineSpec] = ...,
        replica_count : builtins.int = ...,
        disk_spec : typing.Optional[google.cloud.aiplatform.v1.machine_resources_pb2.DiskSpec] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["container_spec",b"container_spec","disk_spec",b"disk_spec","machine_spec",b"machine_spec","python_package_spec",b"python_package_spec","task",b"task"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["container_spec",b"container_spec","disk_spec",b"disk_spec","machine_spec",b"machine_spec","python_package_spec",b"python_package_spec","replica_count",b"replica_count","task",b"task"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["task",b"task"]) -> typing.Optional[typing_extensions.Literal["container_spec","python_package_spec"]]: ...
global___WorkerPoolSpec = WorkerPoolSpec

class ContainerSpec(google.protobuf.message.Message):
    """The spec of a Container."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    IMAGE_URI_FIELD_NUMBER: builtins.int
    COMMAND_FIELD_NUMBER: builtins.int
    ARGS_FIELD_NUMBER: builtins.int
    ENV_FIELD_NUMBER: builtins.int
    image_uri: typing.Text = ...
    """Required. The URI of a container image in the Container Registry that is to be run on
    each worker replica.
    """

    @property
    def command(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
        """The command to be invoked when the container is started.
        It overrides the entrypoint instruction in Dockerfile when provided.
        """
        pass
    @property
    def args(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
        """The arguments to be passed when starting the container."""
        pass
    @property
    def env(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[google.cloud.aiplatform.v1.env_var_pb2.EnvVar]:
        """Environment variables to be passed to the container.
        Maximum limit is 100.
        """
        pass
    def __init__(self,
        *,
        image_uri : typing.Text = ...,
        command : typing.Optional[typing.Iterable[typing.Text]] = ...,
        args : typing.Optional[typing.Iterable[typing.Text]] = ...,
        env : typing.Optional[typing.Iterable[google.cloud.aiplatform.v1.env_var_pb2.EnvVar]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["args",b"args","command",b"command","env",b"env","image_uri",b"image_uri"]) -> None: ...
global___ContainerSpec = ContainerSpec

class PythonPackageSpec(google.protobuf.message.Message):
    """The spec of a Python packaged code."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    EXECUTOR_IMAGE_URI_FIELD_NUMBER: builtins.int
    PACKAGE_URIS_FIELD_NUMBER: builtins.int
    PYTHON_MODULE_FIELD_NUMBER: builtins.int
    ARGS_FIELD_NUMBER: builtins.int
    ENV_FIELD_NUMBER: builtins.int
    executor_image_uri: typing.Text = ...
    """Required. The URI of a container image in Artifact Registry that will run the
    provided Python package. Vertex AI provides a wide range of executor
    images with pre-installed packages to meet users' various use cases. See
    the list of [pre-built containers for
    training](https://cloud.google.com/vertex-ai/docs/training/pre-built-containers).
    You must use an image from this list.
    """

    @property
    def package_uris(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
        """Required. The Google Cloud Storage location of the Python package files which are
        the training program and its dependent packages.
        The maximum number of package URIs is 100.
        """
        pass
    python_module: typing.Text = ...
    """Required. The Python module name to run after installing the packages."""

    @property
    def args(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
        """Command line arguments to be passed to the Python task."""
        pass
    @property
    def env(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[google.cloud.aiplatform.v1.env_var_pb2.EnvVar]:
        """Environment variables to be passed to the python module.
        Maximum limit is 100.
        """
        pass
    def __init__(self,
        *,
        executor_image_uri : typing.Text = ...,
        package_uris : typing.Optional[typing.Iterable[typing.Text]] = ...,
        python_module : typing.Text = ...,
        args : typing.Optional[typing.Iterable[typing.Text]] = ...,
        env : typing.Optional[typing.Iterable[google.cloud.aiplatform.v1.env_var_pb2.EnvVar]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["args",b"args","env",b"env","executor_image_uri",b"executor_image_uri","package_uris",b"package_uris","python_module",b"python_module"]) -> None: ...
global___PythonPackageSpec = PythonPackageSpec

class Scheduling(google.protobuf.message.Message):
    """All parameters related to queuing and scheduling of custom jobs."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    TIMEOUT_FIELD_NUMBER: builtins.int
    RESTART_JOB_ON_WORKER_RESTART_FIELD_NUMBER: builtins.int
    @property
    def timeout(self) -> google.protobuf.duration_pb2.Duration:
        """The maximum job running time. The default is 7 days."""
        pass
    restart_job_on_worker_restart: builtins.bool = ...
    """Restarts the entire CustomJob if a worker gets restarted.
    This feature can be used by distributed training jobs that are not
    resilient to workers leaving and joining a job.
    """

    def __init__(self,
        *,
        timeout : typing.Optional[google.protobuf.duration_pb2.Duration] = ...,
        restart_job_on_worker_restart : builtins.bool = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["timeout",b"timeout"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["restart_job_on_worker_restart",b"restart_job_on_worker_restart","timeout",b"timeout"]) -> None: ...
global___Scheduling = Scheduling
