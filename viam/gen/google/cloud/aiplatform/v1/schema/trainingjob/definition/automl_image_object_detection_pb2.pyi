"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import google.protobuf.descriptor
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor = ...

class AutoMlImageObjectDetection(google.protobuf.message.Message):
    """A TrainingJob that trains and uploads an AutoML Image Object Detection Model."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    INPUTS_FIELD_NUMBER: builtins.int
    METADATA_FIELD_NUMBER: builtins.int
    @property
    def inputs(self) -> global___AutoMlImageObjectDetectionInputs:
        """The input parameters of this TrainingJob."""
        pass
    @property
    def metadata(self) -> global___AutoMlImageObjectDetectionMetadata:
        """The metadata information"""
        pass
    def __init__(self,
        *,
        inputs : typing.Optional[global___AutoMlImageObjectDetectionInputs] = ...,
        metadata : typing.Optional[global___AutoMlImageObjectDetectionMetadata] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["inputs",b"inputs","metadata",b"metadata"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["inputs",b"inputs","metadata",b"metadata"]) -> None: ...
global___AutoMlImageObjectDetection = AutoMlImageObjectDetection

class AutoMlImageObjectDetectionInputs(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class _ModelType:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _ModelTypeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_ModelType.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        MODEL_TYPE_UNSPECIFIED: AutoMlImageObjectDetectionInputs.ModelType.ValueType = ...  # 0
        """Should not be set."""

        CLOUD_HIGH_ACCURACY_1: AutoMlImageObjectDetectionInputs.ModelType.ValueType = ...  # 1
        """A model best tailored to be used within Google Cloud, and which cannot
        be exported. Expected to have a higher latency, but should also have a
        higher prediction quality than other cloud models.
        """

        CLOUD_LOW_LATENCY_1: AutoMlImageObjectDetectionInputs.ModelType.ValueType = ...  # 2
        """A model best tailored to be used within Google Cloud, and which cannot
        be exported. Expected to have a low latency, but may have lower
        prediction quality than other cloud models.
        """

        MOBILE_TF_LOW_LATENCY_1: AutoMlImageObjectDetectionInputs.ModelType.ValueType = ...  # 3
        """A model that, in addition to being available within Google
        Cloud can also be exported (see ModelService.ExportModel) and
        used on a mobile or edge device with TensorFlow afterwards.
        Expected to have low latency, but may have lower prediction
        quality than other mobile models.
        """

        MOBILE_TF_VERSATILE_1: AutoMlImageObjectDetectionInputs.ModelType.ValueType = ...  # 4
        """A model that, in addition to being available within Google
        Cloud can also be exported (see ModelService.ExportModel) and
        used on a mobile or edge device with TensorFlow afterwards.
        """

        MOBILE_TF_HIGH_ACCURACY_1: AutoMlImageObjectDetectionInputs.ModelType.ValueType = ...  # 5
        """A model that, in addition to being available within Google
        Cloud, can also be exported (see ModelService.ExportModel) and
        used on a mobile or edge device with TensorFlow afterwards.
        Expected to have a higher latency, but should also have a higher
        prediction quality than other mobile models.
        """

    class ModelType(_ModelType, metaclass=_ModelTypeEnumTypeWrapper):
        pass

    MODEL_TYPE_UNSPECIFIED: AutoMlImageObjectDetectionInputs.ModelType.ValueType = ...  # 0
    """Should not be set."""

    CLOUD_HIGH_ACCURACY_1: AutoMlImageObjectDetectionInputs.ModelType.ValueType = ...  # 1
    """A model best tailored to be used within Google Cloud, and which cannot
    be exported. Expected to have a higher latency, but should also have a
    higher prediction quality than other cloud models.
    """

    CLOUD_LOW_LATENCY_1: AutoMlImageObjectDetectionInputs.ModelType.ValueType = ...  # 2
    """A model best tailored to be used within Google Cloud, and which cannot
    be exported. Expected to have a low latency, but may have lower
    prediction quality than other cloud models.
    """

    MOBILE_TF_LOW_LATENCY_1: AutoMlImageObjectDetectionInputs.ModelType.ValueType = ...  # 3
    """A model that, in addition to being available within Google
    Cloud can also be exported (see ModelService.ExportModel) and
    used on a mobile or edge device with TensorFlow afterwards.
    Expected to have low latency, but may have lower prediction
    quality than other mobile models.
    """

    MOBILE_TF_VERSATILE_1: AutoMlImageObjectDetectionInputs.ModelType.ValueType = ...  # 4
    """A model that, in addition to being available within Google
    Cloud can also be exported (see ModelService.ExportModel) and
    used on a mobile or edge device with TensorFlow afterwards.
    """

    MOBILE_TF_HIGH_ACCURACY_1: AutoMlImageObjectDetectionInputs.ModelType.ValueType = ...  # 5
    """A model that, in addition to being available within Google
    Cloud, can also be exported (see ModelService.ExportModel) and
    used on a mobile or edge device with TensorFlow afterwards.
    Expected to have a higher latency, but should also have a higher
    prediction quality than other mobile models.
    """


    MODEL_TYPE_FIELD_NUMBER: builtins.int
    BUDGET_MILLI_NODE_HOURS_FIELD_NUMBER: builtins.int
    DISABLE_EARLY_STOPPING_FIELD_NUMBER: builtins.int
    model_type: global___AutoMlImageObjectDetectionInputs.ModelType.ValueType = ...
    budget_milli_node_hours: builtins.int = ...
    """The training budget of creating this model, expressed in milli node
    hours i.e. 1,000 value in this field means 1 node hour. The actual
    metadata.costMilliNodeHours will be equal or less than this value.
    If further model training ceases to provide any improvements, it will
    stop without using the full budget and the metadata.successfulStopReason
    will be `model-converged`.
    Note, node_hour  = actual_hour * number_of_nodes_involved.
    For modelType `cloud`(default), the budget must be between 20,000
    and 900,000 milli node hours, inclusive. The default value is 216,000
    which represents one day in wall time, considering 9 nodes are used.
    For model types `mobile-tf-low-latency-1`, `mobile-tf-versatile-1`,
    `mobile-tf-high-accuracy-1`
    the training budget must be between 1,000 and 100,000 milli node hours,
    inclusive. The default value is 24,000 which represents one day in
    wall time on a single node that is used.
    """

    disable_early_stopping: builtins.bool = ...
    """Use the entire training budget. This disables the early stopping feature.
    When false the early stopping feature is enabled, which means that AutoML
    Image Object Detection might stop training before the entire training
    budget has been used.
    """

    def __init__(self,
        *,
        model_type : global___AutoMlImageObjectDetectionInputs.ModelType.ValueType = ...,
        budget_milli_node_hours : builtins.int = ...,
        disable_early_stopping : builtins.bool = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["budget_milli_node_hours",b"budget_milli_node_hours","disable_early_stopping",b"disable_early_stopping","model_type",b"model_type"]) -> None: ...
global___AutoMlImageObjectDetectionInputs = AutoMlImageObjectDetectionInputs

class AutoMlImageObjectDetectionMetadata(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class _SuccessfulStopReason:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _SuccessfulStopReasonEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_SuccessfulStopReason.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        SUCCESSFUL_STOP_REASON_UNSPECIFIED: AutoMlImageObjectDetectionMetadata.SuccessfulStopReason.ValueType = ...  # 0
        """Should not be set."""

        BUDGET_REACHED: AutoMlImageObjectDetectionMetadata.SuccessfulStopReason.ValueType = ...  # 1
        """The inputs.budgetMilliNodeHours had been reached."""

        MODEL_CONVERGED: AutoMlImageObjectDetectionMetadata.SuccessfulStopReason.ValueType = ...  # 2
        """Further training of the Model ceased to increase its quality, since it
        already has converged.
        """

    class SuccessfulStopReason(_SuccessfulStopReason, metaclass=_SuccessfulStopReasonEnumTypeWrapper):
        pass

    SUCCESSFUL_STOP_REASON_UNSPECIFIED: AutoMlImageObjectDetectionMetadata.SuccessfulStopReason.ValueType = ...  # 0
    """Should not be set."""

    BUDGET_REACHED: AutoMlImageObjectDetectionMetadata.SuccessfulStopReason.ValueType = ...  # 1
    """The inputs.budgetMilliNodeHours had been reached."""

    MODEL_CONVERGED: AutoMlImageObjectDetectionMetadata.SuccessfulStopReason.ValueType = ...  # 2
    """Further training of the Model ceased to increase its quality, since it
    already has converged.
    """


    COST_MILLI_NODE_HOURS_FIELD_NUMBER: builtins.int
    SUCCESSFUL_STOP_REASON_FIELD_NUMBER: builtins.int
    cost_milli_node_hours: builtins.int = ...
    """The actual training cost of creating this model, expressed in
    milli node hours, i.e. 1,000 value in this field means 1 node hour.
    Guaranteed to not exceed inputs.budgetMilliNodeHours.
    """

    successful_stop_reason: global___AutoMlImageObjectDetectionMetadata.SuccessfulStopReason.ValueType = ...
    """For successful job completions, this is the reason why the job has
    finished.
    """

    def __init__(self,
        *,
        cost_milli_node_hours : builtins.int = ...,
        successful_stop_reason : global___AutoMlImageObjectDetectionMetadata.SuccessfulStopReason.ValueType = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["cost_milli_node_hours",b"cost_milli_node_hours","successful_stop_reason",b"successful_stop_reason"]) -> None: ...
global___AutoMlImageObjectDetectionMetadata = AutoMlImageObjectDetectionMetadata
