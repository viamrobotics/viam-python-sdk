"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import google.protobuf.descriptor
import google.protobuf.message
import google.protobuf.timestamp_pb2
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor = ...

class FeatureStatsAnomaly(google.protobuf.message.Message):
    """Stats and Anomaly generated at specific timestamp for specific Feature.
    The start_time and end_time are used to define the time range of the dataset
    that current stats belongs to, e.g. prediction traffic is bucketed into
    prediction datasets by time window. If the Dataset is not defined by time
    window, start_time = end_time. Timestamp of the stats and anomalies always
    refers to end_time. Raw stats and anomalies are stored in stats_uri or
    anomaly_uri in the tensorflow defined protos. Field data_stats contains
    almost identical information with the raw stats in Vertex AI
    defined proto, for UI to display.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    SCORE_FIELD_NUMBER: builtins.int
    STATS_URI_FIELD_NUMBER: builtins.int
    ANOMALY_URI_FIELD_NUMBER: builtins.int
    DISTRIBUTION_DEVIATION_FIELD_NUMBER: builtins.int
    ANOMALY_DETECTION_THRESHOLD_FIELD_NUMBER: builtins.int
    START_TIME_FIELD_NUMBER: builtins.int
    END_TIME_FIELD_NUMBER: builtins.int
    score: builtins.float = ...
    """Feature importance score, only populated when cross-feature monitoring is
    enabled. For now only used to represent feature attribution score within
    range [0, 1] for
    [ModelDeploymentMonitoringObjectiveType.FEATURE_ATTRIBUTION_SKEW][google.cloud.aiplatform.v1.ModelDeploymentMonitoringObjectiveType.FEATURE_ATTRIBUTION_SKEW] and
    [ModelDeploymentMonitoringObjectiveType.FEATURE_ATTRIBUTION_DRIFT][google.cloud.aiplatform.v1.ModelDeploymentMonitoringObjectiveType.FEATURE_ATTRIBUTION_DRIFT].
    """

    stats_uri: typing.Text = ...
    """Path of the stats file for current feature values in Cloud Storage bucket.
    Format: gs://<bucket_name>/<object_name>/stats.
    Example: gs://monitoring_bucket/feature_name/stats.
    Stats are stored as binary format with Protobuf message
    [tensorflow.metadata.v0.FeatureNameStatistics](https://github.com/tensorflow/metadata/blob/master/tensorflow_metadata/proto/v0/statistics.proto).
    """

    anomaly_uri: typing.Text = ...
    """Path of the anomaly file for current feature values in Cloud Storage
    bucket.
    Format: gs://<bucket_name>/<object_name>/anomalies.
    Example: gs://monitoring_bucket/feature_name/anomalies.
    Stats are stored as binary format with Protobuf message
    Anoamlies are stored as binary format with Protobuf message
    [tensorflow.metadata.v0.AnomalyInfo]
    (https://github.com/tensorflow/metadata/blob/master/tensorflow_metadata/proto/v0/anomalies.proto).
    """

    distribution_deviation: builtins.float = ...
    """Deviation from the current stats to baseline stats.
      1. For categorical feature, the distribution distance is calculated by
         L-inifinity norm.
      2. For numerical feature, the distribution distance is calculated by
         Jensenâ€“Shannon divergence.
    """

    anomaly_detection_threshold: builtins.float = ...
    """This is the threshold used when detecting anomalies.
    The threshold can be changed by user, so this one might be different from
    [ThresholdConfig.value][google.cloud.aiplatform.v1.ThresholdConfig.value].
    """

    @property
    def start_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """The start timestamp of window where stats were generated.
        For objectives where time window doesn't make sense (e.g. Featurestore
        Snapshot Monitoring), start_time is only used to indicate the monitoring
        intervals, so it always equals to (end_time - monitoring_interval).
        """
        pass
    @property
    def end_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """The end timestamp of window where stats were generated.
        For objectives where time window doesn't make sense (e.g. Featurestore
        Snapshot Monitoring), end_time indicates the timestamp of the data used to
        generate stats (e.g. timestamp we take snapshots for feature values).
        """
        pass
    def __init__(self,
        *,
        score : builtins.float = ...,
        stats_uri : typing.Text = ...,
        anomaly_uri : typing.Text = ...,
        distribution_deviation : builtins.float = ...,
        anomaly_detection_threshold : builtins.float = ...,
        start_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        end_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["end_time",b"end_time","start_time",b"start_time"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["anomaly_detection_threshold",b"anomaly_detection_threshold","anomaly_uri",b"anomaly_uri","distribution_deviation",b"distribution_deviation","end_time",b"end_time","score",b"score","start_time",b"start_time","stats_uri",b"stats_uri"]) -> None: ...
global___FeatureStatsAnomaly = FeatureStatsAnomaly
