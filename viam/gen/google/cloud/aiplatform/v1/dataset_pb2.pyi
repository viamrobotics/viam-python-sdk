"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import google.cloud.aiplatform.v1.encryption_spec_pb2
import google.cloud.aiplatform.v1.io_pb2
import google.protobuf.descriptor
import google.protobuf.internal.containers
import google.protobuf.message
import google.protobuf.struct_pb2
import google.protobuf.timestamp_pb2
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor = ...

class Dataset(google.protobuf.message.Message):
    """A collection of DataItems and Annotations on them."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class LabelsEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: typing.Text = ...
        value: typing.Text = ...
        def __init__(self,
            *,
            key : typing.Text = ...,
            value : typing.Text = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

    NAME_FIELD_NUMBER: builtins.int
    DISPLAY_NAME_FIELD_NUMBER: builtins.int
    DESCRIPTION_FIELD_NUMBER: builtins.int
    METADATA_SCHEMA_URI_FIELD_NUMBER: builtins.int
    METADATA_FIELD_NUMBER: builtins.int
    CREATE_TIME_FIELD_NUMBER: builtins.int
    UPDATE_TIME_FIELD_NUMBER: builtins.int
    ETAG_FIELD_NUMBER: builtins.int
    LABELS_FIELD_NUMBER: builtins.int
    ENCRYPTION_SPEC_FIELD_NUMBER: builtins.int
    name: typing.Text = ...
    """Output only. The resource name of the Dataset."""

    display_name: typing.Text = ...
    """Required. The user-defined name of the Dataset.
    The name can be up to 128 characters long and can be consist of any UTF-8
    characters.
    """

    description: typing.Text = ...
    """Optional. The description of the Dataset."""

    metadata_schema_uri: typing.Text = ...
    """Required. Points to a YAML file stored on Google Cloud Storage describing additional
    information about the Dataset.
    The schema is defined as an OpenAPI 3.0.2 Schema Object.
    The schema files that can be used here are found in
    gs://google-cloud-aiplatform/schema/dataset/metadata/.
    """

    @property
    def metadata(self) -> google.protobuf.struct_pb2.Value:
        """Required. Additional information about the Dataset."""
        pass
    @property
    def create_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Output only. Timestamp when this Dataset was created."""
        pass
    @property
    def update_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Output only. Timestamp when this Dataset was last updated."""
        pass
    etag: typing.Text = ...
    """Used to perform consistent read-modify-write updates. If not set, a blind
    "overwrite" update happens.
    """

    @property
    def labels(self) -> google.protobuf.internal.containers.ScalarMap[typing.Text, typing.Text]:
        """The labels with user-defined metadata to organize your Datasets.

        Label keys and values can be no longer than 64 characters
        (Unicode codepoints), can only contain lowercase letters, numeric
        characters, underscores and dashes. International characters are allowed.
        No more than 64 user labels can be associated with one Dataset (System
        labels are excluded).

        See https://goo.gl/xmQnxf for more information and examples of labels.
        System reserved label keys are prefixed with "aiplatform.googleapis.com/"
        and are immutable. Following system labels exist for each Dataset:

        * "aiplatform.googleapis.com/dataset_metadata_schema": output only, its
          value is the [metadata_schema's][google.cloud.aiplatform.v1.Dataset.metadata_schema_uri] title.
        """
        pass
    @property
    def encryption_spec(self) -> google.cloud.aiplatform.v1.encryption_spec_pb2.EncryptionSpec:
        """Customer-managed encryption key spec for a Dataset. If set, this Dataset
        and all sub-resources of this Dataset will be secured by this key.
        """
        pass
    def __init__(self,
        *,
        name : typing.Text = ...,
        display_name : typing.Text = ...,
        description : typing.Text = ...,
        metadata_schema_uri : typing.Text = ...,
        metadata : typing.Optional[google.protobuf.struct_pb2.Value] = ...,
        create_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        update_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        etag : typing.Text = ...,
        labels : typing.Optional[typing.Mapping[typing.Text, typing.Text]] = ...,
        encryption_spec : typing.Optional[google.cloud.aiplatform.v1.encryption_spec_pb2.EncryptionSpec] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["create_time",b"create_time","encryption_spec",b"encryption_spec","metadata",b"metadata","update_time",b"update_time"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["create_time",b"create_time","description",b"description","display_name",b"display_name","encryption_spec",b"encryption_spec","etag",b"etag","labels",b"labels","metadata",b"metadata","metadata_schema_uri",b"metadata_schema_uri","name",b"name","update_time",b"update_time"]) -> None: ...
global___Dataset = Dataset

class ImportDataConfig(google.protobuf.message.Message):
    """Describes the location from where we import data into a Dataset, together
    with the labels that will be applied to the DataItems and the Annotations.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class DataItemLabelsEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: typing.Text = ...
        value: typing.Text = ...
        def __init__(self,
            *,
            key : typing.Text = ...,
            value : typing.Text = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

    GCS_SOURCE_FIELD_NUMBER: builtins.int
    DATA_ITEM_LABELS_FIELD_NUMBER: builtins.int
    IMPORT_SCHEMA_URI_FIELD_NUMBER: builtins.int
    @property
    def gcs_source(self) -> google.cloud.aiplatform.v1.io_pb2.GcsSource:
        """The Google Cloud Storage location for the input content."""
        pass
    @property
    def data_item_labels(self) -> google.protobuf.internal.containers.ScalarMap[typing.Text, typing.Text]:
        """Labels that will be applied to newly imported DataItems. If an identical
        DataItem as one being imported already exists in the Dataset, then these
        labels will be appended to these of the already existing one, and if labels
        with identical key is imported before, the old label value will be
        overwritten. If two DataItems are identical in the same import data
        operation, the labels will be combined and if key collision happens in this
        case, one of the values will be picked randomly. Two DataItems are
        considered identical if their content bytes are identical (e.g. image bytes
        or pdf bytes).
        These labels will be overridden by Annotation labels specified inside index
        file referenced by [import_schema_uri][google.cloud.aiplatform.v1.ImportDataConfig.import_schema_uri], e.g. jsonl file.
        """
        pass
    import_schema_uri: typing.Text = ...
    """Required. Points to a YAML file stored on Google Cloud Storage describing the import
    format. Validation will be done against the schema. The schema is defined
    as an [OpenAPI 3.0.2 Schema
    Object](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.2.md#schemaObject).
    """

    def __init__(self,
        *,
        gcs_source : typing.Optional[google.cloud.aiplatform.v1.io_pb2.GcsSource] = ...,
        data_item_labels : typing.Optional[typing.Mapping[typing.Text, typing.Text]] = ...,
        import_schema_uri : typing.Text = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["gcs_source",b"gcs_source","source",b"source"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["data_item_labels",b"data_item_labels","gcs_source",b"gcs_source","import_schema_uri",b"import_schema_uri","source",b"source"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["source",b"source"]) -> typing.Optional[typing_extensions.Literal["gcs_source"]]: ...
global___ImportDataConfig = ImportDataConfig

class ExportDataConfig(google.protobuf.message.Message):
    """Describes what part of the Dataset is to be exported, the destination of
    the export and how to export.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    GCS_DESTINATION_FIELD_NUMBER: builtins.int
    ANNOTATIONS_FILTER_FIELD_NUMBER: builtins.int
    @property
    def gcs_destination(self) -> google.cloud.aiplatform.v1.io_pb2.GcsDestination:
        """The Google Cloud Storage location where the output is to be written to.
        In the given directory a new directory will be created with name:
        `export-data-<dataset-display-name>-<timestamp-of-export-call>` where
        timestamp is in YYYY-MM-DDThh:mm:ss.sssZ ISO-8601 format. All export
        output will be written into that directory. Inside that directory,
        annotations with the same schema will be grouped into sub directories
        which are named with the corresponding annotations' schema title. Inside
        these sub directories, a schema.yaml will be created to describe the
        output format.
        """
        pass
    annotations_filter: typing.Text = ...
    """A filter on Annotations of the Dataset. Only Annotations on to-be-exported
    DataItems(specified by [data_items_filter][]) that match this filter will
    be exported. The filter syntax is the same as in
    [ListAnnotations][google.cloud.aiplatform.v1.DatasetService.ListAnnotations].
    """

    def __init__(self,
        *,
        gcs_destination : typing.Optional[google.cloud.aiplatform.v1.io_pb2.GcsDestination] = ...,
        annotations_filter : typing.Text = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["destination",b"destination","gcs_destination",b"gcs_destination"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["annotations_filter",b"annotations_filter","destination",b"destination","gcs_destination",b"gcs_destination"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["destination",b"destination"]) -> typing.Optional[typing_extensions.Literal["gcs_destination"]]: ...
global___ExportDataConfig = ExportDataConfig
