"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import google.protobuf.descriptor
import google.protobuf.duration_pb2
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import google.protobuf.timestamp_pb2
import google.rpc.status_pb2
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor = ...

class _Feature:
    ValueType = typing.NewType('ValueType', builtins.int)
    V: typing_extensions.TypeAlias = ValueType
class _FeatureEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_Feature.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
    FEATURE_UNSPECIFIED: Feature.ValueType = ...  # 0
    """Unspecified."""

    LABEL_DETECTION: Feature.ValueType = ...  # 1
    """Label detection. Detect objects, such as dog or flower."""

    SHOT_CHANGE_DETECTION: Feature.ValueType = ...  # 2
    """Shot change detection."""

    EXPLICIT_CONTENT_DETECTION: Feature.ValueType = ...  # 3
    """Explicit content detection."""

    SPEECH_TRANSCRIPTION: Feature.ValueType = ...  # 6
    """Speech transcription."""

class Feature(_Feature, metaclass=_FeatureEnumTypeWrapper):
    """Video annotation feature."""
    pass

FEATURE_UNSPECIFIED: Feature.ValueType = ...  # 0
"""Unspecified."""

LABEL_DETECTION: Feature.ValueType = ...  # 1
"""Label detection. Detect objects, such as dog or flower."""

SHOT_CHANGE_DETECTION: Feature.ValueType = ...  # 2
"""Shot change detection."""

EXPLICIT_CONTENT_DETECTION: Feature.ValueType = ...  # 3
"""Explicit content detection."""

SPEECH_TRANSCRIPTION: Feature.ValueType = ...  # 6
"""Speech transcription."""

global___Feature = Feature


class _LabelDetectionMode:
    ValueType = typing.NewType('ValueType', builtins.int)
    V: typing_extensions.TypeAlias = ValueType
class _LabelDetectionModeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_LabelDetectionMode.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
    LABEL_DETECTION_MODE_UNSPECIFIED: LabelDetectionMode.ValueType = ...  # 0
    """Unspecified."""

    SHOT_MODE: LabelDetectionMode.ValueType = ...  # 1
    """Detect shot-level labels."""

    FRAME_MODE: LabelDetectionMode.ValueType = ...  # 2
    """Detect frame-level labels."""

    SHOT_AND_FRAME_MODE: LabelDetectionMode.ValueType = ...  # 3
    """Detect both shot-level and frame-level labels."""

class LabelDetectionMode(_LabelDetectionMode, metaclass=_LabelDetectionModeEnumTypeWrapper):
    """Label detection mode."""
    pass

LABEL_DETECTION_MODE_UNSPECIFIED: LabelDetectionMode.ValueType = ...  # 0
"""Unspecified."""

SHOT_MODE: LabelDetectionMode.ValueType = ...  # 1
"""Detect shot-level labels."""

FRAME_MODE: LabelDetectionMode.ValueType = ...  # 2
"""Detect frame-level labels."""

SHOT_AND_FRAME_MODE: LabelDetectionMode.ValueType = ...  # 3
"""Detect both shot-level and frame-level labels."""

global___LabelDetectionMode = LabelDetectionMode


class _Likelihood:
    ValueType = typing.NewType('ValueType', builtins.int)
    V: typing_extensions.TypeAlias = ValueType
class _LikelihoodEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_Likelihood.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
    LIKELIHOOD_UNSPECIFIED: Likelihood.ValueType = ...  # 0
    """Unspecified likelihood."""

    VERY_UNLIKELY: Likelihood.ValueType = ...  # 1
    """Very unlikely."""

    UNLIKELY: Likelihood.ValueType = ...  # 2
    """Unlikely."""

    POSSIBLE: Likelihood.ValueType = ...  # 3
    """Possible."""

    LIKELY: Likelihood.ValueType = ...  # 4
    """Likely."""

    VERY_LIKELY: Likelihood.ValueType = ...  # 5
    """Very likely."""

class Likelihood(_Likelihood, metaclass=_LikelihoodEnumTypeWrapper):
    """Bucketized representation of likelihood."""
    pass

LIKELIHOOD_UNSPECIFIED: Likelihood.ValueType = ...  # 0
"""Unspecified likelihood."""

VERY_UNLIKELY: Likelihood.ValueType = ...  # 1
"""Very unlikely."""

UNLIKELY: Likelihood.ValueType = ...  # 2
"""Unlikely."""

POSSIBLE: Likelihood.ValueType = ...  # 3
"""Possible."""

LIKELY: Likelihood.ValueType = ...  # 4
"""Likely."""

VERY_LIKELY: Likelihood.ValueType = ...  # 5
"""Very likely."""

global___Likelihood = Likelihood


class AnnotateVideoRequest(google.protobuf.message.Message):
    """Video annotation request."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    INPUT_URI_FIELD_NUMBER: builtins.int
    INPUT_CONTENT_FIELD_NUMBER: builtins.int
    FEATURES_FIELD_NUMBER: builtins.int
    VIDEO_CONTEXT_FIELD_NUMBER: builtins.int
    OUTPUT_URI_FIELD_NUMBER: builtins.int
    LOCATION_ID_FIELD_NUMBER: builtins.int
    input_uri: typing.Text = ...
    """Input video location. Currently, only
    [Google Cloud Storage](https://cloud.google.com/storage/) URIs are
    supported, which must be specified in the following format:
    `gs://bucket-id/object-id` (other URI formats return
    [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]). For
    more information, see [Request
    URIs](https://cloud.google.com/storage/docs/request-endpoints). A video URI
    may include wildcards in `object-id`, and thus identify multiple videos.
    Supported wildcards: '*' to match 0 or more characters;
    '?' to match 1 character. If unset, the input video should be embedded
    in the request as `input_content`. If set, `input_content` should be unset.
    """

    input_content: builtins.bytes = ...
    """The video data bytes.
    If unset, the input video(s) should be specified via `input_uri`.
    If set, `input_uri` should be unset.
    """

    @property
    def features(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[global___Feature.ValueType]:
        """Required. Requested video annotation features."""
        pass
    @property
    def video_context(self) -> global___VideoContext:
        """Additional video context and/or feature-specific parameters."""
        pass
    output_uri: typing.Text = ...
    """Optional. Location where the output (in JSON format) should be stored.
    Currently, only [Google Cloud Storage](https://cloud.google.com/storage/)
    URIs are supported, which must be specified in the following format:
    `gs://bucket-id/object-id` (other URI formats return
    [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]). For
    more information, see [Request
    URIs](https://cloud.google.com/storage/docs/request-endpoints).
    """

    location_id: typing.Text = ...
    """Optional. Cloud region where annotation should take place. Supported cloud
    regions: `us-east1`, `us-west1`, `europe-west1`, `asia-east1`. If no region
    is specified, a region will be determined based on video file location.
    """

    def __init__(self,
        *,
        input_uri : typing.Text = ...,
        input_content : builtins.bytes = ...,
        features : typing.Optional[typing.Iterable[global___Feature.ValueType]] = ...,
        video_context : typing.Optional[global___VideoContext] = ...,
        output_uri : typing.Text = ...,
        location_id : typing.Text = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["video_context",b"video_context"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["features",b"features","input_content",b"input_content","input_uri",b"input_uri","location_id",b"location_id","output_uri",b"output_uri","video_context",b"video_context"]) -> None: ...
global___AnnotateVideoRequest = AnnotateVideoRequest

class VideoContext(google.protobuf.message.Message):
    """Video context and/or feature-specific parameters."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    SEGMENTS_FIELD_NUMBER: builtins.int
    LABEL_DETECTION_CONFIG_FIELD_NUMBER: builtins.int
    SHOT_CHANGE_DETECTION_CONFIG_FIELD_NUMBER: builtins.int
    EXPLICIT_CONTENT_DETECTION_CONFIG_FIELD_NUMBER: builtins.int
    SPEECH_TRANSCRIPTION_CONFIG_FIELD_NUMBER: builtins.int
    @property
    def segments(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___VideoSegment]:
        """Video segments to annotate. The segments may overlap and are not required
        to be contiguous or span the whole video. If unspecified, each video is
        treated as a single segment.
        """
        pass
    @property
    def label_detection_config(self) -> global___LabelDetectionConfig:
        """Config for LABEL_DETECTION."""
        pass
    @property
    def shot_change_detection_config(self) -> global___ShotChangeDetectionConfig:
        """Config for SHOT_CHANGE_DETECTION."""
        pass
    @property
    def explicit_content_detection_config(self) -> global___ExplicitContentDetectionConfig:
        """Config for EXPLICIT_CONTENT_DETECTION."""
        pass
    @property
    def speech_transcription_config(self) -> global___SpeechTranscriptionConfig:
        """Config for SPEECH_TRANSCRIPTION."""
        pass
    def __init__(self,
        *,
        segments : typing.Optional[typing.Iterable[global___VideoSegment]] = ...,
        label_detection_config : typing.Optional[global___LabelDetectionConfig] = ...,
        shot_change_detection_config : typing.Optional[global___ShotChangeDetectionConfig] = ...,
        explicit_content_detection_config : typing.Optional[global___ExplicitContentDetectionConfig] = ...,
        speech_transcription_config : typing.Optional[global___SpeechTranscriptionConfig] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["explicit_content_detection_config",b"explicit_content_detection_config","label_detection_config",b"label_detection_config","shot_change_detection_config",b"shot_change_detection_config","speech_transcription_config",b"speech_transcription_config"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["explicit_content_detection_config",b"explicit_content_detection_config","label_detection_config",b"label_detection_config","segments",b"segments","shot_change_detection_config",b"shot_change_detection_config","speech_transcription_config",b"speech_transcription_config"]) -> None: ...
global___VideoContext = VideoContext

class LabelDetectionConfig(google.protobuf.message.Message):
    """Config for LABEL_DETECTION."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    LABEL_DETECTION_MODE_FIELD_NUMBER: builtins.int
    STATIONARY_CAMERA_FIELD_NUMBER: builtins.int
    MODEL_FIELD_NUMBER: builtins.int
    label_detection_mode: global___LabelDetectionMode.ValueType = ...
    """What labels should be detected with LABEL_DETECTION, in addition to
    video-level labels or segment-level labels.
    If unspecified, defaults to `SHOT_MODE`.
    """

    stationary_camera: builtins.bool = ...
    """Whether the video has been shot from a stationary (i.e. non-moving) camera.
    When set to true, might improve detection accuracy for moving objects.
    Should be used with `SHOT_AND_FRAME_MODE` enabled.
    """

    model: typing.Text = ...
    """Model to use for label detection.
    Supported values: "builtin/stable" (the default if unset) and
    "builtin/latest".
    """

    def __init__(self,
        *,
        label_detection_mode : global___LabelDetectionMode.ValueType = ...,
        stationary_camera : builtins.bool = ...,
        model : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["label_detection_mode",b"label_detection_mode","model",b"model","stationary_camera",b"stationary_camera"]) -> None: ...
global___LabelDetectionConfig = LabelDetectionConfig

class ShotChangeDetectionConfig(google.protobuf.message.Message):
    """Config for SHOT_CHANGE_DETECTION."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    MODEL_FIELD_NUMBER: builtins.int
    model: typing.Text = ...
    """Model to use for shot change detection.
    Supported values: "builtin/stable" (the default if unset) and
    "builtin/latest".
    """

    def __init__(self,
        *,
        model : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["model",b"model"]) -> None: ...
global___ShotChangeDetectionConfig = ShotChangeDetectionConfig

class ExplicitContentDetectionConfig(google.protobuf.message.Message):
    """Config for EXPLICIT_CONTENT_DETECTION."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    MODEL_FIELD_NUMBER: builtins.int
    model: typing.Text = ...
    """Model to use for explicit content detection.
    Supported values: "builtin/stable" (the default if unset) and
    "builtin/latest".
    """

    def __init__(self,
        *,
        model : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["model",b"model"]) -> None: ...
global___ExplicitContentDetectionConfig = ExplicitContentDetectionConfig

class VideoSegment(google.protobuf.message.Message):
    """Video segment."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    START_TIME_OFFSET_FIELD_NUMBER: builtins.int
    END_TIME_OFFSET_FIELD_NUMBER: builtins.int
    @property
    def start_time_offset(self) -> google.protobuf.duration_pb2.Duration:
        """Time-offset, relative to the beginning of the video,
        corresponding to the start of the segment (inclusive).
        """
        pass
    @property
    def end_time_offset(self) -> google.protobuf.duration_pb2.Duration:
        """Time-offset, relative to the beginning of the video,
        corresponding to the end of the segment (inclusive).
        """
        pass
    def __init__(self,
        *,
        start_time_offset : typing.Optional[google.protobuf.duration_pb2.Duration] = ...,
        end_time_offset : typing.Optional[google.protobuf.duration_pb2.Duration] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["end_time_offset",b"end_time_offset","start_time_offset",b"start_time_offset"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["end_time_offset",b"end_time_offset","start_time_offset",b"start_time_offset"]) -> None: ...
global___VideoSegment = VideoSegment

class LabelSegment(google.protobuf.message.Message):
    """Video segment level annotation results for label detection."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    SEGMENT_FIELD_NUMBER: builtins.int
    CONFIDENCE_FIELD_NUMBER: builtins.int
    @property
    def segment(self) -> global___VideoSegment:
        """Video segment where a label was detected."""
        pass
    confidence: builtins.float = ...
    """Confidence that the label is accurate. Range: [0, 1]."""

    def __init__(self,
        *,
        segment : typing.Optional[global___VideoSegment] = ...,
        confidence : builtins.float = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["segment",b"segment"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["confidence",b"confidence","segment",b"segment"]) -> None: ...
global___LabelSegment = LabelSegment

class LabelFrame(google.protobuf.message.Message):
    """Video frame level annotation results for label detection."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    TIME_OFFSET_FIELD_NUMBER: builtins.int
    CONFIDENCE_FIELD_NUMBER: builtins.int
    @property
    def time_offset(self) -> google.protobuf.duration_pb2.Duration:
        """Time-offset, relative to the beginning of the video, corresponding to the
        video frame for this location.
        """
        pass
    confidence: builtins.float = ...
    """Confidence that the label is accurate. Range: [0, 1]."""

    def __init__(self,
        *,
        time_offset : typing.Optional[google.protobuf.duration_pb2.Duration] = ...,
        confidence : builtins.float = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["time_offset",b"time_offset"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["confidence",b"confidence","time_offset",b"time_offset"]) -> None: ...
global___LabelFrame = LabelFrame

class Entity(google.protobuf.message.Message):
    """Detected entity from video analysis."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    ENTITY_ID_FIELD_NUMBER: builtins.int
    DESCRIPTION_FIELD_NUMBER: builtins.int
    LANGUAGE_CODE_FIELD_NUMBER: builtins.int
    entity_id: typing.Text = ...
    """Opaque entity ID. Some IDs may be available in
    [Google Knowledge Graph Search
    API](https://developers.google.com/knowledge-graph/).
    """

    description: typing.Text = ...
    """Textual description, e.g. `Fixed-gear bicycle`."""

    language_code: typing.Text = ...
    """Language code for `description` in BCP-47 format."""

    def __init__(self,
        *,
        entity_id : typing.Text = ...,
        description : typing.Text = ...,
        language_code : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["description",b"description","entity_id",b"entity_id","language_code",b"language_code"]) -> None: ...
global___Entity = Entity

class LabelAnnotation(google.protobuf.message.Message):
    """Label annotation."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    ENTITY_FIELD_NUMBER: builtins.int
    CATEGORY_ENTITIES_FIELD_NUMBER: builtins.int
    SEGMENTS_FIELD_NUMBER: builtins.int
    FRAMES_FIELD_NUMBER: builtins.int
    @property
    def entity(self) -> global___Entity:
        """Detected entity."""
        pass
    @property
    def category_entities(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Entity]:
        """Common categories for the detected entity.
        E.g. when the label is `Terrier` the category is likely `dog`. And in some
        cases there might be more than one categories e.g. `Terrier` could also be
        a `pet`.
        """
        pass
    @property
    def segments(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___LabelSegment]:
        """All video segments where a label was detected."""
        pass
    @property
    def frames(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___LabelFrame]:
        """All video frames where a label was detected."""
        pass
    def __init__(self,
        *,
        entity : typing.Optional[global___Entity] = ...,
        category_entities : typing.Optional[typing.Iterable[global___Entity]] = ...,
        segments : typing.Optional[typing.Iterable[global___LabelSegment]] = ...,
        frames : typing.Optional[typing.Iterable[global___LabelFrame]] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["entity",b"entity"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["category_entities",b"category_entities","entity",b"entity","frames",b"frames","segments",b"segments"]) -> None: ...
global___LabelAnnotation = LabelAnnotation

class ExplicitContentFrame(google.protobuf.message.Message):
    """Video frame level annotation results for explicit content."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    TIME_OFFSET_FIELD_NUMBER: builtins.int
    PORNOGRAPHY_LIKELIHOOD_FIELD_NUMBER: builtins.int
    @property
    def time_offset(self) -> google.protobuf.duration_pb2.Duration:
        """Time-offset, relative to the beginning of the video, corresponding to the
        video frame for this location.
        """
        pass
    pornography_likelihood: global___Likelihood.ValueType = ...
    """Likelihood of the pornography content.."""

    def __init__(self,
        *,
        time_offset : typing.Optional[google.protobuf.duration_pb2.Duration] = ...,
        pornography_likelihood : global___Likelihood.ValueType = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["time_offset",b"time_offset"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["pornography_likelihood",b"pornography_likelihood","time_offset",b"time_offset"]) -> None: ...
global___ExplicitContentFrame = ExplicitContentFrame

class ExplicitContentAnnotation(google.protobuf.message.Message):
    """Explicit content annotation (based on per-frame visual signals only).
    If no explicit content has been detected in a frame, no annotations are
    present for that frame.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    FRAMES_FIELD_NUMBER: builtins.int
    @property
    def frames(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ExplicitContentFrame]:
        """All video frames where explicit content was detected."""
        pass
    def __init__(self,
        *,
        frames : typing.Optional[typing.Iterable[global___ExplicitContentFrame]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["frames",b"frames"]) -> None: ...
global___ExplicitContentAnnotation = ExplicitContentAnnotation

class VideoAnnotationResults(google.protobuf.message.Message):
    """Annotation results for a single video."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    INPUT_URI_FIELD_NUMBER: builtins.int
    SEGMENT_LABEL_ANNOTATIONS_FIELD_NUMBER: builtins.int
    SHOT_LABEL_ANNOTATIONS_FIELD_NUMBER: builtins.int
    FRAME_LABEL_ANNOTATIONS_FIELD_NUMBER: builtins.int
    SHOT_ANNOTATIONS_FIELD_NUMBER: builtins.int
    EXPLICIT_ANNOTATION_FIELD_NUMBER: builtins.int
    SPEECH_TRANSCRIPTIONS_FIELD_NUMBER: builtins.int
    ERROR_FIELD_NUMBER: builtins.int
    input_uri: typing.Text = ...
    """Output only. Video file location in
    [Google Cloud Storage](https://cloud.google.com/storage/).
    """

    @property
    def segment_label_annotations(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___LabelAnnotation]:
        """Label annotations on video level or user specified segment level.
        There is exactly one element for each unique label.
        """
        pass
    @property
    def shot_label_annotations(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___LabelAnnotation]:
        """Label annotations on shot level.
        There is exactly one element for each unique label.
        """
        pass
    @property
    def frame_label_annotations(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___LabelAnnotation]:
        """Label annotations on frame level.
        There is exactly one element for each unique label.
        """
        pass
    @property
    def shot_annotations(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___VideoSegment]:
        """Shot annotations. Each shot is represented as a video segment."""
        pass
    @property
    def explicit_annotation(self) -> global___ExplicitContentAnnotation:
        """Explicit content annotation."""
        pass
    @property
    def speech_transcriptions(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___SpeechTranscription]:
        """Speech transcription."""
        pass
    @property
    def error(self) -> google.rpc.status_pb2.Status:
        """Output only. If set, indicates an error. Note that for a single
        `AnnotateVideoRequest` some videos may succeed and some may fail.
        """
        pass
    def __init__(self,
        *,
        input_uri : typing.Text = ...,
        segment_label_annotations : typing.Optional[typing.Iterable[global___LabelAnnotation]] = ...,
        shot_label_annotations : typing.Optional[typing.Iterable[global___LabelAnnotation]] = ...,
        frame_label_annotations : typing.Optional[typing.Iterable[global___LabelAnnotation]] = ...,
        shot_annotations : typing.Optional[typing.Iterable[global___VideoSegment]] = ...,
        explicit_annotation : typing.Optional[global___ExplicitContentAnnotation] = ...,
        speech_transcriptions : typing.Optional[typing.Iterable[global___SpeechTranscription]] = ...,
        error : typing.Optional[google.rpc.status_pb2.Status] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["error",b"error","explicit_annotation",b"explicit_annotation"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["error",b"error","explicit_annotation",b"explicit_annotation","frame_label_annotations",b"frame_label_annotations","input_uri",b"input_uri","segment_label_annotations",b"segment_label_annotations","shot_annotations",b"shot_annotations","shot_label_annotations",b"shot_label_annotations","speech_transcriptions",b"speech_transcriptions"]) -> None: ...
global___VideoAnnotationResults = VideoAnnotationResults

class AnnotateVideoResponse(google.protobuf.message.Message):
    """Video annotation response. Included in the `response`
    field of the `Operation` returned by the `GetOperation`
    call of the `google::longrunning::Operations` service.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    ANNOTATION_RESULTS_FIELD_NUMBER: builtins.int
    @property
    def annotation_results(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___VideoAnnotationResults]:
        """Annotation results for all videos specified in `AnnotateVideoRequest`."""
        pass
    def __init__(self,
        *,
        annotation_results : typing.Optional[typing.Iterable[global___VideoAnnotationResults]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["annotation_results",b"annotation_results"]) -> None: ...
global___AnnotateVideoResponse = AnnotateVideoResponse

class VideoAnnotationProgress(google.protobuf.message.Message):
    """Annotation progress for a single video."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    INPUT_URI_FIELD_NUMBER: builtins.int
    PROGRESS_PERCENT_FIELD_NUMBER: builtins.int
    START_TIME_FIELD_NUMBER: builtins.int
    UPDATE_TIME_FIELD_NUMBER: builtins.int
    input_uri: typing.Text = ...
    """Output only. Video file location in
    [Google Cloud Storage](https://cloud.google.com/storage/).
    """

    progress_percent: builtins.int = ...
    """Output only. Approximate percentage processed thus far. Guaranteed to be
    100 when fully processed.
    """

    @property
    def start_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Output only. Time when the request was received."""
        pass
    @property
    def update_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Output only. Time of the most recent update."""
        pass
    def __init__(self,
        *,
        input_uri : typing.Text = ...,
        progress_percent : builtins.int = ...,
        start_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        update_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["start_time",b"start_time","update_time",b"update_time"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["input_uri",b"input_uri","progress_percent",b"progress_percent","start_time",b"start_time","update_time",b"update_time"]) -> None: ...
global___VideoAnnotationProgress = VideoAnnotationProgress

class AnnotateVideoProgress(google.protobuf.message.Message):
    """Video annotation progress. Included in the `metadata`
    field of the `Operation` returned by the `GetOperation`
    call of the `google::longrunning::Operations` service.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    ANNOTATION_PROGRESS_FIELD_NUMBER: builtins.int
    @property
    def annotation_progress(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___VideoAnnotationProgress]:
        """Progress metadata for all videos specified in `AnnotateVideoRequest`."""
        pass
    def __init__(self,
        *,
        annotation_progress : typing.Optional[typing.Iterable[global___VideoAnnotationProgress]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["annotation_progress",b"annotation_progress"]) -> None: ...
global___AnnotateVideoProgress = AnnotateVideoProgress

class SpeechTranscriptionConfig(google.protobuf.message.Message):
    """Config for SPEECH_TRANSCRIPTION."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    LANGUAGE_CODE_FIELD_NUMBER: builtins.int
    MAX_ALTERNATIVES_FIELD_NUMBER: builtins.int
    FILTER_PROFANITY_FIELD_NUMBER: builtins.int
    SPEECH_CONTEXTS_FIELD_NUMBER: builtins.int
    ENABLE_AUTOMATIC_PUNCTUATION_FIELD_NUMBER: builtins.int
    AUDIO_TRACKS_FIELD_NUMBER: builtins.int
    language_code: typing.Text = ...
    """Required. *Required* The language of the supplied audio as a
    [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
    Example: "en-US".
    See [Language Support](https://cloud.google.com/speech/docs/languages)
    for a list of the currently supported language codes.
    """

    max_alternatives: builtins.int = ...
    """Optional. Maximum number of recognition hypotheses to be returned.
    Specifically, the maximum number of `SpeechRecognitionAlternative` messages
    within each `SpeechTranscription`. The server may return fewer than
    `max_alternatives`. Valid values are `0`-`30`. A value of `0` or `1` will
    return a maximum of one. If omitted, will return a maximum of one.
    """

    filter_profanity: builtins.bool = ...
    """Optional. If set to `true`, the server will attempt to filter out
    profanities, replacing all but the initial character in each filtered word
    with asterisks, e.g. "f***". If set to `false` or omitted, profanities
    won't be filtered out.
    """

    @property
    def speech_contexts(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___SpeechContext]:
        """Optional. A means to provide context to assist the speech recognition."""
        pass
    enable_automatic_punctuation: builtins.bool = ...
    """Optional. If 'true', adds punctuation to recognition result hypotheses.
    This feature is only available in select languages. Setting this for
    requests in other languages has no effect at all. The default 'false' value
    does not add punctuation to result hypotheses. NOTE: "This is currently
    offered as an experimental service, complimentary to all users. In the
    future this may be exclusively available as a premium feature."
    """

    @property
    def audio_tracks(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.int]:
        """Optional. For file formats, such as MXF or MKV, supporting multiple audio
        tracks, specify up to two tracks. Default: track 0.
        """
        pass
    def __init__(self,
        *,
        language_code : typing.Text = ...,
        max_alternatives : builtins.int = ...,
        filter_profanity : builtins.bool = ...,
        speech_contexts : typing.Optional[typing.Iterable[global___SpeechContext]] = ...,
        enable_automatic_punctuation : builtins.bool = ...,
        audio_tracks : typing.Optional[typing.Iterable[builtins.int]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["audio_tracks",b"audio_tracks","enable_automatic_punctuation",b"enable_automatic_punctuation","filter_profanity",b"filter_profanity","language_code",b"language_code","max_alternatives",b"max_alternatives","speech_contexts",b"speech_contexts"]) -> None: ...
global___SpeechTranscriptionConfig = SpeechTranscriptionConfig

class SpeechContext(google.protobuf.message.Message):
    """Provides "hints" to the speech recognizer to favor specific words and phrases
    in the results.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    PHRASES_FIELD_NUMBER: builtins.int
    @property
    def phrases(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
        """Optional. A list of strings containing words and phrases "hints" so that
        the speech recognition is more likely to recognize them. This can be used
        to improve the accuracy for specific words and phrases, for example, if
        specific commands are typically spoken by the user. This can also be used
        to add additional words to the vocabulary of the recognizer. See
        [usage limits](https://cloud.google.com/speech/limits#content).
        """
        pass
    def __init__(self,
        *,
        phrases : typing.Optional[typing.Iterable[typing.Text]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["phrases",b"phrases"]) -> None: ...
global___SpeechContext = SpeechContext

class SpeechTranscription(google.protobuf.message.Message):
    """A speech recognition result corresponding to a portion of the audio."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    ALTERNATIVES_FIELD_NUMBER: builtins.int
    @property
    def alternatives(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___SpeechRecognitionAlternative]:
        """May contain one or more recognition hypotheses (up to the maximum specified
        in `max_alternatives`).  These alternatives are ordered in terms of
        accuracy, with the top (first) alternative being the most probable, as
        ranked by the recognizer.
        """
        pass
    def __init__(self,
        *,
        alternatives : typing.Optional[typing.Iterable[global___SpeechRecognitionAlternative]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["alternatives",b"alternatives"]) -> None: ...
global___SpeechTranscription = SpeechTranscription

class SpeechRecognitionAlternative(google.protobuf.message.Message):
    """Alternative hypotheses (a.k.a. n-best list)."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    TRANSCRIPT_FIELD_NUMBER: builtins.int
    CONFIDENCE_FIELD_NUMBER: builtins.int
    WORDS_FIELD_NUMBER: builtins.int
    transcript: typing.Text = ...
    """Output only. Transcript text representing the words that the user spoke."""

    confidence: builtins.float = ...
    """Output only. The confidence estimate between 0.0 and 1.0. A higher number
    indicates an estimated greater likelihood that the recognized words are
    correct. This field is set only for the top alternative.
    This field is not guaranteed to be accurate and users should not rely on it
    to be always provided.
    The default of 0.0 is a sentinel value indicating `confidence` was not set.
    """

    @property
    def words(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___WordInfo]:
        """Output only. A list of word-specific information for each recognized word."""
        pass
    def __init__(self,
        *,
        transcript : typing.Text = ...,
        confidence : builtins.float = ...,
        words : typing.Optional[typing.Iterable[global___WordInfo]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["confidence",b"confidence","transcript",b"transcript","words",b"words"]) -> None: ...
global___SpeechRecognitionAlternative = SpeechRecognitionAlternative

class WordInfo(google.protobuf.message.Message):
    """Word-specific information for recognized words. Word information is only
    included in the response when certain request parameters are set, such
    as `enable_word_time_offsets`.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    START_TIME_FIELD_NUMBER: builtins.int
    END_TIME_FIELD_NUMBER: builtins.int
    WORD_FIELD_NUMBER: builtins.int
    @property
    def start_time(self) -> google.protobuf.duration_pb2.Duration:
        """Output only. Time offset relative to the beginning of the audio, and
        corresponding to the start of the spoken word. This field is only set if
        `enable_word_time_offsets=true` and only in the top hypothesis. This is an
        experimental feature and the accuracy of the time offset can vary.
        """
        pass
    @property
    def end_time(self) -> google.protobuf.duration_pb2.Duration:
        """Output only. Time offset relative to the beginning of the audio, and
        corresponding to the end of the spoken word. This field is only set if
        `enable_word_time_offsets=true` and only in the top hypothesis. This is an
        experimental feature and the accuracy of the time offset can vary.
        """
        pass
    word: typing.Text = ...
    """Output only. The word corresponding to this set of information."""

    def __init__(self,
        *,
        start_time : typing.Optional[google.protobuf.duration_pb2.Duration] = ...,
        end_time : typing.Optional[google.protobuf.duration_pb2.Duration] = ...,
        word : typing.Text = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["end_time",b"end_time","start_time",b"start_time"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["end_time",b"end_time","start_time",b"start_time","word",b"word"]) -> None: ...
global___WordInfo = WordInfo
