"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import google.genomics.v1.range_pb2
import google.genomics.v1.readalignment_pb2
import google.genomics.v1.readgroupset_pb2
import google.protobuf.descriptor
import google.protobuf.field_mask_pb2
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor = ...

class SearchReadGroupSetsRequest(google.protobuf.message.Message):
    """The read group set search request."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    DATASET_IDS_FIELD_NUMBER: builtins.int
    NAME_FIELD_NUMBER: builtins.int
    PAGE_TOKEN_FIELD_NUMBER: builtins.int
    PAGE_SIZE_FIELD_NUMBER: builtins.int
    @property
    def dataset_ids(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
        """Restricts this query to read group sets within the given datasets. At least
        one ID must be provided.
        """
        pass
    name: typing.Text = ...
    """Only return read group sets for which a substring of the name matches this
    string.
    """

    page_token: typing.Text = ...
    """The continuation token, which is used to page through large result sets.
    To get the next page of results, set this parameter to the value of
    `nextPageToken` from the previous response.
    """

    page_size: builtins.int = ...
    """The maximum number of results to return in a single page. If unspecified,
    defaults to 256. The maximum value is 1024.
    """

    def __init__(self,
        *,
        dataset_ids : typing.Optional[typing.Iterable[typing.Text]] = ...,
        name : typing.Text = ...,
        page_token : typing.Text = ...,
        page_size : builtins.int = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["dataset_ids",b"dataset_ids","name",b"name","page_size",b"page_size","page_token",b"page_token"]) -> None: ...
global___SearchReadGroupSetsRequest = SearchReadGroupSetsRequest

class SearchReadGroupSetsResponse(google.protobuf.message.Message):
    """The read group set search response."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    READ_GROUP_SETS_FIELD_NUMBER: builtins.int
    NEXT_PAGE_TOKEN_FIELD_NUMBER: builtins.int
    @property
    def read_group_sets(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[google.genomics.v1.readgroupset_pb2.ReadGroupSet]:
        """The list of matching read group sets."""
        pass
    next_page_token: typing.Text = ...
    """The continuation token, which is used to page through large result sets.
    Provide this value in a subsequent request to return the next page of
    results. This field will be empty if there aren't any additional results.
    """

    def __init__(self,
        *,
        read_group_sets : typing.Optional[typing.Iterable[google.genomics.v1.readgroupset_pb2.ReadGroupSet]] = ...,
        next_page_token : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["next_page_token",b"next_page_token","read_group_sets",b"read_group_sets"]) -> None: ...
global___SearchReadGroupSetsResponse = SearchReadGroupSetsResponse

class ImportReadGroupSetsRequest(google.protobuf.message.Message):
    """The read group set import request."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class _PartitionStrategy:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _PartitionStrategyEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_PartitionStrategy.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        PARTITION_STRATEGY_UNSPECIFIED: ImportReadGroupSetsRequest.PartitionStrategy.ValueType = ...  # 0
        PER_FILE_PER_SAMPLE: ImportReadGroupSetsRequest.PartitionStrategy.ValueType = ...  # 1
        """In most cases, this strategy yields one read group set per file. This is
        the default behavior.

        Allocate one read group set per file per sample. For BAM files, read
        groups are considered to share a sample if they have identical sample
        names. Furthermore, all reads for each file which do not belong to a read
        group, if any, will be grouped into a single read group set per-file.
        """

        MERGE_ALL: ImportReadGroupSetsRequest.PartitionStrategy.ValueType = ...  # 2
        """Includes all read groups in all imported files into a single read group
        set. Requires that the headers for all imported files are equivalent. All
        reads which do not belong to a read group, if any, will be grouped into a
        separate read group set.
        """

    class PartitionStrategy(_PartitionStrategy, metaclass=_PartitionStrategyEnumTypeWrapper):
        pass

    PARTITION_STRATEGY_UNSPECIFIED: ImportReadGroupSetsRequest.PartitionStrategy.ValueType = ...  # 0
    PER_FILE_PER_SAMPLE: ImportReadGroupSetsRequest.PartitionStrategy.ValueType = ...  # 1
    """In most cases, this strategy yields one read group set per file. This is
    the default behavior.

    Allocate one read group set per file per sample. For BAM files, read
    groups are considered to share a sample if they have identical sample
    names. Furthermore, all reads for each file which do not belong to a read
    group, if any, will be grouped into a single read group set per-file.
    """

    MERGE_ALL: ImportReadGroupSetsRequest.PartitionStrategy.ValueType = ...  # 2
    """Includes all read groups in all imported files into a single read group
    set. Requires that the headers for all imported files are equivalent. All
    reads which do not belong to a read group, if any, will be grouped into a
    separate read group set.
    """


    DATASET_ID_FIELD_NUMBER: builtins.int
    REFERENCE_SET_ID_FIELD_NUMBER: builtins.int
    SOURCE_URIS_FIELD_NUMBER: builtins.int
    PARTITION_STRATEGY_FIELD_NUMBER: builtins.int
    dataset_id: typing.Text = ...
    """Required. The ID of the dataset these read group sets will belong to. The
    caller must have WRITE permissions to this dataset.
    """

    reference_set_id: typing.Text = ...
    """The reference set to which the imported read group sets are aligned to, if
    any. The reference names of this reference set must be a superset of those
    found in the imported file headers. If no reference set id is provided, a
    best effort is made to associate with a matching reference set.
    """

    @property
    def source_uris(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
        """A list of URIs pointing at [BAM
        files](https://samtools.github.io/hts-specs/SAMv1.pdf)
        in Google Cloud Storage.
        Those URIs can include wildcards (*), but do not add or remove
        matching files before import has completed.

        Note that Google Cloud Storage object listing is only eventually
        consistent: files added may be not be immediately visible to
        everyone. Thus, if using a wildcard it is preferable not to start
        the import immediately after the files are created.
        """
        pass
    partition_strategy: global___ImportReadGroupSetsRequest.PartitionStrategy.ValueType = ...
    """The partition strategy describes how read groups are partitioned into read
    group sets.
    """

    def __init__(self,
        *,
        dataset_id : typing.Text = ...,
        reference_set_id : typing.Text = ...,
        source_uris : typing.Optional[typing.Iterable[typing.Text]] = ...,
        partition_strategy : global___ImportReadGroupSetsRequest.PartitionStrategy.ValueType = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["dataset_id",b"dataset_id","partition_strategy",b"partition_strategy","reference_set_id",b"reference_set_id","source_uris",b"source_uris"]) -> None: ...
global___ImportReadGroupSetsRequest = ImportReadGroupSetsRequest

class ImportReadGroupSetsResponse(google.protobuf.message.Message):
    """The read group set import response."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    READ_GROUP_SET_IDS_FIELD_NUMBER: builtins.int
    @property
    def read_group_set_ids(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
        """IDs of the read group sets that were created."""
        pass
    def __init__(self,
        *,
        read_group_set_ids : typing.Optional[typing.Iterable[typing.Text]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["read_group_set_ids",b"read_group_set_ids"]) -> None: ...
global___ImportReadGroupSetsResponse = ImportReadGroupSetsResponse

class ExportReadGroupSetRequest(google.protobuf.message.Message):
    """The read group set export request."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    PROJECT_ID_FIELD_NUMBER: builtins.int
    EXPORT_URI_FIELD_NUMBER: builtins.int
    READ_GROUP_SET_ID_FIELD_NUMBER: builtins.int
    REFERENCE_NAMES_FIELD_NUMBER: builtins.int
    project_id: typing.Text = ...
    """Required. The Google Cloud project ID that owns this
    export. The caller must have WRITE access to this project.
    """

    export_uri: typing.Text = ...
    """Required. A Google Cloud Storage URI for the exported BAM file.
    The currently authenticated user must have write access to the new file.
    An error will be returned if the URI already contains data.
    """

    read_group_set_id: typing.Text = ...
    """Required. The ID of the read group set to export. The caller must have
    READ access to this read group set.
    """

    @property
    def reference_names(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
        """The reference names to export. If this is not specified, all reference
        sequences, including unmapped reads, are exported.
        Use `*` to export only unmapped reads.
        """
        pass
    def __init__(self,
        *,
        project_id : typing.Text = ...,
        export_uri : typing.Text = ...,
        read_group_set_id : typing.Text = ...,
        reference_names : typing.Optional[typing.Iterable[typing.Text]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["export_uri",b"export_uri","project_id",b"project_id","read_group_set_id",b"read_group_set_id","reference_names",b"reference_names"]) -> None: ...
global___ExportReadGroupSetRequest = ExportReadGroupSetRequest

class UpdateReadGroupSetRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    READ_GROUP_SET_ID_FIELD_NUMBER: builtins.int
    READ_GROUP_SET_FIELD_NUMBER: builtins.int
    UPDATE_MASK_FIELD_NUMBER: builtins.int
    read_group_set_id: typing.Text = ...
    """The ID of the read group set to be updated. The caller must have WRITE
    permissions to the dataset associated with this read group set.
    """

    @property
    def read_group_set(self) -> google.genomics.v1.readgroupset_pb2.ReadGroupSet:
        """The new read group set data. See `updateMask` for details on mutability of
        fields.
        """
        pass
    @property
    def update_mask(self) -> google.protobuf.field_mask_pb2.FieldMask:
        """An optional mask specifying which fields to update. Supported fields:

        * [name][google.genomics.v1.ReadGroupSet.name].
        * [referenceSetId][google.genomics.v1.ReadGroupSet.reference_set_id].

        Leaving `updateMask` unset is equivalent to specifying all mutable
        fields.
        """
        pass
    def __init__(self,
        *,
        read_group_set_id : typing.Text = ...,
        read_group_set : typing.Optional[google.genomics.v1.readgroupset_pb2.ReadGroupSet] = ...,
        update_mask : typing.Optional[google.protobuf.field_mask_pb2.FieldMask] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["read_group_set",b"read_group_set","update_mask",b"update_mask"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["read_group_set",b"read_group_set","read_group_set_id",b"read_group_set_id","update_mask",b"update_mask"]) -> None: ...
global___UpdateReadGroupSetRequest = UpdateReadGroupSetRequest

class DeleteReadGroupSetRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    READ_GROUP_SET_ID_FIELD_NUMBER: builtins.int
    read_group_set_id: typing.Text = ...
    """The ID of the read group set to be deleted. The caller must have WRITE
    permissions to the dataset associated with this read group set.
    """

    def __init__(self,
        *,
        read_group_set_id : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["read_group_set_id",b"read_group_set_id"]) -> None: ...
global___DeleteReadGroupSetRequest = DeleteReadGroupSetRequest

class GetReadGroupSetRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    READ_GROUP_SET_ID_FIELD_NUMBER: builtins.int
    read_group_set_id: typing.Text = ...
    """The ID of the read group set."""

    def __init__(self,
        *,
        read_group_set_id : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["read_group_set_id",b"read_group_set_id"]) -> None: ...
global___GetReadGroupSetRequest = GetReadGroupSetRequest

class ListCoverageBucketsRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    READ_GROUP_SET_ID_FIELD_NUMBER: builtins.int
    REFERENCE_NAME_FIELD_NUMBER: builtins.int
    START_FIELD_NUMBER: builtins.int
    END_FIELD_NUMBER: builtins.int
    TARGET_BUCKET_WIDTH_FIELD_NUMBER: builtins.int
    PAGE_TOKEN_FIELD_NUMBER: builtins.int
    PAGE_SIZE_FIELD_NUMBER: builtins.int
    read_group_set_id: typing.Text = ...
    """Required. The ID of the read group set over which coverage is requested."""

    reference_name: typing.Text = ...
    """The name of the reference to query, within the reference set associated
    with this query. Optional.
    """

    start: builtins.int = ...
    """The start position of the range on the reference, 0-based inclusive. If
    specified, `referenceName` must also be specified. Defaults to 0.
    """

    end: builtins.int = ...
    """The end position of the range on the reference, 0-based exclusive. If
    specified, `referenceName` must also be specified. If unset or 0, defaults
    to the length of the reference.
    """

    target_bucket_width: builtins.int = ...
    """The desired width of each reported coverage bucket in base pairs. This
    will be rounded down to the nearest precomputed bucket width; the value
    of which is returned as `bucketWidth` in the response. Defaults
    to infinity (each bucket spans an entire reference sequence) or the length
    of the target range, if specified. The smallest precomputed
    `bucketWidth` is currently 2048 base pairs; this is subject to
    change.
    """

    page_token: typing.Text = ...
    """The continuation token, which is used to page through large result sets.
    To get the next page of results, set this parameter to the value of
    `nextPageToken` from the previous response.
    """

    page_size: builtins.int = ...
    """The maximum number of results to return in a single page. If unspecified,
    defaults to 1024. The maximum value is 2048.
    """

    def __init__(self,
        *,
        read_group_set_id : typing.Text = ...,
        reference_name : typing.Text = ...,
        start : builtins.int = ...,
        end : builtins.int = ...,
        target_bucket_width : builtins.int = ...,
        page_token : typing.Text = ...,
        page_size : builtins.int = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["end",b"end","page_size",b"page_size","page_token",b"page_token","read_group_set_id",b"read_group_set_id","reference_name",b"reference_name","start",b"start","target_bucket_width",b"target_bucket_width"]) -> None: ...
global___ListCoverageBucketsRequest = ListCoverageBucketsRequest

class CoverageBucket(google.protobuf.message.Message):
    """A bucket over which read coverage has been precomputed. A bucket corresponds
    to a specific range of the reference sequence.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    RANGE_FIELD_NUMBER: builtins.int
    MEAN_COVERAGE_FIELD_NUMBER: builtins.int
    @property
    def range(self) -> google.genomics.v1.range_pb2.Range:
        """The genomic coordinate range spanned by this bucket."""
        pass
    mean_coverage: builtins.float = ...
    """The average number of reads which are aligned to each individual
    reference base in this bucket.
    """

    def __init__(self,
        *,
        range : typing.Optional[google.genomics.v1.range_pb2.Range] = ...,
        mean_coverage : builtins.float = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["range",b"range"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["mean_coverage",b"mean_coverage","range",b"range"]) -> None: ...
global___CoverageBucket = CoverageBucket

class ListCoverageBucketsResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    BUCKET_WIDTH_FIELD_NUMBER: builtins.int
    COVERAGE_BUCKETS_FIELD_NUMBER: builtins.int
    NEXT_PAGE_TOKEN_FIELD_NUMBER: builtins.int
    bucket_width: builtins.int = ...
    """The length of each coverage bucket in base pairs. Note that buckets at the
    end of a reference sequence may be shorter. This value is omitted if the
    bucket width is infinity (the default behaviour, with no range or
    `targetBucketWidth`).
    """

    @property
    def coverage_buckets(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___CoverageBucket]:
        """The coverage buckets. The list of buckets is sparse; a bucket with 0
        overlapping reads is not returned. A bucket never crosses more than one
        reference sequence. Each bucket has width `bucketWidth`, unless
        its end is the end of the reference sequence.
        """
        pass
    next_page_token: typing.Text = ...
    """The continuation token, which is used to page through large result sets.
    Provide this value in a subsequent request to return the next page of
    results. This field will be empty if there aren't any additional results.
    """

    def __init__(self,
        *,
        bucket_width : builtins.int = ...,
        coverage_buckets : typing.Optional[typing.Iterable[global___CoverageBucket]] = ...,
        next_page_token : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["bucket_width",b"bucket_width","coverage_buckets",b"coverage_buckets","next_page_token",b"next_page_token"]) -> None: ...
global___ListCoverageBucketsResponse = ListCoverageBucketsResponse

class SearchReadsRequest(google.protobuf.message.Message):
    """The read search request."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    READ_GROUP_SET_IDS_FIELD_NUMBER: builtins.int
    READ_GROUP_IDS_FIELD_NUMBER: builtins.int
    REFERENCE_NAME_FIELD_NUMBER: builtins.int
    START_FIELD_NUMBER: builtins.int
    END_FIELD_NUMBER: builtins.int
    PAGE_TOKEN_FIELD_NUMBER: builtins.int
    PAGE_SIZE_FIELD_NUMBER: builtins.int
    @property
    def read_group_set_ids(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
        """The IDs of the read groups sets within which to search for reads. All
        specified read group sets must be aligned against a common set of reference
        sequences; this defines the genomic coordinates for the query. Must specify
        one of `readGroupSetIds` or `readGroupIds`.
        """
        pass
    @property
    def read_group_ids(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
        """The IDs of the read groups within which to search for reads. All specified
        read groups must belong to the same read group sets. Must specify one of
        `readGroupSetIds` or `readGroupIds`.
        """
        pass
    reference_name: typing.Text = ...
    """The reference sequence name, for example `chr1`, `1`, or `chrX`. If set to
    `*`, only unmapped reads are returned. If unspecified, all reads (mapped
    and unmapped) are returned.
    """

    start: builtins.int = ...
    """The start position of the range on the reference, 0-based inclusive. If
    specified, `referenceName` must also be specified.
    """

    end: builtins.int = ...
    """The end position of the range on the reference, 0-based exclusive. If
    specified, `referenceName` must also be specified.
    """

    page_token: typing.Text = ...
    """The continuation token, which is used to page through large result sets.
    To get the next page of results, set this parameter to the value of
    `nextPageToken` from the previous response.
    """

    page_size: builtins.int = ...
    """The maximum number of results to return in a single page. If unspecified,
    defaults to 256. The maximum value is 2048.
    """

    def __init__(self,
        *,
        read_group_set_ids : typing.Optional[typing.Iterable[typing.Text]] = ...,
        read_group_ids : typing.Optional[typing.Iterable[typing.Text]] = ...,
        reference_name : typing.Text = ...,
        start : builtins.int = ...,
        end : builtins.int = ...,
        page_token : typing.Text = ...,
        page_size : builtins.int = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["end",b"end","page_size",b"page_size","page_token",b"page_token","read_group_ids",b"read_group_ids","read_group_set_ids",b"read_group_set_ids","reference_name",b"reference_name","start",b"start"]) -> None: ...
global___SearchReadsRequest = SearchReadsRequest

class SearchReadsResponse(google.protobuf.message.Message):
    """The read search response."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    ALIGNMENTS_FIELD_NUMBER: builtins.int
    NEXT_PAGE_TOKEN_FIELD_NUMBER: builtins.int
    @property
    def alignments(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[google.genomics.v1.readalignment_pb2.Read]:
        """The list of matching alignments sorted by mapped genomic coordinate,
        if any, ascending in position within the same reference. Unmapped reads,
        which have no position, are returned contiguously and are sorted in
        ascending lexicographic order by fragment name.
        """
        pass
    next_page_token: typing.Text = ...
    """The continuation token, which is used to page through large result sets.
    Provide this value in a subsequent request to return the next page of
    results. This field will be empty if there aren't any additional results.
    """

    def __init__(self,
        *,
        alignments : typing.Optional[typing.Iterable[google.genomics.v1.readalignment_pb2.Read]] = ...,
        next_page_token : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["alignments",b"alignments","next_page_token",b"next_page_token"]) -> None: ...
global___SearchReadsResponse = SearchReadsResponse

class StreamReadsRequest(google.protobuf.message.Message):
    """The stream reads request."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    PROJECT_ID_FIELD_NUMBER: builtins.int
    READ_GROUP_SET_ID_FIELD_NUMBER: builtins.int
    REFERENCE_NAME_FIELD_NUMBER: builtins.int
    START_FIELD_NUMBER: builtins.int
    END_FIELD_NUMBER: builtins.int
    SHARD_FIELD_NUMBER: builtins.int
    TOTAL_SHARDS_FIELD_NUMBER: builtins.int
    project_id: typing.Text = ...
    """The Google Cloud project ID which will be billed
    for this access. The caller must have WRITE access to this project.
    Required.
    """

    read_group_set_id: typing.Text = ...
    """The ID of the read group set from which to stream reads."""

    reference_name: typing.Text = ...
    """The reference sequence name, for example `chr1`,
    `1`, or `chrX`. If set to *, only unmapped reads are
    returned.
    """

    start: builtins.int = ...
    """The start position of the range on the reference, 0-based inclusive. If
    specified, `referenceName` must also be specified.
    """

    end: builtins.int = ...
    """The end position of the range on the reference, 0-based exclusive. If
    specified, `referenceName` must also be specified.
    """

    shard: builtins.int = ...
    """Restricts results to a shard containing approximately `1/totalShards`
    of the normal response payload for this query. Results from a sharded
    request are disjoint from those returned by all queries which differ only
    in their shard parameter. A shard may yield 0 results; this is especially
    likely for large values of `totalShards`.

    Valid values are `[0, totalShards)`.
    """

    total_shards: builtins.int = ...
    """Specifying `totalShards` causes a disjoint subset of the normal response
    payload to be returned for each query with a unique `shard` parameter
    specified. A best effort is made to yield equally sized shards. Sharding
    can be used to distribute processing amongst workers, where each worker is
    assigned a unique `shard` number and all workers specify the same
    `totalShards` number. The union of reads returned for all sharded queries
    `[0, totalShards)` is equal to those returned by a single unsharded query.

    Queries for different values of `totalShards` with common divisors will
    share shard boundaries. For example, streaming `shard` 2 of 5
    `totalShards` yields the same results as streaming `shard`s 4 and 5 of 10
    `totalShards`. This property can be leveraged for adaptive retries.
    """

    def __init__(self,
        *,
        project_id : typing.Text = ...,
        read_group_set_id : typing.Text = ...,
        reference_name : typing.Text = ...,
        start : builtins.int = ...,
        end : builtins.int = ...,
        shard : builtins.int = ...,
        total_shards : builtins.int = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["end",b"end","project_id",b"project_id","read_group_set_id",b"read_group_set_id","reference_name",b"reference_name","shard",b"shard","start",b"start","total_shards",b"total_shards"]) -> None: ...
global___StreamReadsRequest = StreamReadsRequest

class StreamReadsResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    ALIGNMENTS_FIELD_NUMBER: builtins.int
    @property
    def alignments(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[google.genomics.v1.readalignment_pb2.Read]: ...
    def __init__(self,
        *,
        alignments : typing.Optional[typing.Iterable[google.genomics.v1.readalignment_pb2.Read]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["alignments",b"alignments"]) -> None: ...
global___StreamReadsResponse = StreamReadsResponse
