"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import google.protobuf.descriptor
import google.protobuf.duration_pb2
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import google.protobuf.timestamp_pb2
import google.rpc.code_pb2
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor = ...

class ComputeEngine(google.protobuf.message.Message):
    """Describes a Compute Engine resource that is being managed by a running
    [pipeline][google.genomics.v1alpha2.Pipeline].
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    INSTANCE_NAME_FIELD_NUMBER: builtins.int
    ZONE_FIELD_NUMBER: builtins.int
    MACHINE_TYPE_FIELD_NUMBER: builtins.int
    DISK_NAMES_FIELD_NUMBER: builtins.int
    instance_name: typing.Text = ...
    """The instance on which the operation is running."""

    zone: typing.Text = ...
    """The availability zone in which the instance resides."""

    machine_type: typing.Text = ...
    """The machine type of the instance."""

    @property
    def disk_names(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
        """The names of the disks that were created for this pipeline."""
        pass
    def __init__(self,
        *,
        instance_name : typing.Text = ...,
        zone : typing.Text = ...,
        machine_type : typing.Text = ...,
        disk_names : typing.Optional[typing.Iterable[typing.Text]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["disk_names",b"disk_names","instance_name",b"instance_name","machine_type",b"machine_type","zone",b"zone"]) -> None: ...
global___ComputeEngine = ComputeEngine

class RuntimeMetadata(google.protobuf.message.Message):
    """Runtime metadata that will be populated in the
    [runtimeMetadata][google.genomics.v1.OperationMetadata.runtime_metadata]
    field of the Operation associated with a RunPipeline execution.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    COMPUTE_ENGINE_FIELD_NUMBER: builtins.int
    @property
    def compute_engine(self) -> global___ComputeEngine:
        """Execution information specific to Google Compute Engine."""
        pass
    def __init__(self,
        *,
        compute_engine : typing.Optional[global___ComputeEngine] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["compute_engine",b"compute_engine"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["compute_engine",b"compute_engine"]) -> None: ...
global___RuntimeMetadata = RuntimeMetadata

class Pipeline(google.protobuf.message.Message):
    """The pipeline object. Represents a transformation from a set of input
    parameters to a set of output parameters. The transformation is defined
    as a docker image and command to run within that image. Each pipeline
    is run on a Google Compute Engine VM. A pipeline can be created with the
    `create` method and then later run with the `run` method, or a pipeline can
    be defined and run all at once with the `run` method.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    PROJECT_ID_FIELD_NUMBER: builtins.int
    NAME_FIELD_NUMBER: builtins.int
    DESCRIPTION_FIELD_NUMBER: builtins.int
    INPUT_PARAMETERS_FIELD_NUMBER: builtins.int
    OUTPUT_PARAMETERS_FIELD_NUMBER: builtins.int
    DOCKER_FIELD_NUMBER: builtins.int
    RESOURCES_FIELD_NUMBER: builtins.int
    PIPELINE_ID_FIELD_NUMBER: builtins.int
    project_id: typing.Text = ...
    """Required. The project in which to create the pipeline. The caller must have
    WRITE access.
    """

    name: typing.Text = ...
    """Required. A user specified pipeline name that does not have to be unique.
    This name can be used for filtering Pipelines in ListPipelines.
    """

    description: typing.Text = ...
    """User-specified description."""

    @property
    def input_parameters(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___PipelineParameter]:
        """Input parameters of the pipeline."""
        pass
    @property
    def output_parameters(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___PipelineParameter]:
        """Output parameters of the pipeline."""
        pass
    @property
    def docker(self) -> global___DockerExecutor:
        """Specifies the docker run information."""
        pass
    @property
    def resources(self) -> global___PipelineResources:
        """Required. Specifies resource requirements for the pipeline run.
        Required fields:

        *
        [minimumCpuCores][google.genomics.v1alpha2.PipelineResources.minimum_cpu_cores]

        *
        [minimumRamGb][google.genomics.v1alpha2.PipelineResources.minimum_ram_gb]
        """
        pass
    pipeline_id: typing.Text = ...
    """Unique pipeline id that is generated by the service when CreatePipeline
    is called. Cannot be specified in the Pipeline used in the
    CreatePipelineRequest, and will be populated in the response to
    CreatePipeline and all subsequent Get and List calls. Indicates that the
    service has registered this pipeline.
    """

    def __init__(self,
        *,
        project_id : typing.Text = ...,
        name : typing.Text = ...,
        description : typing.Text = ...,
        input_parameters : typing.Optional[typing.Iterable[global___PipelineParameter]] = ...,
        output_parameters : typing.Optional[typing.Iterable[global___PipelineParameter]] = ...,
        docker : typing.Optional[global___DockerExecutor] = ...,
        resources : typing.Optional[global___PipelineResources] = ...,
        pipeline_id : typing.Text = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["docker",b"docker","executor",b"executor","resources",b"resources"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["description",b"description","docker",b"docker","executor",b"executor","input_parameters",b"input_parameters","name",b"name","output_parameters",b"output_parameters","pipeline_id",b"pipeline_id","project_id",b"project_id","resources",b"resources"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["executor",b"executor"]) -> typing.Optional[typing_extensions.Literal["docker"]]: ...
global___Pipeline = Pipeline

class CreatePipelineRequest(google.protobuf.message.Message):
    """The request to create a pipeline. The pipeline field here should not have
    `pipelineId` populated, as that will be populated by the server.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    PIPELINE_FIELD_NUMBER: builtins.int
    @property
    def pipeline(self) -> global___Pipeline:
        """The pipeline to create. Should not have `pipelineId` populated."""
        pass
    def __init__(self,
        *,
        pipeline : typing.Optional[global___Pipeline] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["pipeline",b"pipeline"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["pipeline",b"pipeline"]) -> None: ...
global___CreatePipelineRequest = CreatePipelineRequest

class RunPipelineArgs(google.protobuf.message.Message):
    """The pipeline run arguments."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class InputsEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: typing.Text = ...
        value: typing.Text = ...
        def __init__(self,
            *,
            key : typing.Text = ...,
            value : typing.Text = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

    class OutputsEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: typing.Text = ...
        value: typing.Text = ...
        def __init__(self,
            *,
            key : typing.Text = ...,
            value : typing.Text = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

    class LabelsEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: typing.Text = ...
        value: typing.Text = ...
        def __init__(self,
            *,
            key : typing.Text = ...,
            value : typing.Text = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

    PROJECT_ID_FIELD_NUMBER: builtins.int
    INPUTS_FIELD_NUMBER: builtins.int
    OUTPUTS_FIELD_NUMBER: builtins.int
    SERVICE_ACCOUNT_FIELD_NUMBER: builtins.int
    CLIENT_ID_FIELD_NUMBER: builtins.int
    RESOURCES_FIELD_NUMBER: builtins.int
    LOGGING_FIELD_NUMBER: builtins.int
    KEEP_VM_ALIVE_ON_FAILURE_DURATION_FIELD_NUMBER: builtins.int
    LABELS_FIELD_NUMBER: builtins.int
    project_id: typing.Text = ...
    """Required. The project in which to run the pipeline. The caller must have
    WRITER access to all Google Cloud services and resources (e.g. Google
    Compute Engine) will be used.
    """

    @property
    def inputs(self) -> google.protobuf.internal.containers.ScalarMap[typing.Text, typing.Text]:
        """Pipeline input arguments; keys are defined in the pipeline documentation.
        All input parameters that do not have default values  must be specified.
        If parameters with defaults are specified here, the defaults will be
        overridden.
        """
        pass
    @property
    def outputs(self) -> google.protobuf.internal.containers.ScalarMap[typing.Text, typing.Text]:
        """Pipeline output arguments; keys are defined in the pipeline
        documentation.  All output parameters of without default values
        must be specified.  If parameters with defaults are specified
        here, the defaults will be overridden.
        """
        pass
    @property
    def service_account(self) -> global___ServiceAccount:
        """The Google Cloud Service Account that will be used to access data and
        services. By default, the compute service account associated with
        `projectId` is used.
        """
        pass
    client_id: typing.Text = ...
    """This field is deprecated. Use `labels` instead. Client-specified pipeline
    operation identifier.
    """

    @property
    def resources(self) -> global___PipelineResources:
        """Specifies resource requirements/overrides for the pipeline run."""
        pass
    @property
    def logging(self) -> global___LoggingOptions:
        """Required. Logging options. Used by the service to communicate results
        to the user.
        """
        pass
    @property
    def keep_vm_alive_on_failure_duration(self) -> google.protobuf.duration_pb2.Duration:
        """How long to keep the VM up after a failure (for example docker command
        failed, copying input or output files failed, etc). While the VM is up, one
        can ssh into the VM to debug. Default is 0; maximum allowed value is 1 day.
        """
        pass
    @property
    def labels(self) -> google.protobuf.internal.containers.ScalarMap[typing.Text, typing.Text]:
        """Labels to apply to this pipeline run. Labels will also be applied to
        compute resources (VM, disks) created by this pipeline run. When listing
        operations, operations can [filtered by labels]
        [google.longrunning.ListOperationsRequest.filter].
        Label keys may not be empty; label values may be empty. Non-empty labels
        must be 1-63 characters long, and comply with [RFC1035]
        (https://www.ietf.org/rfc/rfc1035.txt).
        Specifically, the name must be 1-63 characters long and match the regular
        expression `[a-z]([-a-z0-9]*[a-z0-9])?` which means the first
        character must be a lowercase letter, and all following characters must be
        a dash, lowercase letter, or digit, except the last character, which cannot
        be a dash.
        """
        pass
    def __init__(self,
        *,
        project_id : typing.Text = ...,
        inputs : typing.Optional[typing.Mapping[typing.Text, typing.Text]] = ...,
        outputs : typing.Optional[typing.Mapping[typing.Text, typing.Text]] = ...,
        service_account : typing.Optional[global___ServiceAccount] = ...,
        client_id : typing.Text = ...,
        resources : typing.Optional[global___PipelineResources] = ...,
        logging : typing.Optional[global___LoggingOptions] = ...,
        keep_vm_alive_on_failure_duration : typing.Optional[google.protobuf.duration_pb2.Duration] = ...,
        labels : typing.Optional[typing.Mapping[typing.Text, typing.Text]] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["keep_vm_alive_on_failure_duration",b"keep_vm_alive_on_failure_duration","logging",b"logging","resources",b"resources","service_account",b"service_account"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["client_id",b"client_id","inputs",b"inputs","keep_vm_alive_on_failure_duration",b"keep_vm_alive_on_failure_duration","labels",b"labels","logging",b"logging","outputs",b"outputs","project_id",b"project_id","resources",b"resources","service_account",b"service_account"]) -> None: ...
global___RunPipelineArgs = RunPipelineArgs

class RunPipelineRequest(google.protobuf.message.Message):
    """The request to run a pipeline. If `pipelineId` is specified, it
    refers to a saved pipeline created with CreatePipeline and set as
    the `pipelineId` of the returned Pipeline object. If
    `ephemeralPipeline` is specified, that pipeline is run once
    with the given args and not saved. It is an error to specify both
    `pipelineId` and `ephemeralPipeline`. `pipelineArgs`
    must be specified.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    PIPELINE_ID_FIELD_NUMBER: builtins.int
    EPHEMERAL_PIPELINE_FIELD_NUMBER: builtins.int
    PIPELINE_ARGS_FIELD_NUMBER: builtins.int
    pipeline_id: typing.Text = ...
    """The already created pipeline to run."""

    @property
    def ephemeral_pipeline(self) -> global___Pipeline:
        """A new pipeline object to run once and then delete."""
        pass
    @property
    def pipeline_args(self) -> global___RunPipelineArgs:
        """The arguments to use when running this pipeline."""
        pass
    def __init__(self,
        *,
        pipeline_id : typing.Text = ...,
        ephemeral_pipeline : typing.Optional[global___Pipeline] = ...,
        pipeline_args : typing.Optional[global___RunPipelineArgs] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["ephemeral_pipeline",b"ephemeral_pipeline","pipeline",b"pipeline","pipeline_args",b"pipeline_args","pipeline_id",b"pipeline_id"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["ephemeral_pipeline",b"ephemeral_pipeline","pipeline",b"pipeline","pipeline_args",b"pipeline_args","pipeline_id",b"pipeline_id"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["pipeline",b"pipeline"]) -> typing.Optional[typing_extensions.Literal["pipeline_id","ephemeral_pipeline"]]: ...
global___RunPipelineRequest = RunPipelineRequest

class GetPipelineRequest(google.protobuf.message.Message):
    """A request to get a saved pipeline by id."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    PIPELINE_ID_FIELD_NUMBER: builtins.int
    pipeline_id: typing.Text = ...
    """Caller must have READ access to the project in which this pipeline
    is defined.
    """

    def __init__(self,
        *,
        pipeline_id : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["pipeline_id",b"pipeline_id"]) -> None: ...
global___GetPipelineRequest = GetPipelineRequest

class ListPipelinesRequest(google.protobuf.message.Message):
    """A request to list pipelines in a given project. Pipelines can be
    filtered by name using `namePrefix`: all pipelines with names that
    begin with `namePrefix` will be returned. Uses standard pagination:
    `pageSize` indicates how many pipelines to return, and
    `pageToken` comes from a previous ListPipelinesResponse to
    indicate offset.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    PROJECT_ID_FIELD_NUMBER: builtins.int
    NAME_PREFIX_FIELD_NUMBER: builtins.int
    PAGE_SIZE_FIELD_NUMBER: builtins.int
    PAGE_TOKEN_FIELD_NUMBER: builtins.int
    project_id: typing.Text = ...
    """Required. The name of the project to search for pipelines. Caller
    must have READ access to this project.
    """

    name_prefix: typing.Text = ...
    """Pipelines with names that match this prefix should be
    returned.  If unspecified, all pipelines in the project, up to
    `pageSize`, will be returned.
    """

    page_size: builtins.int = ...
    """Number of pipelines to return at once. Defaults to 256, and max
    is 2048.
    """

    page_token: typing.Text = ...
    """Token to use to indicate where to start getting results.
    If unspecified, returns the first page of results.
    """

    def __init__(self,
        *,
        project_id : typing.Text = ...,
        name_prefix : typing.Text = ...,
        page_size : builtins.int = ...,
        page_token : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["name_prefix",b"name_prefix","page_size",b"page_size","page_token",b"page_token","project_id",b"project_id"]) -> None: ...
global___ListPipelinesRequest = ListPipelinesRequest

class ListPipelinesResponse(google.protobuf.message.Message):
    """The response of ListPipelines. Contains at most `pageSize`
    pipelines. If it contains `pageSize` pipelines, and more pipelines
    exist, then `nextPageToken` will be populated and should be
    used as the `pageToken` argument to a subsequent ListPipelines
    request.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    PIPELINES_FIELD_NUMBER: builtins.int
    NEXT_PAGE_TOKEN_FIELD_NUMBER: builtins.int
    @property
    def pipelines(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Pipeline]:
        """The matched pipelines."""
        pass
    next_page_token: typing.Text = ...
    """The token to use to get the next page of results."""

    def __init__(self,
        *,
        pipelines : typing.Optional[typing.Iterable[global___Pipeline]] = ...,
        next_page_token : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["next_page_token",b"next_page_token","pipelines",b"pipelines"]) -> None: ...
global___ListPipelinesResponse = ListPipelinesResponse

class DeletePipelineRequest(google.protobuf.message.Message):
    """The request to delete a saved pipeline by ID."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    PIPELINE_ID_FIELD_NUMBER: builtins.int
    pipeline_id: typing.Text = ...
    """Caller must have WRITE access to the project in which this pipeline
    is defined.
    """

    def __init__(self,
        *,
        pipeline_id : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["pipeline_id",b"pipeline_id"]) -> None: ...
global___DeletePipelineRequest = DeletePipelineRequest

class GetControllerConfigRequest(google.protobuf.message.Message):
    """Request to get controller configuation.  Should only be used
    by VMs created by the Pipelines Service and not by end users.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    OPERATION_ID_FIELD_NUMBER: builtins.int
    VALIDATION_TOKEN_FIELD_NUMBER: builtins.int
    operation_id: typing.Text = ...
    """The operation to retrieve controller configuration for."""

    validation_token: builtins.int = ...
    def __init__(self,
        *,
        operation_id : typing.Text = ...,
        validation_token : builtins.int = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["operation_id",b"operation_id","validation_token",b"validation_token"]) -> None: ...
global___GetControllerConfigRequest = GetControllerConfigRequest

class ControllerConfig(google.protobuf.message.Message):
    """Stores the information that the controller will fetch from the
    server in order to run. Should only be used by VMs created by the
    Pipelines Service and not by end users.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class RepeatedString(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        VALUES_FIELD_NUMBER: builtins.int
        @property
        def values(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]: ...
        def __init__(self,
            *,
            values : typing.Optional[typing.Iterable[typing.Text]] = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["values",b"values"]) -> None: ...

    class VarsEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: typing.Text = ...
        value: typing.Text = ...
        def __init__(self,
            *,
            key : typing.Text = ...,
            value : typing.Text = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

    class DisksEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: typing.Text = ...
        value: typing.Text = ...
        def __init__(self,
            *,
            key : typing.Text = ...,
            value : typing.Text = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

    class GcsSourcesEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: typing.Text = ...
        @property
        def value(self) -> global___ControllerConfig.RepeatedString: ...
        def __init__(self,
            *,
            key : typing.Text = ...,
            value : typing.Optional[global___ControllerConfig.RepeatedString] = ...,
            ) -> None: ...
        def HasField(self, field_name: typing_extensions.Literal["value",b"value"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

    class GcsSinksEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: typing.Text = ...
        @property
        def value(self) -> global___ControllerConfig.RepeatedString: ...
        def __init__(self,
            *,
            key : typing.Text = ...,
            value : typing.Optional[global___ControllerConfig.RepeatedString] = ...,
            ) -> None: ...
        def HasField(self, field_name: typing_extensions.Literal["value",b"value"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

    IMAGE_FIELD_NUMBER: builtins.int
    CMD_FIELD_NUMBER: builtins.int
    GCS_LOG_PATH_FIELD_NUMBER: builtins.int
    MACHINE_TYPE_FIELD_NUMBER: builtins.int
    VARS_FIELD_NUMBER: builtins.int
    DISKS_FIELD_NUMBER: builtins.int
    GCS_SOURCES_FIELD_NUMBER: builtins.int
    GCS_SINKS_FIELD_NUMBER: builtins.int
    image: typing.Text = ...
    cmd: typing.Text = ...
    gcs_log_path: typing.Text = ...
    machine_type: typing.Text = ...
    @property
    def vars(self) -> google.protobuf.internal.containers.ScalarMap[typing.Text, typing.Text]: ...
    @property
    def disks(self) -> google.protobuf.internal.containers.ScalarMap[typing.Text, typing.Text]: ...
    @property
    def gcs_sources(self) -> google.protobuf.internal.containers.MessageMap[typing.Text, global___ControllerConfig.RepeatedString]: ...
    @property
    def gcs_sinks(self) -> google.protobuf.internal.containers.MessageMap[typing.Text, global___ControllerConfig.RepeatedString]: ...
    def __init__(self,
        *,
        image : typing.Text = ...,
        cmd : typing.Text = ...,
        gcs_log_path : typing.Text = ...,
        machine_type : typing.Text = ...,
        vars : typing.Optional[typing.Mapping[typing.Text, typing.Text]] = ...,
        disks : typing.Optional[typing.Mapping[typing.Text, typing.Text]] = ...,
        gcs_sources : typing.Optional[typing.Mapping[typing.Text, global___ControllerConfig.RepeatedString]] = ...,
        gcs_sinks : typing.Optional[typing.Mapping[typing.Text, global___ControllerConfig.RepeatedString]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["cmd",b"cmd","disks",b"disks","gcs_log_path",b"gcs_log_path","gcs_sinks",b"gcs_sinks","gcs_sources",b"gcs_sources","image",b"image","machine_type",b"machine_type","vars",b"vars"]) -> None: ...
global___ControllerConfig = ControllerConfig

class TimestampEvent(google.protobuf.message.Message):
    """Stores the list of events and times they occured for major events in job
    execution.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    DESCRIPTION_FIELD_NUMBER: builtins.int
    TIMESTAMP_FIELD_NUMBER: builtins.int
    description: typing.Text = ...
    """String indicating the type of event"""

    @property
    def timestamp(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """The time this event occured."""
        pass
    def __init__(self,
        *,
        description : typing.Text = ...,
        timestamp : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["timestamp",b"timestamp"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["description",b"description","timestamp",b"timestamp"]) -> None: ...
global___TimestampEvent = TimestampEvent

class SetOperationStatusRequest(google.protobuf.message.Message):
    """Request to set operation status. Should only be used by VMs
    created by the Pipelines Service and not by end users.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    OPERATION_ID_FIELD_NUMBER: builtins.int
    TIMESTAMP_EVENTS_FIELD_NUMBER: builtins.int
    ERROR_CODE_FIELD_NUMBER: builtins.int
    ERROR_MESSAGE_FIELD_NUMBER: builtins.int
    VALIDATION_TOKEN_FIELD_NUMBER: builtins.int
    operation_id: typing.Text = ...
    @property
    def timestamp_events(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___TimestampEvent]: ...
    error_code: google.rpc.code_pb2.Code.ValueType = ...
    error_message: typing.Text = ...
    validation_token: builtins.int = ...
    def __init__(self,
        *,
        operation_id : typing.Text = ...,
        timestamp_events : typing.Optional[typing.Iterable[global___TimestampEvent]] = ...,
        error_code : google.rpc.code_pb2.Code.ValueType = ...,
        error_message : typing.Text = ...,
        validation_token : builtins.int = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["error_code",b"error_code","error_message",b"error_message","operation_id",b"operation_id","timestamp_events",b"timestamp_events","validation_token",b"validation_token"]) -> None: ...
global___SetOperationStatusRequest = SetOperationStatusRequest

class ServiceAccount(google.protobuf.message.Message):
    """A Google Cloud Service Account."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    EMAIL_FIELD_NUMBER: builtins.int
    SCOPES_FIELD_NUMBER: builtins.int
    email: typing.Text = ...
    """Email address of the service account. Defaults to `default`,
    which uses the compute service account associated with the project.
    """

    @property
    def scopes(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
        """List of scopes to be enabled for this service account on the VM.
        The following scopes are automatically included:

        * https://www.googleapis.com/auth/compute
        * https://www.googleapis.com/auth/devstorage.full_control
        * https://www.googleapis.com/auth/genomics
        * https://www.googleapis.com/auth/logging.write
        * https://www.googleapis.com/auth/monitoring.write
        """
        pass
    def __init__(self,
        *,
        email : typing.Text = ...,
        scopes : typing.Optional[typing.Iterable[typing.Text]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["email",b"email","scopes",b"scopes"]) -> None: ...
global___ServiceAccount = ServiceAccount

class LoggingOptions(google.protobuf.message.Message):
    """The logging options for the pipeline run."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    GCS_PATH_FIELD_NUMBER: builtins.int
    gcs_path: typing.Text = ...
    """The location in Google Cloud Storage to which the pipeline logs
    will be copied. Can be specified as a fully qualified directory
    path, in which case logs will be output with a unique identifier
    as the filename in that directory, or as a fully specified path,
    which must end in `.log`, in which case that path will be
    used, and the user must ensure that logs are not
    overwritten. Stdout and stderr logs from the run are also
    generated and output as `-stdout.log` and `-stderr.log`.
    """

    def __init__(self,
        *,
        gcs_path : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["gcs_path",b"gcs_path"]) -> None: ...
global___LoggingOptions = LoggingOptions

class PipelineResources(google.protobuf.message.Message):
    """The system resources for the pipeline run."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class Disk(google.protobuf.message.Message):
        """A Google Compute Engine disk resource specification."""
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        class _Type:
            ValueType = typing.NewType('ValueType', builtins.int)
            V: typing_extensions.TypeAlias = ValueType
        class _TypeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_Type.ValueType], builtins.type):
            DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
            TYPE_UNSPECIFIED: PipelineResources.Disk.Type.ValueType = ...  # 0
            """Default disk type. Use one of the other options below."""

            PERSISTENT_HDD: PipelineResources.Disk.Type.ValueType = ...  # 1
            """Specifies a Google Compute Engine persistent hard disk. See
            https://cloud.google.com/compute/docs/disks/#pdspecs for details.
            """

            PERSISTENT_SSD: PipelineResources.Disk.Type.ValueType = ...  # 2
            """Specifies a Google Compute Engine persistent solid-state disk. See
            https://cloud.google.com/compute/docs/disks/#pdspecs for details.
            """

            LOCAL_SSD: PipelineResources.Disk.Type.ValueType = ...  # 3
            """Specifies a Google Compute Engine local SSD.
            See https://cloud.google.com/compute/docs/disks/local-ssd for details.
            """

        class Type(_Type, metaclass=_TypeEnumTypeWrapper):
            """The types of disks that may be attached to VMs."""
            pass

        TYPE_UNSPECIFIED: PipelineResources.Disk.Type.ValueType = ...  # 0
        """Default disk type. Use one of the other options below."""

        PERSISTENT_HDD: PipelineResources.Disk.Type.ValueType = ...  # 1
        """Specifies a Google Compute Engine persistent hard disk. See
        https://cloud.google.com/compute/docs/disks/#pdspecs for details.
        """

        PERSISTENT_SSD: PipelineResources.Disk.Type.ValueType = ...  # 2
        """Specifies a Google Compute Engine persistent solid-state disk. See
        https://cloud.google.com/compute/docs/disks/#pdspecs for details.
        """

        LOCAL_SSD: PipelineResources.Disk.Type.ValueType = ...  # 3
        """Specifies a Google Compute Engine local SSD.
        See https://cloud.google.com/compute/docs/disks/local-ssd for details.
        """


        NAME_FIELD_NUMBER: builtins.int
        TYPE_FIELD_NUMBER: builtins.int
        SIZE_GB_FIELD_NUMBER: builtins.int
        SOURCE_FIELD_NUMBER: builtins.int
        AUTO_DELETE_FIELD_NUMBER: builtins.int
        MOUNT_POINT_FIELD_NUMBER: builtins.int
        name: typing.Text = ...
        """Required. The name of the disk that can be used in the pipeline
        parameters. Must be 1 - 63 characters.
        The name "boot" is reserved for system use.
        """

        type: global___PipelineResources.Disk.Type.ValueType = ...
        """Required. The type of the disk to create."""

        size_gb: builtins.int = ...
        """The size of the disk. Defaults to 500 (GB).
        This field is not applicable for local SSD.
        """

        source: typing.Text = ...
        """The full or partial URL of the persistent disk to attach. See
        https://cloud.google.com/compute/docs/reference/latest/instances#resource
        and
        https://cloud.google.com/compute/docs/disks/persistent-disks#snapshots
        for more details.
        """

        auto_delete: builtins.bool = ...
        """Deprecated. Disks created by the Pipelines API will be deleted at the end
        of the pipeline run, regardless of what this field is set to.
        """

        mount_point: typing.Text = ...
        """Required at create time and cannot be overridden at run time.
        Specifies the path in the docker container where files on
        this disk should be located. For example, if `mountPoint`
        is `/mnt/disk`, and the parameter has `localPath`
        `inputs/file.txt`, the docker container can access the data at
        `/mnt/disk/inputs/file.txt`.
        """

        def __init__(self,
            *,
            name : typing.Text = ...,
            type : global___PipelineResources.Disk.Type.ValueType = ...,
            size_gb : builtins.int = ...,
            source : typing.Text = ...,
            auto_delete : builtins.bool = ...,
            mount_point : typing.Text = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["auto_delete",b"auto_delete","mount_point",b"mount_point","name",b"name","size_gb",b"size_gb","source",b"source","type",b"type"]) -> None: ...

    MINIMUM_CPU_CORES_FIELD_NUMBER: builtins.int
    PREEMPTIBLE_FIELD_NUMBER: builtins.int
    MINIMUM_RAM_GB_FIELD_NUMBER: builtins.int
    DISKS_FIELD_NUMBER: builtins.int
    ZONES_FIELD_NUMBER: builtins.int
    BOOT_DISK_SIZE_GB_FIELD_NUMBER: builtins.int
    NO_ADDRESS_FIELD_NUMBER: builtins.int
    minimum_cpu_cores: builtins.int = ...
    """The minimum number of cores to use. Defaults to 1."""

    preemptible: builtins.bool = ...
    """Whether to use preemptible VMs. Defaults to `false`. In order to use this,
    must be true for both create time and run time. Cannot be true at run time
    if false at create time.
    """

    minimum_ram_gb: builtins.float = ...
    """The minimum amount of RAM to use. Defaults to 3.75 (GB)"""

    @property
    def disks(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___PipelineResources.Disk]:
        """Disks to attach."""
        pass
    @property
    def zones(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
        """List of Google Compute Engine availability zones to which resource
        creation will restricted. If empty, any zone may be chosen.
        """
        pass
    boot_disk_size_gb: builtins.int = ...
    """The size of the boot disk. Defaults to 10 (GB)."""

    no_address: builtins.bool = ...
    """Whether to assign an external IP to the instance. This is an experimental
    feature that may go away. Defaults to false.
    Corresponds to `--no_address` flag for [gcloud compute instances create]
    (https://cloud.google.com/sdk/gcloud/reference/compute/instances/create).
    In order to use this, must be true for both create time and run time.
    Cannot be true at run time if false at create time. If you need to ssh into
    a private IP VM for debugging, you can ssh to a public VM and then ssh into
    the private VM's Internal IP.  If noAddress is set, this pipeline run may
    only load docker images from Google Container Registry and not Docker Hub.
    ** Note: To use this option, your project must be in Google Access for
    Private IPs Early Access Program.**
    """

    def __init__(self,
        *,
        minimum_cpu_cores : builtins.int = ...,
        preemptible : builtins.bool = ...,
        minimum_ram_gb : builtins.float = ...,
        disks : typing.Optional[typing.Iterable[global___PipelineResources.Disk]] = ...,
        zones : typing.Optional[typing.Iterable[typing.Text]] = ...,
        boot_disk_size_gb : builtins.int = ...,
        no_address : builtins.bool = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["boot_disk_size_gb",b"boot_disk_size_gb","disks",b"disks","minimum_cpu_cores",b"minimum_cpu_cores","minimum_ram_gb",b"minimum_ram_gb","no_address",b"no_address","preemptible",b"preemptible","zones",b"zones"]) -> None: ...
global___PipelineResources = PipelineResources

class PipelineParameter(google.protobuf.message.Message):
    """Parameters facilitate setting and delivering data into the
    pipeline's execution environment. They are defined at create time,
    with optional defaults, and can be overridden at run time.

    If `localCopy` is unset, then the parameter specifies a string that
    is passed as-is into the pipeline, as the value of the environment
    variable with the given name.  A default value can be optionally
    specified at create time. The default can be overridden at run time
    using the inputs map. If no default is given, a value must be
    supplied at runtime.

    If `localCopy` is defined, then the parameter specifies a data
    source or sink, both in Google Cloud Storage and on the Docker container
    where the pipeline computation is run. The [service account associated with
    the Pipeline][google.genomics.v1alpha2.RunPipelineArgs.service_account] (by
    default the project's Compute Engine service account) must have access to the
    Google Cloud Storage paths.

    At run time, the Google Cloud Storage paths can be overridden if a default
    was provided at create time, or must be set otherwise. The pipeline runner
    should add a key/value pair to either the inputs or outputs map. The
    indicated data copies will be carried out before/after pipeline execution,
    just as if the corresponding arguments were provided to `gsutil cp`.

    For example: Given the following `PipelineParameter`, specified
    in the `inputParameters` list:

    ```
    {name: "input_file", localCopy: {path: "file.txt", disk: "pd1"}}
    ```

    where `disk` is defined in the `PipelineResources` object as:

    ```
    {name: "pd1", mountPoint: "/mnt/disk/"}
    ```

    We create a disk named `pd1`, mount it on the host VM, and map
    `/mnt/pd1` to `/mnt/disk` in the docker container.  At
    runtime, an entry for `input_file` would be required in the inputs
    map, such as:

    ```
      inputs["input_file"] = "gs://my-bucket/bar.txt"
    ```

    This would generate the following gsutil call:

    ```
      gsutil cp gs://my-bucket/bar.txt /mnt/pd1/file.txt
    ```

    The file `/mnt/pd1/file.txt` maps to `/mnt/disk/file.txt` in the
    Docker container. Acceptable paths are:

    <table>
      <thead>
        <tr><th>Google Cloud storage path</th><th>Local path</th></tr>
      </thead>
      <tbody>
        <tr><td>file</td><td>file</td></tr>
        <tr><td>glob</td><td>directory</td></tr>
      </tbody>
    </table>

    For outputs, the direction of the copy is reversed:

    ```
      gsutil cp /mnt/disk/file.txt gs://my-bucket/bar.txt
    ```

    Acceptable paths are:

    <table>
      <thead>
        <tr><th>Local path</th><th>Google Cloud Storage path</th></tr>
      </thead>
      <tbody>
        <tr><td>file</td><td>file</td></tr>
        <tr>
          <td>file</td>
          <td>directory - directory must already exist</td>
        </tr>
        <tr>
          <td>glob</td>
          <td>directory - directory will be created if it doesn't exist</td></tr>
      </tbody>
    </table>

    One restriction due to docker limitations, is that for outputs that are found
    on the boot disk, the local path cannot be a glob and must be a file.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class LocalCopy(google.protobuf.message.Message):
        """LocalCopy defines how a remote file should be copied to and from the VM."""
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        PATH_FIELD_NUMBER: builtins.int
        DISK_FIELD_NUMBER: builtins.int
        path: typing.Text = ...
        """Required. The path within the user's docker container where
        this input should be localized to and from, relative to the specified
        disk's mount point. For example: file.txt,
        """

        disk: typing.Text = ...
        """Required. The name of the disk where this parameter is
        located. Can be the name of one of the disks specified in the
        Resources field, or "boot", which represents the Docker
        instance's boot disk and has a mount point of `/`.
        """

        def __init__(self,
            *,
            path : typing.Text = ...,
            disk : typing.Text = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["disk",b"disk","path",b"path"]) -> None: ...

    NAME_FIELD_NUMBER: builtins.int
    DESCRIPTION_FIELD_NUMBER: builtins.int
    DEFAULT_VALUE_FIELD_NUMBER: builtins.int
    LOCAL_COPY_FIELD_NUMBER: builtins.int
    name: typing.Text = ...
    """Required. Name of the parameter - the pipeline runner uses this string
    as the key to the input and output maps in RunPipeline.
    """

    description: typing.Text = ...
    """Human-readable description."""

    default_value: typing.Text = ...
    """The default value for this parameter. Can be overridden at runtime.
    If `localCopy` is present, then this must be a Google Cloud Storage path
    beginning with `gs://`.
    """

    @property
    def local_copy(self) -> global___PipelineParameter.LocalCopy:
        """If present, this parameter is marked for copying to and from the VM.
        `LocalCopy` indicates where on the VM the file should be. The value
        given to this parameter (either at runtime or using `defaultValue`)
        must be the remote path where the file should be.
        """
        pass
    def __init__(self,
        *,
        name : typing.Text = ...,
        description : typing.Text = ...,
        default_value : typing.Text = ...,
        local_copy : typing.Optional[global___PipelineParameter.LocalCopy] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["local_copy",b"local_copy"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["default_value",b"default_value","description",b"description","local_copy",b"local_copy","name",b"name"]) -> None: ...
global___PipelineParameter = PipelineParameter

class DockerExecutor(google.protobuf.message.Message):
    """The Docker execuctor specification."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    IMAGE_NAME_FIELD_NUMBER: builtins.int
    CMD_FIELD_NUMBER: builtins.int
    image_name: typing.Text = ...
    """Required. Image name from either Docker Hub or Google Container Registry.
    Users that run pipelines must have READ access to the image.
    """

    cmd: typing.Text = ...
    """Required. The command or newline delimited script to run. The command
    string will be executed within a bash shell.

    If the command exits with a non-zero exit code, output parameter
    de-localization will be skipped and the pipeline operation's
    [`error`][google.longrunning.Operation.error] field will be populated.

    Maximum command string length is 16384.
    """

    def __init__(self,
        *,
        image_name : typing.Text = ...,
        cmd : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["cmd",b"cmd","image_name",b"image_name"]) -> None: ...
global___DockerExecutor = DockerExecutor
