"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
from .... import app
import builtins
import collections.abc
import google.protobuf.descriptor
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import google.protobuf.timestamp_pb2
import sys
import typing
if sys.version_info >= (3, 10):
    import typing as typing_extensions
else:
    import typing_extensions
DESCRIPTOR: google.protobuf.descriptor.FileDescriptor

class _DataPipelineRunStatus:
    ValueType = typing.NewType('ValueType', builtins.int)
    V: typing_extensions.TypeAlias = ValueType

class _DataPipelineRunStatusEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_DataPipelineRunStatus.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor
    DATA_PIPELINE_RUN_STATUS_UNSPECIFIED: _DataPipelineRunStatus.ValueType
    DATA_PIPELINE_RUN_STATUS_SCHEDULED: _DataPipelineRunStatus.ValueType
    DATA_PIPELINE_RUN_STATUS_STARTED: _DataPipelineRunStatus.ValueType
    DATA_PIPELINE_RUN_STATUS_COMPLETED: _DataPipelineRunStatus.ValueType
    DATA_PIPELINE_RUN_STATUS_FAILED: _DataPipelineRunStatus.ValueType

class DataPipelineRunStatus(_DataPipelineRunStatus, metaclass=_DataPipelineRunStatusEnumTypeWrapper):
    ...
DATA_PIPELINE_RUN_STATUS_UNSPECIFIED: DataPipelineRunStatus.ValueType
DATA_PIPELINE_RUN_STATUS_SCHEDULED: DataPipelineRunStatus.ValueType
DATA_PIPELINE_RUN_STATUS_STARTED: DataPipelineRunStatus.ValueType
DATA_PIPELINE_RUN_STATUS_COMPLETED: DataPipelineRunStatus.ValueType
DATA_PIPELINE_RUN_STATUS_FAILED: DataPipelineRunStatus.ValueType
global___DataPipelineRunStatus = DataPipelineRunStatus

@typing.final
class DataPipeline(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    ID_FIELD_NUMBER: builtins.int
    ORGANIZATION_ID_FIELD_NUMBER: builtins.int
    NAME_FIELD_NUMBER: builtins.int
    MQL_BINARY_FIELD_NUMBER: builtins.int
    SCHEDULE_FIELD_NUMBER: builtins.int
    ENABLED_FIELD_NUMBER: builtins.int
    CREATED_ON_FIELD_NUMBER: builtins.int
    UPDATED_AT_FIELD_NUMBER: builtins.int
    DATA_SOURCE_TYPE_FIELD_NUMBER: builtins.int
    id: builtins.str
    organization_id: builtins.str
    'The associated Viam organization ID.'
    name: builtins.str
    'A unique identifier at the org level.'
    schedule: builtins.str
    'A cron expression representing the expected execution schedule in UTC (note this also\n    defines the input time window; an hourly schedule would process 1 hour of data at a time).\n    '
    enabled: builtins.bool
    'Whether or not the pipeline is enabled.'
    data_source_type: app.data.v1.data_pb2.TabularDataSourceType.ValueType
    'The type of data source for the pipeline. If not specified, default is standard data storage.'

    @property
    def mql_binary(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.bytes]:
        """A MongoDB aggregation pipeline as a list of BSON documents, where
        each document is one stage in the pipeline.
        """

    @property
    def created_on(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """The time the pipeline was created."""

    @property
    def updated_at(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """The time the pipeline was last updated."""

    def __init__(self, *, id: builtins.str=..., organization_id: builtins.str=..., name: builtins.str=..., mql_binary: collections.abc.Iterable[builtins.bytes] | None=..., schedule: builtins.str=..., enabled: builtins.bool=..., created_on: google.protobuf.timestamp_pb2.Timestamp | None=..., updated_at: google.protobuf.timestamp_pb2.Timestamp | None=..., data_source_type: app.data.v1.data_pb2.TabularDataSourceType.ValueType | None=...) -> None:
        ...

    def HasField(self, field_name: typing.Literal['_data_source_type', b'_data_source_type', 'created_on', b'created_on', 'data_source_type', b'data_source_type', 'updated_at', b'updated_at']) -> builtins.bool:
        ...

    def ClearField(self, field_name: typing.Literal['_data_source_type', b'_data_source_type', 'created_on', b'created_on', 'data_source_type', b'data_source_type', 'enabled', b'enabled', 'id', b'id', 'mql_binary', b'mql_binary', 'name', b'name', 'organization_id', b'organization_id', 'schedule', b'schedule', 'updated_at', b'updated_at']) -> None:
        ...

    def WhichOneof(self, oneof_group: typing.Literal['_data_source_type', b'_data_source_type']) -> typing.Literal['data_source_type'] | None:
        ...
global___DataPipeline = DataPipeline

@typing.final
class GetDataPipelineRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    ID_FIELD_NUMBER: builtins.int
    id: builtins.str
    'The ID of the data pipeline to retrieve.'

    def __init__(self, *, id: builtins.str=...) -> None:
        ...

    def ClearField(self, field_name: typing.Literal['id', b'id']) -> None:
        ...
global___GetDataPipelineRequest = GetDataPipelineRequest

@typing.final
class GetDataPipelineResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    DATA_PIPELINE_FIELD_NUMBER: builtins.int

    @property
    def data_pipeline(self) -> global___DataPipeline:
        ...

    def __init__(self, *, data_pipeline: global___DataPipeline | None=...) -> None:
        ...

    def HasField(self, field_name: typing.Literal['data_pipeline', b'data_pipeline']) -> builtins.bool:
        ...

    def ClearField(self, field_name: typing.Literal['data_pipeline', b'data_pipeline']) -> None:
        ...
global___GetDataPipelineResponse = GetDataPipelineResponse

@typing.final
class ListDataPipelinesRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    ORGANIZATION_ID_FIELD_NUMBER: builtins.int
    organization_id: builtins.str
    'The associated Viam organization ID.'

    def __init__(self, *, organization_id: builtins.str=...) -> None:
        ...

    def ClearField(self, field_name: typing.Literal['organization_id', b'organization_id']) -> None:
        ...
global___ListDataPipelinesRequest = ListDataPipelinesRequest

@typing.final
class ListDataPipelinesResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    DATA_PIPELINES_FIELD_NUMBER: builtins.int

    @property
    def data_pipelines(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___DataPipeline]:
        ...

    def __init__(self, *, data_pipelines: collections.abc.Iterable[global___DataPipeline] | None=...) -> None:
        ...

    def ClearField(self, field_name: typing.Literal['data_pipelines', b'data_pipelines']) -> None:
        ...
global___ListDataPipelinesResponse = ListDataPipelinesResponse

@typing.final
class CreateDataPipelineRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    ORGANIZATION_ID_FIELD_NUMBER: builtins.int
    NAME_FIELD_NUMBER: builtins.int
    MQL_BINARY_FIELD_NUMBER: builtins.int
    SCHEDULE_FIELD_NUMBER: builtins.int
    ENABLE_BACKFILL_FIELD_NUMBER: builtins.int
    DATA_SOURCE_TYPE_FIELD_NUMBER: builtins.int
    organization_id: builtins.str
    'The associated Viam organization ID.'
    name: builtins.str
    'A unique identifier at the org level.'
    schedule: builtins.str
    'A cron expression representing the expected execution schedule in UTC (note this also\n    defines the input time window; an hourly schedule would process 1 hour of data at a time).\n    '
    enable_backfill: builtins.bool
    "When true, pipeline runs will be scheduled for the organization's past data."
    data_source_type: app.data.v1.data_pb2.TabularDataSourceType.ValueType
    'The type of data source for the pipeline. If not specified, default is standard data storage.'

    @property
    def mql_binary(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.bytes]:
        """A MongoDB aggregation pipeline as a list of BSON documents, where
        each document is one stage in the pipeline.
        """

    def __init__(self, *, organization_id: builtins.str=..., name: builtins.str=..., mql_binary: collections.abc.Iterable[builtins.bytes] | None=..., schedule: builtins.str=..., enable_backfill: builtins.bool | None=..., data_source_type: app.data.v1.data_pb2.TabularDataSourceType.ValueType | None=...) -> None:
        ...

    def HasField(self, field_name: typing.Literal['_data_source_type', b'_data_source_type', '_enable_backfill', b'_enable_backfill', 'data_source_type', b'data_source_type', 'enable_backfill', b'enable_backfill']) -> builtins.bool:
        ...

    def ClearField(self, field_name: typing.Literal['_data_source_type', b'_data_source_type', '_enable_backfill', b'_enable_backfill', 'data_source_type', b'data_source_type', 'enable_backfill', b'enable_backfill', 'mql_binary', b'mql_binary', 'name', b'name', 'organization_id', b'organization_id', 'schedule', b'schedule']) -> None:
        ...

    @typing.overload
    def WhichOneof(self, oneof_group: typing.Literal['_data_source_type', b'_data_source_type']) -> typing.Literal['data_source_type'] | None:
        ...

    @typing.overload
    def WhichOneof(self, oneof_group: typing.Literal['_enable_backfill', b'_enable_backfill']) -> typing.Literal['enable_backfill'] | None:
        ...
global___CreateDataPipelineRequest = CreateDataPipelineRequest

@typing.final
class CreateDataPipelineResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    ID_FIELD_NUMBER: builtins.int
    id: builtins.str
    'The ID of the newly created data pipeline.'

    def __init__(self, *, id: builtins.str=...) -> None:
        ...

    def ClearField(self, field_name: typing.Literal['id', b'id']) -> None:
        ...
global___CreateDataPipelineResponse = CreateDataPipelineResponse

@typing.final
class UpdateDataPipelineRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    ID_FIELD_NUMBER: builtins.int
    NAME_FIELD_NUMBER: builtins.int
    MQL_BINARY_FIELD_NUMBER: builtins.int
    SCHEDULE_FIELD_NUMBER: builtins.int
    DATA_SOURCE_TYPE_FIELD_NUMBER: builtins.int
    id: builtins.str
    'The ID of the data pipeline to update.'
    name: builtins.str
    'A unique identifier at the org level.'
    schedule: builtins.str
    'A cron expression representing the expected execution schedule in UTC (note this also\n    defines the input time window; an hourly schedule would process 1 hour of data at a time).\n    '
    data_source_type: app.data.v1.data_pb2.TabularDataSourceType.ValueType
    'The type of data source for the pipeline. If not specified, default is standard data storage.'

    @property
    def mql_binary(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.bytes]:
        """A MongoDB aggregation pipeline as a list of BSON documents, where
        each document is one stage in the pipeline.
        """

    def __init__(self, *, id: builtins.str=..., name: builtins.str=..., mql_binary: collections.abc.Iterable[builtins.bytes] | None=..., schedule: builtins.str=..., data_source_type: app.data.v1.data_pb2.TabularDataSourceType.ValueType | None=...) -> None:
        ...

    def HasField(self, field_name: typing.Literal['_data_source_type', b'_data_source_type', 'data_source_type', b'data_source_type']) -> builtins.bool:
        ...

    def ClearField(self, field_name: typing.Literal['_data_source_type', b'_data_source_type', 'data_source_type', b'data_source_type', 'id', b'id', 'mql_binary', b'mql_binary', 'name', b'name', 'schedule', b'schedule']) -> None:
        ...

    def WhichOneof(self, oneof_group: typing.Literal['_data_source_type', b'_data_source_type']) -> typing.Literal['data_source_type'] | None:
        ...
global___UpdateDataPipelineRequest = UpdateDataPipelineRequest

@typing.final
class UpdateDataPipelineResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    def __init__(self) -> None:
        ...
global___UpdateDataPipelineResponse = UpdateDataPipelineResponse

@typing.final
class DeleteDataPipelineRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    ID_FIELD_NUMBER: builtins.int
    id: builtins.str
    'The ID of the data pipeline to delete.'

    def __init__(self, *, id: builtins.str=...) -> None:
        ...

    def ClearField(self, field_name: typing.Literal['id', b'id']) -> None:
        ...
global___DeleteDataPipelineRequest = DeleteDataPipelineRequest

@typing.final
class DeleteDataPipelineResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    def __init__(self) -> None:
        ...
global___DeleteDataPipelineResponse = DeleteDataPipelineResponse

@typing.final
class EnableDataPipelineRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    ID_FIELD_NUMBER: builtins.int
    id: builtins.str
    'The ID of the data pipeline to enable.'

    def __init__(self, *, id: builtins.str=...) -> None:
        ...

    def ClearField(self, field_name: typing.Literal['id', b'id']) -> None:
        ...
global___EnableDataPipelineRequest = EnableDataPipelineRequest

@typing.final
class EnableDataPipelineResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    def __init__(self) -> None:
        ...
global___EnableDataPipelineResponse = EnableDataPipelineResponse

@typing.final
class DisableDataPipelineRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    ID_FIELD_NUMBER: builtins.int
    id: builtins.str
    'The ID of the data pipeline to disable.'

    def __init__(self, *, id: builtins.str=...) -> None:
        ...

    def ClearField(self, field_name: typing.Literal['id', b'id']) -> None:
        ...
global___DisableDataPipelineRequest = DisableDataPipelineRequest

@typing.final
class DisableDataPipelineResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    def __init__(self) -> None:
        ...
global___DisableDataPipelineResponse = DisableDataPipelineResponse

@typing.final
class ListDataPipelineRunsRequest(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    ID_FIELD_NUMBER: builtins.int
    PAGE_SIZE_FIELD_NUMBER: builtins.int
    PAGE_TOKEN_FIELD_NUMBER: builtins.int
    id: builtins.str
    'The ID of the data pipeline to list runs for.'
    page_size: builtins.int
    'pagination fields'
    page_token: builtins.str

    def __init__(self, *, id: builtins.str=..., page_size: builtins.int=..., page_token: builtins.str=...) -> None:
        ...

    def ClearField(self, field_name: typing.Literal['id', b'id', 'page_size', b'page_size', 'page_token', b'page_token']) -> None:
        ...
global___ListDataPipelineRunsRequest = ListDataPipelineRunsRequest

@typing.final
class ListDataPipelineRunsResponse(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    PIPELINE_ID_FIELD_NUMBER: builtins.int
    RUNS_FIELD_NUMBER: builtins.int
    NEXT_PAGE_TOKEN_FIELD_NUMBER: builtins.int
    pipeline_id: builtins.str
    'The ID of the data pipeline the runs are for.'
    next_page_token: builtins.str
    'A token to retrieve the next page of results.'

    @property
    def runs(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___DataPipelineRun]:
        """The runs that were run."""

    def __init__(self, *, pipeline_id: builtins.str=..., runs: collections.abc.Iterable[global___DataPipelineRun] | None=..., next_page_token: builtins.str=...) -> None:
        ...

    def ClearField(self, field_name: typing.Literal['next_page_token', b'next_page_token', 'pipeline_id', b'pipeline_id', 'runs', b'runs']) -> None:
        ...
global___ListDataPipelineRunsResponse = ListDataPipelineRunsResponse

@typing.final
class DataPipelineRun(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor
    ID_FIELD_NUMBER: builtins.int
    START_TIME_FIELD_NUMBER: builtins.int
    END_TIME_FIELD_NUMBER: builtins.int
    DATA_START_TIME_FIELD_NUMBER: builtins.int
    DATA_END_TIME_FIELD_NUMBER: builtins.int
    STATUS_FIELD_NUMBER: builtins.int
    id: builtins.str
    'The ID of the run.'
    status: global___DataPipelineRunStatus.ValueType
    'The status of the run.'

    @property
    def start_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """The time the run started."""

    @property
    def end_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """The time the run ended."""

    @property
    def data_start_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """The start time of the data that was processed in the run."""

    @property
    def data_end_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """The end time of the data that was processed in the run."""

    def __init__(self, *, id: builtins.str=..., start_time: google.protobuf.timestamp_pb2.Timestamp | None=..., end_time: google.protobuf.timestamp_pb2.Timestamp | None=..., data_start_time: google.protobuf.timestamp_pb2.Timestamp | None=..., data_end_time: google.protobuf.timestamp_pb2.Timestamp | None=..., status: global___DataPipelineRunStatus.ValueType=...) -> None:
        ...

    def HasField(self, field_name: typing.Literal['data_end_time', b'data_end_time', 'data_start_time', b'data_start_time', 'end_time', b'end_time', 'start_time', b'start_time']) -> builtins.bool:
        ...

    def ClearField(self, field_name: typing.Literal['data_end_time', b'data_end_time', 'data_start_time', b'data_start_time', 'end_time', b'end_time', 'id', b'id', 'start_time', b'start_time', 'status', b'status']) -> None:
        ...
global___DataPipelineRun = DataPipelineRun