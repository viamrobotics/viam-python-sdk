"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import google.protobuf.descriptor
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor = ...

class _SsmlVoiceGender:
    ValueType = typing.NewType('ValueType', builtins.int)
    V: typing_extensions.TypeAlias = ValueType
class _SsmlVoiceGenderEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_SsmlVoiceGender.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
    SSML_VOICE_GENDER_UNSPECIFIED: SsmlVoiceGender.ValueType = ...  # 0
    """An unspecified gender.
    In VoiceSelectionParams, this means that the client doesn't care which
    gender the selected voice will have. In the Voice field of
    ListVoicesResponse, this may mean that the voice doesn't fit any of the
    other categories in this enum, or that the gender of the voice isn't known.
    """

    MALE: SsmlVoiceGender.ValueType = ...  # 1
    """A male voice."""

    FEMALE: SsmlVoiceGender.ValueType = ...  # 2
    """A female voice."""

    NEUTRAL: SsmlVoiceGender.ValueType = ...  # 3
    """A gender-neutral voice. This voice is not yet supported."""

class SsmlVoiceGender(_SsmlVoiceGender, metaclass=_SsmlVoiceGenderEnumTypeWrapper):
    """Gender of the voice as described in
    [SSML voice element](https://www.w3.org/TR/speech-synthesis11/#edef_voice).
    """
    pass

SSML_VOICE_GENDER_UNSPECIFIED: SsmlVoiceGender.ValueType = ...  # 0
"""An unspecified gender.
In VoiceSelectionParams, this means that the client doesn't care which
gender the selected voice will have. In the Voice field of
ListVoicesResponse, this may mean that the voice doesn't fit any of the
other categories in this enum, or that the gender of the voice isn't known.
"""

MALE: SsmlVoiceGender.ValueType = ...  # 1
"""A male voice."""

FEMALE: SsmlVoiceGender.ValueType = ...  # 2
"""A female voice."""

NEUTRAL: SsmlVoiceGender.ValueType = ...  # 3
"""A gender-neutral voice. This voice is not yet supported."""

global___SsmlVoiceGender = SsmlVoiceGender


class _AudioEncoding:
    ValueType = typing.NewType('ValueType', builtins.int)
    V: typing_extensions.TypeAlias = ValueType
class _AudioEncodingEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_AudioEncoding.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
    AUDIO_ENCODING_UNSPECIFIED: AudioEncoding.ValueType = ...  # 0
    """Not specified. Will return result [google.rpc.Code.INVALID_ARGUMENT][]."""

    LINEAR16: AudioEncoding.ValueType = ...  # 1
    """Uncompressed 16-bit signed little-endian samples (Linear PCM).
    Audio content returned as LINEAR16 also contains a WAV header.
    """

    MP3: AudioEncoding.ValueType = ...  # 2
    """MP3 audio at 32kbps."""

    MP3_64_KBPS: AudioEncoding.ValueType = ...  # 4
    """MP3 at 64kbps."""

    OGG_OPUS: AudioEncoding.ValueType = ...  # 3
    """Opus encoded audio wrapped in an ogg container. The result will be a
    file which can be played natively on Android, and in browsers (at least
    Chrome and Firefox). The quality of the encoding is considerably higher
    than MP3 while using approximately the same bitrate.
    """

    MULAW: AudioEncoding.ValueType = ...  # 5
    """8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
    Audio content returned as MULAW also contains a WAV header.
    """

    ALAW: AudioEncoding.ValueType = ...  # 6
    """8-bit samples that compand 14-bit audio samples using G.711 PCMU/A-law.
    Audio content returned as ALAW also contains a WAV header.
    """

class AudioEncoding(_AudioEncoding, metaclass=_AudioEncodingEnumTypeWrapper):
    """Configuration to set up audio encoder. The encoding determines the output
    audio format that we'd like.
    """
    pass

AUDIO_ENCODING_UNSPECIFIED: AudioEncoding.ValueType = ...  # 0
"""Not specified. Will return result [google.rpc.Code.INVALID_ARGUMENT][]."""

LINEAR16: AudioEncoding.ValueType = ...  # 1
"""Uncompressed 16-bit signed little-endian samples (Linear PCM).
Audio content returned as LINEAR16 also contains a WAV header.
"""

MP3: AudioEncoding.ValueType = ...  # 2
"""MP3 audio at 32kbps."""

MP3_64_KBPS: AudioEncoding.ValueType = ...  # 4
"""MP3 at 64kbps."""

OGG_OPUS: AudioEncoding.ValueType = ...  # 3
"""Opus encoded audio wrapped in an ogg container. The result will be a
file which can be played natively on Android, and in browsers (at least
Chrome and Firefox). The quality of the encoding is considerably higher
than MP3 while using approximately the same bitrate.
"""

MULAW: AudioEncoding.ValueType = ...  # 5
"""8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
Audio content returned as MULAW also contains a WAV header.
"""

ALAW: AudioEncoding.ValueType = ...  # 6
"""8-bit samples that compand 14-bit audio samples using G.711 PCMU/A-law.
Audio content returned as ALAW also contains a WAV header.
"""

global___AudioEncoding = AudioEncoding


class ListVoicesRequest(google.protobuf.message.Message):
    """The top-level message sent by the client for the `ListVoices` method."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    LANGUAGE_CODE_FIELD_NUMBER: builtins.int
    language_code: typing.Text = ...
    """Optional. Recommended.
    [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
    If not specified, the API will return all supported voices.
    If specified, the ListVoices call will only return voices that can be used
    to synthesize this language_code. For example, if you specify `"en-NZ"`,
    all `"en-NZ"` voices will be returned. If you specify `"no"`, both
    `"no-\\*"` (Norwegian) and `"nb-\\*"` (Norwegian Bokmal) voices will be
    returned.
    """

    def __init__(self,
        *,
        language_code : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["language_code",b"language_code"]) -> None: ...
global___ListVoicesRequest = ListVoicesRequest

class ListVoicesResponse(google.protobuf.message.Message):
    """The message returned to the client by the `ListVoices` method."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    VOICES_FIELD_NUMBER: builtins.int
    @property
    def voices(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Voice]:
        """The list of voices."""
        pass
    def __init__(self,
        *,
        voices : typing.Optional[typing.Iterable[global___Voice]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["voices",b"voices"]) -> None: ...
global___ListVoicesResponse = ListVoicesResponse

class Voice(google.protobuf.message.Message):
    """Description of a voice supported by the TTS service."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    LANGUAGE_CODES_FIELD_NUMBER: builtins.int
    NAME_FIELD_NUMBER: builtins.int
    SSML_GENDER_FIELD_NUMBER: builtins.int
    NATURAL_SAMPLE_RATE_HERTZ_FIELD_NUMBER: builtins.int
    @property
    def language_codes(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
        """The languages that this voice supports, expressed as
        [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tags (e.g.
        "en-US", "es-419", "cmn-tw").
        """
        pass
    name: typing.Text = ...
    """The name of this voice.  Each distinct voice has a unique name."""

    ssml_gender: global___SsmlVoiceGender.ValueType = ...
    """The gender of this voice."""

    natural_sample_rate_hertz: builtins.int = ...
    """The natural sample rate (in hertz) for this voice."""

    def __init__(self,
        *,
        language_codes : typing.Optional[typing.Iterable[typing.Text]] = ...,
        name : typing.Text = ...,
        ssml_gender : global___SsmlVoiceGender.ValueType = ...,
        natural_sample_rate_hertz : builtins.int = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["language_codes",b"language_codes","name",b"name","natural_sample_rate_hertz",b"natural_sample_rate_hertz","ssml_gender",b"ssml_gender"]) -> None: ...
global___Voice = Voice

class SynthesizeSpeechRequest(google.protobuf.message.Message):
    """The top-level message sent by the client for the `SynthesizeSpeech` method."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class _TimepointType:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _TimepointTypeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_TimepointType.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        TIMEPOINT_TYPE_UNSPECIFIED: SynthesizeSpeechRequest.TimepointType.ValueType = ...  # 0
        """Not specified. No timepoint information will be returned."""

        SSML_MARK: SynthesizeSpeechRequest.TimepointType.ValueType = ...  # 1
        """Timepoint information of `<mark>` tags in SSML input will be returned."""

    class TimepointType(_TimepointType, metaclass=_TimepointTypeEnumTypeWrapper):
        """The type of timepoint information that is returned in the response."""
        pass

    TIMEPOINT_TYPE_UNSPECIFIED: SynthesizeSpeechRequest.TimepointType.ValueType = ...  # 0
    """Not specified. No timepoint information will be returned."""

    SSML_MARK: SynthesizeSpeechRequest.TimepointType.ValueType = ...  # 1
    """Timepoint information of `<mark>` tags in SSML input will be returned."""


    INPUT_FIELD_NUMBER: builtins.int
    VOICE_FIELD_NUMBER: builtins.int
    AUDIO_CONFIG_FIELD_NUMBER: builtins.int
    ENABLE_TIME_POINTING_FIELD_NUMBER: builtins.int
    @property
    def input(self) -> global___SynthesisInput:
        """Required. The Synthesizer requires either plain text or SSML as input."""
        pass
    @property
    def voice(self) -> global___VoiceSelectionParams:
        """Required. The desired voice of the synthesized audio."""
        pass
    @property
    def audio_config(self) -> global___AudioConfig:
        """Required. The configuration of the synthesized audio."""
        pass
    @property
    def enable_time_pointing(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[global___SynthesizeSpeechRequest.TimepointType.ValueType]:
        """Whether and what timepoints are returned in the response."""
        pass
    def __init__(self,
        *,
        input : typing.Optional[global___SynthesisInput] = ...,
        voice : typing.Optional[global___VoiceSelectionParams] = ...,
        audio_config : typing.Optional[global___AudioConfig] = ...,
        enable_time_pointing : typing.Optional[typing.Iterable[global___SynthesizeSpeechRequest.TimepointType.ValueType]] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["audio_config",b"audio_config","input",b"input","voice",b"voice"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["audio_config",b"audio_config","enable_time_pointing",b"enable_time_pointing","input",b"input","voice",b"voice"]) -> None: ...
global___SynthesizeSpeechRequest = SynthesizeSpeechRequest

class SynthesisInput(google.protobuf.message.Message):
    """Contains text input to be synthesized. Either `text` or `ssml` must be
    supplied. Supplying both or neither returns
    [google.rpc.Code.INVALID_ARGUMENT][]. The input size is limited to 5000
    characters.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    TEXT_FIELD_NUMBER: builtins.int
    SSML_FIELD_NUMBER: builtins.int
    text: typing.Text = ...
    """The raw text to be synthesized."""

    ssml: typing.Text = ...
    """The SSML document to be synthesized. The SSML document must be valid
    and well-formed. Otherwise the RPC will fail and return
    [google.rpc.Code.INVALID_ARGUMENT][]. For more information, see
    [SSML](https://cloud.google.com/text-to-speech/docs/ssml).
    """

    def __init__(self,
        *,
        text : typing.Text = ...,
        ssml : typing.Text = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["input_source",b"input_source","ssml",b"ssml","text",b"text"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["input_source",b"input_source","ssml",b"ssml","text",b"text"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["input_source",b"input_source"]) -> typing.Optional[typing_extensions.Literal["text","ssml"]]: ...
global___SynthesisInput = SynthesisInput

class VoiceSelectionParams(google.protobuf.message.Message):
    """Description of which voice to use for a synthesis request."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    LANGUAGE_CODE_FIELD_NUMBER: builtins.int
    NAME_FIELD_NUMBER: builtins.int
    SSML_GENDER_FIELD_NUMBER: builtins.int
    CUSTOM_VOICE_FIELD_NUMBER: builtins.int
    language_code: typing.Text = ...
    """Required. The language (and potentially also the region) of the voice expressed as a
    [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag, e.g.
    "en-US". This should not include a script tag (e.g. use
    "cmn-cn" rather than "cmn-Hant-cn"), because the script will be inferred
    from the input provided in the SynthesisInput.  The TTS service
    will use this parameter to help choose an appropriate voice.  Note that
    the TTS service may choose a voice with a slightly different language code
    than the one selected; it may substitute a different region
    (e.g. using en-US rather than en-CA if there isn't a Canadian voice
    available), or even a different language, e.g. using "nb" (Norwegian
    Bokmal) instead of "no" (Norwegian)".
    """

    name: typing.Text = ...
    """The name of the voice. If not set, the service will choose a
    voice based on the other parameters such as language_code and gender.
    """

    ssml_gender: global___SsmlVoiceGender.ValueType = ...
    """The preferred gender of the voice. If not set, the service will
    choose a voice based on the other parameters such as language_code and
    name. Note that this is only a preference, not requirement; if a
    voice of the appropriate gender is not available, the synthesizer should
    substitute a voice with a different gender rather than failing the request.
    """

    @property
    def custom_voice(self) -> global___CustomVoiceParams:
        """The configuration for a custom voice. If [CustomVoiceParams.model] is set,
        the service will choose the custom voice matching the specified
        configuration.
        """
        pass
    def __init__(self,
        *,
        language_code : typing.Text = ...,
        name : typing.Text = ...,
        ssml_gender : global___SsmlVoiceGender.ValueType = ...,
        custom_voice : typing.Optional[global___CustomVoiceParams] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["custom_voice",b"custom_voice"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["custom_voice",b"custom_voice","language_code",b"language_code","name",b"name","ssml_gender",b"ssml_gender"]) -> None: ...
global___VoiceSelectionParams = VoiceSelectionParams

class AudioConfig(google.protobuf.message.Message):
    """Description of audio data to be synthesized."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    AUDIO_ENCODING_FIELD_NUMBER: builtins.int
    SPEAKING_RATE_FIELD_NUMBER: builtins.int
    PITCH_FIELD_NUMBER: builtins.int
    VOLUME_GAIN_DB_FIELD_NUMBER: builtins.int
    SAMPLE_RATE_HERTZ_FIELD_NUMBER: builtins.int
    EFFECTS_PROFILE_ID_FIELD_NUMBER: builtins.int
    audio_encoding: global___AudioEncoding.ValueType = ...
    """Required. The format of the audio byte stream."""

    speaking_rate: builtins.float = ...
    """Optional. Input only. Speaking rate/speed, in the range [0.25, 4.0]. 1.0 is
    the normal native speed supported by the specific voice. 2.0 is twice as
    fast, and 0.5 is half as fast. If unset(0.0), defaults to the native 1.0
    speed. Any other values < 0.25 or > 4.0 will return an error.
    """

    pitch: builtins.float = ...
    """Optional. Input only. Speaking pitch, in the range [-20.0, 20.0]. 20 means
    increase 20 semitones from the original pitch. -20 means decrease 20
    semitones from the original pitch.
    """

    volume_gain_db: builtins.float = ...
    """Optional. Input only. Volume gain (in dB) of the normal native volume
    supported by the specific voice, in the range [-96.0, 16.0]. If unset, or
    set to a value of 0.0 (dB), will play at normal native signal amplitude. A
    value of -6.0 (dB) will play at approximately half the amplitude of the
    normal native signal amplitude. A value of +6.0 (dB) will play at
    approximately twice the amplitude of the normal native signal amplitude.
    Strongly recommend not to exceed +10 (dB) as there's usually no effective
    increase in loudness for any value greater than that.
    """

    sample_rate_hertz: builtins.int = ...
    """Optional. The synthesis sample rate (in hertz) for this audio. When this is
    specified in SynthesizeSpeechRequest, if this is different from the voice's
    natural sample rate, then the synthesizer will honor this request by
    converting to the desired sample rate (which might result in worse audio
    quality), unless the specified sample rate is not supported for the
    encoding chosen, in which case it will fail the request and return
    [google.rpc.Code.INVALID_ARGUMENT][].
    """

    @property
    def effects_profile_id(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
        """Optional. Input only. An identifier which selects 'audio effects' profiles
        that are applied on (post synthesized) text to speech. Effects are applied
        on top of each other in the order they are given. See
        [audio
        profiles](https://cloud.google.com/text-to-speech/docs/audio-profiles) for
        current supported profile ids.
        """
        pass
    def __init__(self,
        *,
        audio_encoding : global___AudioEncoding.ValueType = ...,
        speaking_rate : builtins.float = ...,
        pitch : builtins.float = ...,
        volume_gain_db : builtins.float = ...,
        sample_rate_hertz : builtins.int = ...,
        effects_profile_id : typing.Optional[typing.Iterable[typing.Text]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["audio_encoding",b"audio_encoding","effects_profile_id",b"effects_profile_id","pitch",b"pitch","sample_rate_hertz",b"sample_rate_hertz","speaking_rate",b"speaking_rate","volume_gain_db",b"volume_gain_db"]) -> None: ...
global___AudioConfig = AudioConfig

class CustomVoiceParams(google.protobuf.message.Message):
    """Description of the custom voice to be synthesized."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class _ReportedUsage:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _ReportedUsageEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_ReportedUsage.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        REPORTED_USAGE_UNSPECIFIED: CustomVoiceParams.ReportedUsage.ValueType = ...  # 0
        """Request with reported usage unspecified will be rejected."""

        REALTIME: CustomVoiceParams.ReportedUsage.ValueType = ...  # 1
        """For scenarios where the synthesized audio is not downloadable and can
        only be used once. For example, real-time request in IVR system.
        """

        OFFLINE: CustomVoiceParams.ReportedUsage.ValueType = ...  # 2
        """For scenarios where the synthesized audio is downloadable and can be
        reused. For example, the synthesized audio is downloaded, stored in
        customer service system and played repeatedly.
        """

    class ReportedUsage(_ReportedUsage, metaclass=_ReportedUsageEnumTypeWrapper):
        """The usage of the synthesized audio. You must report your honest and
        correct usage of the service as it's regulated by contract and will cause
        significant difference in billing.
        """
        pass

    REPORTED_USAGE_UNSPECIFIED: CustomVoiceParams.ReportedUsage.ValueType = ...  # 0
    """Request with reported usage unspecified will be rejected."""

    REALTIME: CustomVoiceParams.ReportedUsage.ValueType = ...  # 1
    """For scenarios where the synthesized audio is not downloadable and can
    only be used once. For example, real-time request in IVR system.
    """

    OFFLINE: CustomVoiceParams.ReportedUsage.ValueType = ...  # 2
    """For scenarios where the synthesized audio is downloadable and can be
    reused. For example, the synthesized audio is downloaded, stored in
    customer service system and played repeatedly.
    """


    MODEL_FIELD_NUMBER: builtins.int
    REPORTED_USAGE_FIELD_NUMBER: builtins.int
    model: typing.Text = ...
    """Required. The name of the AutoML model that synthesizes the custom voice."""

    reported_usage: global___CustomVoiceParams.ReportedUsage.ValueType = ...
    """Optional. The usage of the synthesized audio to be reported."""

    def __init__(self,
        *,
        model : typing.Text = ...,
        reported_usage : global___CustomVoiceParams.ReportedUsage.ValueType = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["model",b"model","reported_usage",b"reported_usage"]) -> None: ...
global___CustomVoiceParams = CustomVoiceParams

class SynthesizeSpeechResponse(google.protobuf.message.Message):
    """The message returned to the client by the `SynthesizeSpeech` method."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    AUDIO_CONTENT_FIELD_NUMBER: builtins.int
    TIMEPOINTS_FIELD_NUMBER: builtins.int
    AUDIO_CONFIG_FIELD_NUMBER: builtins.int
    audio_content: builtins.bytes = ...
    """The audio data bytes encoded as specified in the request, including the
    header for encodings that are wrapped in containers (e.g. MP3, OGG_OPUS).
    For LINEAR16 audio, we include the WAV header. Note: as
    with all bytes fields, protobuffers use a pure binary representation,
    whereas JSON representations use base64.
    """

    @property
    def timepoints(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Timepoint]:
        """A link between a position in the original request input and a corresponding
        time in the output audio. It's only supported via `<mark>` of SSML input.
        """
        pass
    @property
    def audio_config(self) -> global___AudioConfig:
        """The audio metadata of `audio_content`."""
        pass
    def __init__(self,
        *,
        audio_content : builtins.bytes = ...,
        timepoints : typing.Optional[typing.Iterable[global___Timepoint]] = ...,
        audio_config : typing.Optional[global___AudioConfig] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["audio_config",b"audio_config"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["audio_config",b"audio_config","audio_content",b"audio_content","timepoints",b"timepoints"]) -> None: ...
global___SynthesizeSpeechResponse = SynthesizeSpeechResponse

class Timepoint(google.protobuf.message.Message):
    """This contains a mapping between a certain point in the input text and a
    corresponding time in the output audio.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    MARK_NAME_FIELD_NUMBER: builtins.int
    TIME_SECONDS_FIELD_NUMBER: builtins.int
    mark_name: typing.Text = ...
    """Timepoint name as received from the client within `<mark>` tag."""

    time_seconds: builtins.float = ...
    """Time offset in seconds from the start of the synthesized audio."""

    def __init__(self,
        *,
        mark_name : typing.Text = ...,
        time_seconds : builtins.float = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["mark_name",b"mark_name","time_seconds",b"time_seconds"]) -> None: ...
global___Timepoint = Timepoint
