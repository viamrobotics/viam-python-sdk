"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import google.cloud.aiplatform.v1beta1.io_pb2
import google.protobuf.descriptor
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor = ...

class ModelMonitoringObjectiveConfig(google.protobuf.message.Message):
    """Next ID: 6"""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class TrainingDataset(google.protobuf.message.Message):
        """Training Dataset information."""
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        DATASET_FIELD_NUMBER: builtins.int
        GCS_SOURCE_FIELD_NUMBER: builtins.int
        BIGQUERY_SOURCE_FIELD_NUMBER: builtins.int
        DATA_FORMAT_FIELD_NUMBER: builtins.int
        TARGET_FIELD_FIELD_NUMBER: builtins.int
        LOGGING_SAMPLING_STRATEGY_FIELD_NUMBER: builtins.int
        dataset: typing.Text = ...
        """The resource name of the Dataset used to train this Model."""

        @property
        def gcs_source(self) -> google.cloud.aiplatform.v1beta1.io_pb2.GcsSource:
            """The Google Cloud Storage uri of the unmanaged Dataset used to train
            this Model.
            """
            pass
        @property
        def bigquery_source(self) -> google.cloud.aiplatform.v1beta1.io_pb2.BigQuerySource:
            """The BigQuery table of the unmanaged Dataset used to train this
            Model.
            """
            pass
        data_format: typing.Text = ...
        """Data format of the dataset, only applicable if the input is from
        Google Cloud Storage.
        The possible formats are:

        "tf-record"
        The source file is a TFRecord file.

        "csv"
        The source file is a CSV file.
        """

        target_field: typing.Text = ...
        """The target field name the model is to predict.
        This field will be excluded when doing Predict and (or) Explain for the
        training data.
        """

        @property
        def logging_sampling_strategy(self) -> global___SamplingStrategy:
            """Strategy to sample data from Training Dataset.
            If not set, we process the whole dataset.
            """
            pass
        def __init__(self,
            *,
            dataset : typing.Text = ...,
            gcs_source : typing.Optional[google.cloud.aiplatform.v1beta1.io_pb2.GcsSource] = ...,
            bigquery_source : typing.Optional[google.cloud.aiplatform.v1beta1.io_pb2.BigQuerySource] = ...,
            data_format : typing.Text = ...,
            target_field : typing.Text = ...,
            logging_sampling_strategy : typing.Optional[global___SamplingStrategy] = ...,
            ) -> None: ...
        def HasField(self, field_name: typing_extensions.Literal["bigquery_source",b"bigquery_source","data_source",b"data_source","dataset",b"dataset","gcs_source",b"gcs_source","logging_sampling_strategy",b"logging_sampling_strategy"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing_extensions.Literal["bigquery_source",b"bigquery_source","data_format",b"data_format","data_source",b"data_source","dataset",b"dataset","gcs_source",b"gcs_source","logging_sampling_strategy",b"logging_sampling_strategy","target_field",b"target_field"]) -> None: ...
        def WhichOneof(self, oneof_group: typing_extensions.Literal["data_source",b"data_source"]) -> typing.Optional[typing_extensions.Literal["dataset","gcs_source","bigquery_source"]]: ...

    class TrainingPredictionSkewDetectionConfig(google.protobuf.message.Message):
        """The config for Training & Prediction data skew detection. It specifies the
        training dataset sources and the skew detection parameters.
        """
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        class SkewThresholdsEntry(google.protobuf.message.Message):
            DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
            KEY_FIELD_NUMBER: builtins.int
            VALUE_FIELD_NUMBER: builtins.int
            key: typing.Text = ...
            @property
            def value(self) -> global___ThresholdConfig: ...
            def __init__(self,
                *,
                key : typing.Text = ...,
                value : typing.Optional[global___ThresholdConfig] = ...,
                ) -> None: ...
            def HasField(self, field_name: typing_extensions.Literal["value",b"value"]) -> builtins.bool: ...
            def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

        class AttributionScoreSkewThresholdsEntry(google.protobuf.message.Message):
            DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
            KEY_FIELD_NUMBER: builtins.int
            VALUE_FIELD_NUMBER: builtins.int
            key: typing.Text = ...
            @property
            def value(self) -> global___ThresholdConfig: ...
            def __init__(self,
                *,
                key : typing.Text = ...,
                value : typing.Optional[global___ThresholdConfig] = ...,
                ) -> None: ...
            def HasField(self, field_name: typing_extensions.Literal["value",b"value"]) -> builtins.bool: ...
            def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

        SKEW_THRESHOLDS_FIELD_NUMBER: builtins.int
        ATTRIBUTION_SCORE_SKEW_THRESHOLDS_FIELD_NUMBER: builtins.int
        @property
        def skew_thresholds(self) -> google.protobuf.internal.containers.MessageMap[typing.Text, global___ThresholdConfig]:
            """Key is the feature name and value is the threshold. If a feature needs to
            be monitored for skew, a value threshold must be configured for that
            feature. The threshold here is against feature distribution distance
            between the training and prediction feature.
            """
            pass
        @property
        def attribution_score_skew_thresholds(self) -> google.protobuf.internal.containers.MessageMap[typing.Text, global___ThresholdConfig]:
            """Key is the feature name and value is the threshold. The threshold here is
            against attribution score distance between the training and prediction
            feature.
            """
            pass
        def __init__(self,
            *,
            skew_thresholds : typing.Optional[typing.Mapping[typing.Text, global___ThresholdConfig]] = ...,
            attribution_score_skew_thresholds : typing.Optional[typing.Mapping[typing.Text, global___ThresholdConfig]] = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["attribution_score_skew_thresholds",b"attribution_score_skew_thresholds","skew_thresholds",b"skew_thresholds"]) -> None: ...

    class PredictionDriftDetectionConfig(google.protobuf.message.Message):
        """The config for Prediction data drift detection."""
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        class DriftThresholdsEntry(google.protobuf.message.Message):
            DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
            KEY_FIELD_NUMBER: builtins.int
            VALUE_FIELD_NUMBER: builtins.int
            key: typing.Text = ...
            @property
            def value(self) -> global___ThresholdConfig: ...
            def __init__(self,
                *,
                key : typing.Text = ...,
                value : typing.Optional[global___ThresholdConfig] = ...,
                ) -> None: ...
            def HasField(self, field_name: typing_extensions.Literal["value",b"value"]) -> builtins.bool: ...
            def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

        class AttributionScoreDriftThresholdsEntry(google.protobuf.message.Message):
            DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
            KEY_FIELD_NUMBER: builtins.int
            VALUE_FIELD_NUMBER: builtins.int
            key: typing.Text = ...
            @property
            def value(self) -> global___ThresholdConfig: ...
            def __init__(self,
                *,
                key : typing.Text = ...,
                value : typing.Optional[global___ThresholdConfig] = ...,
                ) -> None: ...
            def HasField(self, field_name: typing_extensions.Literal["value",b"value"]) -> builtins.bool: ...
            def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

        DRIFT_THRESHOLDS_FIELD_NUMBER: builtins.int
        ATTRIBUTION_SCORE_DRIFT_THRESHOLDS_FIELD_NUMBER: builtins.int
        @property
        def drift_thresholds(self) -> google.protobuf.internal.containers.MessageMap[typing.Text, global___ThresholdConfig]:
            """Key is the feature name and value is the threshold. If a feature needs to
            be monitored for drift, a value threshold must be configured for that
            feature. The threshold here is against feature distribution distance
            between different time windws.
            """
            pass
        @property
        def attribution_score_drift_thresholds(self) -> google.protobuf.internal.containers.MessageMap[typing.Text, global___ThresholdConfig]:
            """Key is the feature name and value is the threshold. The threshold here is
            against attribution score distance between different time windows.
            """
            pass
        def __init__(self,
            *,
            drift_thresholds : typing.Optional[typing.Mapping[typing.Text, global___ThresholdConfig]] = ...,
            attribution_score_drift_thresholds : typing.Optional[typing.Mapping[typing.Text, global___ThresholdConfig]] = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["attribution_score_drift_thresholds",b"attribution_score_drift_thresholds","drift_thresholds",b"drift_thresholds"]) -> None: ...

    class ExplanationConfig(google.protobuf.message.Message):
        """The config for integrating with Vertex Explainable AI. Only applicable if
        the Model has explanation_spec populated.
        """
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        class ExplanationBaseline(google.protobuf.message.Message):
            """Output from [BatchPredictionJob][google.cloud.aiplatform.v1beta1.BatchPredictionJob] for Model Monitoring baseline dataset,
            which can be used to generate baseline attribution scores.
            """
            DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
            class _PredictionFormat:
                ValueType = typing.NewType('ValueType', builtins.int)
                V: typing_extensions.TypeAlias = ValueType
            class _PredictionFormatEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_PredictionFormat.ValueType], builtins.type):
                DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
                PREDICTION_FORMAT_UNSPECIFIED: ModelMonitoringObjectiveConfig.ExplanationConfig.ExplanationBaseline.PredictionFormat.ValueType = ...  # 0
                """Should not be set."""

                JSONL: ModelMonitoringObjectiveConfig.ExplanationConfig.ExplanationBaseline.PredictionFormat.ValueType = ...  # 2
                """Predictions are in JSONL files."""

                BIGQUERY: ModelMonitoringObjectiveConfig.ExplanationConfig.ExplanationBaseline.PredictionFormat.ValueType = ...  # 3
                """Predictions are in BigQuery."""

            class PredictionFormat(_PredictionFormat, metaclass=_PredictionFormatEnumTypeWrapper):
                """The storage format of the predictions generated BatchPrediction job."""
                pass

            PREDICTION_FORMAT_UNSPECIFIED: ModelMonitoringObjectiveConfig.ExplanationConfig.ExplanationBaseline.PredictionFormat.ValueType = ...  # 0
            """Should not be set."""

            JSONL: ModelMonitoringObjectiveConfig.ExplanationConfig.ExplanationBaseline.PredictionFormat.ValueType = ...  # 2
            """Predictions are in JSONL files."""

            BIGQUERY: ModelMonitoringObjectiveConfig.ExplanationConfig.ExplanationBaseline.PredictionFormat.ValueType = ...  # 3
            """Predictions are in BigQuery."""


            GCS_FIELD_NUMBER: builtins.int
            BIGQUERY_FIELD_NUMBER: builtins.int
            PREDICTION_FORMAT_FIELD_NUMBER: builtins.int
            @property
            def gcs(self) -> google.cloud.aiplatform.v1beta1.io_pb2.GcsDestination:
                """Cloud Storage location for BatchExplain output."""
                pass
            @property
            def bigquery(self) -> google.cloud.aiplatform.v1beta1.io_pb2.BigQueryDestination:
                """BigQuery location for BatchExplain output."""
                pass
            prediction_format: global___ModelMonitoringObjectiveConfig.ExplanationConfig.ExplanationBaseline.PredictionFormat.ValueType = ...
            """The storage format of the predictions generated BatchPrediction job."""

            def __init__(self,
                *,
                gcs : typing.Optional[google.cloud.aiplatform.v1beta1.io_pb2.GcsDestination] = ...,
                bigquery : typing.Optional[google.cloud.aiplatform.v1beta1.io_pb2.BigQueryDestination] = ...,
                prediction_format : global___ModelMonitoringObjectiveConfig.ExplanationConfig.ExplanationBaseline.PredictionFormat.ValueType = ...,
                ) -> None: ...
            def HasField(self, field_name: typing_extensions.Literal["bigquery",b"bigquery","destination",b"destination","gcs",b"gcs"]) -> builtins.bool: ...
            def ClearField(self, field_name: typing_extensions.Literal["bigquery",b"bigquery","destination",b"destination","gcs",b"gcs","prediction_format",b"prediction_format"]) -> None: ...
            def WhichOneof(self, oneof_group: typing_extensions.Literal["destination",b"destination"]) -> typing.Optional[typing_extensions.Literal["gcs","bigquery"]]: ...

        ENABLE_FEATURE_ATTRIBUTES_FIELD_NUMBER: builtins.int
        EXPLANATION_BASELINE_FIELD_NUMBER: builtins.int
        enable_feature_attributes: builtins.bool = ...
        """If want to analyze the Vertex Explainable AI feature attribute scores or
        not. If set to true, Vertex AI will log the feature attributions from
        explain response and do the skew/drift detection for them.
        """

        @property
        def explanation_baseline(self) -> global___ModelMonitoringObjectiveConfig.ExplanationConfig.ExplanationBaseline:
            """Predictions generated by the BatchPredictionJob using baseline dataset."""
            pass
        def __init__(self,
            *,
            enable_feature_attributes : builtins.bool = ...,
            explanation_baseline : typing.Optional[global___ModelMonitoringObjectiveConfig.ExplanationConfig.ExplanationBaseline] = ...,
            ) -> None: ...
        def HasField(self, field_name: typing_extensions.Literal["explanation_baseline",b"explanation_baseline"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing_extensions.Literal["enable_feature_attributes",b"enable_feature_attributes","explanation_baseline",b"explanation_baseline"]) -> None: ...

    TRAINING_DATASET_FIELD_NUMBER: builtins.int
    TRAINING_PREDICTION_SKEW_DETECTION_CONFIG_FIELD_NUMBER: builtins.int
    PREDICTION_DRIFT_DETECTION_CONFIG_FIELD_NUMBER: builtins.int
    EXPLANATION_CONFIG_FIELD_NUMBER: builtins.int
    @property
    def training_dataset(self) -> global___ModelMonitoringObjectiveConfig.TrainingDataset:
        """Training dataset for models. This field has to be set only if
        TrainingPredictionSkewDetectionConfig is specified.
        """
        pass
    @property
    def training_prediction_skew_detection_config(self) -> global___ModelMonitoringObjectiveConfig.TrainingPredictionSkewDetectionConfig:
        """The config for skew between training data and prediction data."""
        pass
    @property
    def prediction_drift_detection_config(self) -> global___ModelMonitoringObjectiveConfig.PredictionDriftDetectionConfig:
        """The config for drift of prediction data."""
        pass
    @property
    def explanation_config(self) -> global___ModelMonitoringObjectiveConfig.ExplanationConfig:
        """The config for integrating with Vertex Explainable AI."""
        pass
    def __init__(self,
        *,
        training_dataset : typing.Optional[global___ModelMonitoringObjectiveConfig.TrainingDataset] = ...,
        training_prediction_skew_detection_config : typing.Optional[global___ModelMonitoringObjectiveConfig.TrainingPredictionSkewDetectionConfig] = ...,
        prediction_drift_detection_config : typing.Optional[global___ModelMonitoringObjectiveConfig.PredictionDriftDetectionConfig] = ...,
        explanation_config : typing.Optional[global___ModelMonitoringObjectiveConfig.ExplanationConfig] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["explanation_config",b"explanation_config","prediction_drift_detection_config",b"prediction_drift_detection_config","training_dataset",b"training_dataset","training_prediction_skew_detection_config",b"training_prediction_skew_detection_config"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["explanation_config",b"explanation_config","prediction_drift_detection_config",b"prediction_drift_detection_config","training_dataset",b"training_dataset","training_prediction_skew_detection_config",b"training_prediction_skew_detection_config"]) -> None: ...
global___ModelMonitoringObjectiveConfig = ModelMonitoringObjectiveConfig

class ModelMonitoringAlertConfig(google.protobuf.message.Message):
    """Next ID: 3"""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class EmailAlertConfig(google.protobuf.message.Message):
        """The config for email alert."""
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        USER_EMAILS_FIELD_NUMBER: builtins.int
        @property
        def user_emails(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
            """The email addresses to send the alert."""
            pass
        def __init__(self,
            *,
            user_emails : typing.Optional[typing.Iterable[typing.Text]] = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["user_emails",b"user_emails"]) -> None: ...

    EMAIL_ALERT_CONFIG_FIELD_NUMBER: builtins.int
    ENABLE_LOGGING_FIELD_NUMBER: builtins.int
    @property
    def email_alert_config(self) -> global___ModelMonitoringAlertConfig.EmailAlertConfig:
        """Email alert config."""
        pass
    enable_logging: builtins.bool = ...
    """Dump the anomalies to Cloud Logging. The anomalies will be put to json
    payload encoded from proto
    [google.cloud.aiplatform.logging.ModelMonitoringAnomaliesLogEntry][].
    This can be further sinked to Pub/Sub or any other services supported
    by Cloud Logging.
    """

    def __init__(self,
        *,
        email_alert_config : typing.Optional[global___ModelMonitoringAlertConfig.EmailAlertConfig] = ...,
        enable_logging : builtins.bool = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["alert",b"alert","email_alert_config",b"email_alert_config"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["alert",b"alert","email_alert_config",b"email_alert_config","enable_logging",b"enable_logging"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["alert",b"alert"]) -> typing.Optional[typing_extensions.Literal["email_alert_config"]]: ...
global___ModelMonitoringAlertConfig = ModelMonitoringAlertConfig

class ThresholdConfig(google.protobuf.message.Message):
    """The config for feature monitoring threshold.
    Next ID: 3
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    VALUE_FIELD_NUMBER: builtins.int
    value: builtins.float = ...
    """Specify a threshold value that can trigger the alert.
    If this threshold config is for feature distribution distance:
      1. For categorical feature, the distribution distance is calculated by
         L-inifinity norm.
      2. For numerical feature, the distribution distance is calculated by
         Jensenâ€“Shannon divergence.
    Each feature must have a non-zero threshold if they need to be monitored.
    Otherwise no alert will be triggered for that feature.
    """

    def __init__(self,
        *,
        value : builtins.float = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["threshold",b"threshold","value",b"value"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["threshold",b"threshold","value",b"value"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["threshold",b"threshold"]) -> typing.Optional[typing_extensions.Literal["value"]]: ...
global___ThresholdConfig = ThresholdConfig

class SamplingStrategy(google.protobuf.message.Message):
    """Sampling Strategy for logging, can be for both training and prediction
    dataset.
    Next ID: 2
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class RandomSampleConfig(google.protobuf.message.Message):
        """Requests are randomly selected."""
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        SAMPLE_RATE_FIELD_NUMBER: builtins.int
        sample_rate: builtins.float = ...
        """Sample rate (0, 1]"""

        def __init__(self,
            *,
            sample_rate : builtins.float = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["sample_rate",b"sample_rate"]) -> None: ...

    RANDOM_SAMPLE_CONFIG_FIELD_NUMBER: builtins.int
    @property
    def random_sample_config(self) -> global___SamplingStrategy.RandomSampleConfig:
        """Random sample config. Will support more sampling strategies later."""
        pass
    def __init__(self,
        *,
        random_sample_config : typing.Optional[global___SamplingStrategy.RandomSampleConfig] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["random_sample_config",b"random_sample_config"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["random_sample_config",b"random_sample_config"]) -> None: ...
global___SamplingStrategy = SamplingStrategy
