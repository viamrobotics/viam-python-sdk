"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import google.cloud.aiplatform.v1beta1.encryption_spec_pb2
import google.cloud.aiplatform.v1beta1.feature_monitoring_stats_pb2
import google.cloud.aiplatform.v1beta1.io_pb2
import google.cloud.aiplatform.v1beta1.job_state_pb2
import google.cloud.aiplatform.v1beta1.model_monitoring_pb2
import google.protobuf.descriptor
import google.protobuf.duration_pb2
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import google.protobuf.struct_pb2
import google.protobuf.timestamp_pb2
import google.rpc.status_pb2
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor = ...

class _ModelDeploymentMonitoringObjectiveType:
    ValueType = typing.NewType('ValueType', builtins.int)
    V: typing_extensions.TypeAlias = ValueType
class _ModelDeploymentMonitoringObjectiveTypeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_ModelDeploymentMonitoringObjectiveType.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
    MODEL_DEPLOYMENT_MONITORING_OBJECTIVE_TYPE_UNSPECIFIED: ModelDeploymentMonitoringObjectiveType.ValueType = ...  # 0
    """Default value, should not be set."""

    RAW_FEATURE_SKEW: ModelDeploymentMonitoringObjectiveType.ValueType = ...  # 1
    """Raw feature values' stats to detect skew between Training-Prediction
    datasets.
    """

    RAW_FEATURE_DRIFT: ModelDeploymentMonitoringObjectiveType.ValueType = ...  # 2
    """Raw feature values' stats to detect drift between Serving-Prediction
    datasets.
    """

    FEATURE_ATTRIBUTION_SKEW: ModelDeploymentMonitoringObjectiveType.ValueType = ...  # 3
    """Feature attribution scores to detect skew between Training-Prediction
    datasets.
    """

    FEATURE_ATTRIBUTION_DRIFT: ModelDeploymentMonitoringObjectiveType.ValueType = ...  # 4
    """Feature attribution scores to detect skew between Prediction datasets
    collected within different time windows.
    """

class ModelDeploymentMonitoringObjectiveType(_ModelDeploymentMonitoringObjectiveType, metaclass=_ModelDeploymentMonitoringObjectiveTypeEnumTypeWrapper):
    """The Model Monitoring Objective types."""
    pass

MODEL_DEPLOYMENT_MONITORING_OBJECTIVE_TYPE_UNSPECIFIED: ModelDeploymentMonitoringObjectiveType.ValueType = ...  # 0
"""Default value, should not be set."""

RAW_FEATURE_SKEW: ModelDeploymentMonitoringObjectiveType.ValueType = ...  # 1
"""Raw feature values' stats to detect skew between Training-Prediction
datasets.
"""

RAW_FEATURE_DRIFT: ModelDeploymentMonitoringObjectiveType.ValueType = ...  # 2
"""Raw feature values' stats to detect drift between Serving-Prediction
datasets.
"""

FEATURE_ATTRIBUTION_SKEW: ModelDeploymentMonitoringObjectiveType.ValueType = ...  # 3
"""Feature attribution scores to detect skew between Training-Prediction
datasets.
"""

FEATURE_ATTRIBUTION_DRIFT: ModelDeploymentMonitoringObjectiveType.ValueType = ...  # 4
"""Feature attribution scores to detect skew between Prediction datasets
collected within different time windows.
"""

global___ModelDeploymentMonitoringObjectiveType = ModelDeploymentMonitoringObjectiveType


class ModelDeploymentMonitoringJob(google.protobuf.message.Message):
    """Represents a job that runs periodically to monitor the deployed models in an
    endpoint. It will analyze the logged training & prediction data to detect any
    abnormal behaviors.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class _MonitoringScheduleState:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _MonitoringScheduleStateEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_MonitoringScheduleState.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        MONITORING_SCHEDULE_STATE_UNSPECIFIED: ModelDeploymentMonitoringJob.MonitoringScheduleState.ValueType = ...  # 0
        """Unspecified state."""

        PENDING: ModelDeploymentMonitoringJob.MonitoringScheduleState.ValueType = ...  # 1
        """The pipeline is picked up and wait to run."""

        OFFLINE: ModelDeploymentMonitoringJob.MonitoringScheduleState.ValueType = ...  # 2
        """The pipeline is offline and will be scheduled for next run."""

        RUNNING: ModelDeploymentMonitoringJob.MonitoringScheduleState.ValueType = ...  # 3
        """The pipeline is running."""

    class MonitoringScheduleState(_MonitoringScheduleState, metaclass=_MonitoringScheduleStateEnumTypeWrapper):
        """The state to Specify the monitoring pipeline."""
        pass

    MONITORING_SCHEDULE_STATE_UNSPECIFIED: ModelDeploymentMonitoringJob.MonitoringScheduleState.ValueType = ...  # 0
    """Unspecified state."""

    PENDING: ModelDeploymentMonitoringJob.MonitoringScheduleState.ValueType = ...  # 1
    """The pipeline is picked up and wait to run."""

    OFFLINE: ModelDeploymentMonitoringJob.MonitoringScheduleState.ValueType = ...  # 2
    """The pipeline is offline and will be scheduled for next run."""

    RUNNING: ModelDeploymentMonitoringJob.MonitoringScheduleState.ValueType = ...  # 3
    """The pipeline is running."""


    class LabelsEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: typing.Text = ...
        value: typing.Text = ...
        def __init__(self,
            *,
            key : typing.Text = ...,
            value : typing.Text = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

    NAME_FIELD_NUMBER: builtins.int
    DISPLAY_NAME_FIELD_NUMBER: builtins.int
    ENDPOINT_FIELD_NUMBER: builtins.int
    STATE_FIELD_NUMBER: builtins.int
    SCHEDULE_STATE_FIELD_NUMBER: builtins.int
    MODEL_DEPLOYMENT_MONITORING_OBJECTIVE_CONFIGS_FIELD_NUMBER: builtins.int
    MODEL_DEPLOYMENT_MONITORING_SCHEDULE_CONFIG_FIELD_NUMBER: builtins.int
    LOGGING_SAMPLING_STRATEGY_FIELD_NUMBER: builtins.int
    MODEL_MONITORING_ALERT_CONFIG_FIELD_NUMBER: builtins.int
    PREDICT_INSTANCE_SCHEMA_URI_FIELD_NUMBER: builtins.int
    SAMPLE_PREDICT_INSTANCE_FIELD_NUMBER: builtins.int
    ANALYSIS_INSTANCE_SCHEMA_URI_FIELD_NUMBER: builtins.int
    BIGQUERY_TABLES_FIELD_NUMBER: builtins.int
    LOG_TTL_FIELD_NUMBER: builtins.int
    LABELS_FIELD_NUMBER: builtins.int
    CREATE_TIME_FIELD_NUMBER: builtins.int
    UPDATE_TIME_FIELD_NUMBER: builtins.int
    NEXT_SCHEDULE_TIME_FIELD_NUMBER: builtins.int
    STATS_ANOMALIES_BASE_DIRECTORY_FIELD_NUMBER: builtins.int
    ENCRYPTION_SPEC_FIELD_NUMBER: builtins.int
    ENABLE_MONITORING_PIPELINE_LOGS_FIELD_NUMBER: builtins.int
    ERROR_FIELD_NUMBER: builtins.int
    name: typing.Text = ...
    """Output only. Resource name of a ModelDeploymentMonitoringJob."""

    display_name: typing.Text = ...
    """Required. The user-defined name of the ModelDeploymentMonitoringJob.
    The name can be up to 128 characters long and can be consist of any UTF-8
    characters.
    Display name of a ModelDeploymentMonitoringJob.
    """

    endpoint: typing.Text = ...
    """Required. Endpoint resource name.
    Format: `projects/{project}/locations/{location}/endpoints/{endpoint}`
    """

    state: google.cloud.aiplatform.v1beta1.job_state_pb2.JobState.ValueType = ...
    """Output only. The detailed state of the monitoring job.
    When the job is still creating, the state will be 'PENDING'.
    Once the job is successfully created, the state will be 'RUNNING'.
    Pause the job, the state will be 'PAUSED'.
    Resume the job, the state will return to 'RUNNING'.
    """

    schedule_state: global___ModelDeploymentMonitoringJob.MonitoringScheduleState.ValueType = ...
    """Output only. Schedule state when the monitoring job is in Running state."""

    @property
    def model_deployment_monitoring_objective_configs(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ModelDeploymentMonitoringObjectiveConfig]:
        """Required. The config for monitoring objectives. This is a per DeployedModel config.
        Each DeployedModel needs to be configured separately.
        """
        pass
    @property
    def model_deployment_monitoring_schedule_config(self) -> global___ModelDeploymentMonitoringScheduleConfig:
        """Required. Schedule config for running the monitoring job."""
        pass
    @property
    def logging_sampling_strategy(self) -> google.cloud.aiplatform.v1beta1.model_monitoring_pb2.SamplingStrategy:
        """Required. Sample Strategy for logging."""
        pass
    @property
    def model_monitoring_alert_config(self) -> google.cloud.aiplatform.v1beta1.model_monitoring_pb2.ModelMonitoringAlertConfig:
        """Alert config for model monitoring."""
        pass
    predict_instance_schema_uri: typing.Text = ...
    """YAML schema file uri describing the format of a single instance,
    which are given to format this Endpoint's prediction (and explanation).
    If not set, we will generate predict schema from collected predict
    requests.
    """

    @property
    def sample_predict_instance(self) -> google.protobuf.struct_pb2.Value:
        """Sample Predict instance, same format as [PredictRequest.instances][google.cloud.aiplatform.v1beta1.PredictRequest.instances],
        this can be set as a replacement of
        [ModelDeploymentMonitoringJob.predict_instance_schema_uri][google.cloud.aiplatform.v1beta1.ModelDeploymentMonitoringJob.predict_instance_schema_uri]. If not set,
        we will generate predict schema from collected predict requests.
        """
        pass
    analysis_instance_schema_uri: typing.Text = ...
    """YAML schema file uri describing the format of a single instance that you
    want Tensorflow Data Validation (TFDV) to analyze.

    If this field is empty, all the feature data types are inferred from
    [predict_instance_schema_uri][google.cloud.aiplatform.v1beta1.ModelDeploymentMonitoringJob.predict_instance_schema_uri],
    meaning that TFDV will use the data in the exact format(data type) as
    prediction request/response.
    If there are any data type differences between predict instance and TFDV
    instance, this field can be used to override the schema.
    For models trained with Vertex AI, this field must be set as all the
    fields in predict instance formatted as string.
    """

    @property
    def bigquery_tables(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ModelDeploymentMonitoringBigQueryTable]:
        """Output only. The created bigquery tables for the job under customer project. Customer
        could do their own query & analysis. There could be 4 log tables in
        maximum:
        1. Training data logging predict request/response
        2. Serving data logging predict request/response
        """
        pass
    @property
    def log_ttl(self) -> google.protobuf.duration_pb2.Duration:
        """The TTL of BigQuery tables in user projects which stores logs.
        A day is the basic unit of the TTL and we take the ceil of TTL/86400(a
        day). e.g. { second: 3600} indicates ttl = 1 day.
        """
        pass
    @property
    def labels(self) -> google.protobuf.internal.containers.ScalarMap[typing.Text, typing.Text]:
        """The labels with user-defined metadata to organize your
        ModelDeploymentMonitoringJob.

        Label keys and values can be no longer than 64 characters
        (Unicode codepoints), can only contain lowercase letters, numeric
        characters, underscores and dashes. International characters are allowed.

        See https://goo.gl/xmQnxf for more information and examples of labels.
        """
        pass
    @property
    def create_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Output only. Timestamp when this ModelDeploymentMonitoringJob was created."""
        pass
    @property
    def update_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Output only. Timestamp when this ModelDeploymentMonitoringJob was updated most recently."""
        pass
    @property
    def next_schedule_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Output only. Timestamp when this monitoring pipeline will be scheduled to run for the
        next round.
        """
        pass
    @property
    def stats_anomalies_base_directory(self) -> google.cloud.aiplatform.v1beta1.io_pb2.GcsDestination:
        """Stats anomalies base folder path."""
        pass
    @property
    def encryption_spec(self) -> google.cloud.aiplatform.v1beta1.encryption_spec_pb2.EncryptionSpec:
        """Customer-managed encryption key spec for a ModelDeploymentMonitoringJob. If
        set, this ModelDeploymentMonitoringJob and all sub-resources of this
        ModelDeploymentMonitoringJob will be secured by this key.
        """
        pass
    enable_monitoring_pipeline_logs: builtins.bool = ...
    """If true, the scheduled monitoring pipeline logs are sent to
    Google Cloud Logging, including pipeline status and anomalies detected.
    Please note the logs incur cost, which are subject to [Cloud Logging
    pricing](https://cloud.google.com/logging#pricing).
    """

    @property
    def error(self) -> google.rpc.status_pb2.Status:
        """Output only. Only populated when the job's state is `JOB_STATE_FAILED` or
        `JOB_STATE_CANCELLED`.
        """
        pass
    def __init__(self,
        *,
        name : typing.Text = ...,
        display_name : typing.Text = ...,
        endpoint : typing.Text = ...,
        state : google.cloud.aiplatform.v1beta1.job_state_pb2.JobState.ValueType = ...,
        schedule_state : global___ModelDeploymentMonitoringJob.MonitoringScheduleState.ValueType = ...,
        model_deployment_monitoring_objective_configs : typing.Optional[typing.Iterable[global___ModelDeploymentMonitoringObjectiveConfig]] = ...,
        model_deployment_monitoring_schedule_config : typing.Optional[global___ModelDeploymentMonitoringScheduleConfig] = ...,
        logging_sampling_strategy : typing.Optional[google.cloud.aiplatform.v1beta1.model_monitoring_pb2.SamplingStrategy] = ...,
        model_monitoring_alert_config : typing.Optional[google.cloud.aiplatform.v1beta1.model_monitoring_pb2.ModelMonitoringAlertConfig] = ...,
        predict_instance_schema_uri : typing.Text = ...,
        sample_predict_instance : typing.Optional[google.protobuf.struct_pb2.Value] = ...,
        analysis_instance_schema_uri : typing.Text = ...,
        bigquery_tables : typing.Optional[typing.Iterable[global___ModelDeploymentMonitoringBigQueryTable]] = ...,
        log_ttl : typing.Optional[google.protobuf.duration_pb2.Duration] = ...,
        labels : typing.Optional[typing.Mapping[typing.Text, typing.Text]] = ...,
        create_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        update_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        next_schedule_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        stats_anomalies_base_directory : typing.Optional[google.cloud.aiplatform.v1beta1.io_pb2.GcsDestination] = ...,
        encryption_spec : typing.Optional[google.cloud.aiplatform.v1beta1.encryption_spec_pb2.EncryptionSpec] = ...,
        enable_monitoring_pipeline_logs : builtins.bool = ...,
        error : typing.Optional[google.rpc.status_pb2.Status] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["create_time",b"create_time","encryption_spec",b"encryption_spec","error",b"error","log_ttl",b"log_ttl","logging_sampling_strategy",b"logging_sampling_strategy","model_deployment_monitoring_schedule_config",b"model_deployment_monitoring_schedule_config","model_monitoring_alert_config",b"model_monitoring_alert_config","next_schedule_time",b"next_schedule_time","sample_predict_instance",b"sample_predict_instance","stats_anomalies_base_directory",b"stats_anomalies_base_directory","update_time",b"update_time"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["analysis_instance_schema_uri",b"analysis_instance_schema_uri","bigquery_tables",b"bigquery_tables","create_time",b"create_time","display_name",b"display_name","enable_monitoring_pipeline_logs",b"enable_monitoring_pipeline_logs","encryption_spec",b"encryption_spec","endpoint",b"endpoint","error",b"error","labels",b"labels","log_ttl",b"log_ttl","logging_sampling_strategy",b"logging_sampling_strategy","model_deployment_monitoring_objective_configs",b"model_deployment_monitoring_objective_configs","model_deployment_monitoring_schedule_config",b"model_deployment_monitoring_schedule_config","model_monitoring_alert_config",b"model_monitoring_alert_config","name",b"name","next_schedule_time",b"next_schedule_time","predict_instance_schema_uri",b"predict_instance_schema_uri","sample_predict_instance",b"sample_predict_instance","schedule_state",b"schedule_state","state",b"state","stats_anomalies_base_directory",b"stats_anomalies_base_directory","update_time",b"update_time"]) -> None: ...
global___ModelDeploymentMonitoringJob = ModelDeploymentMonitoringJob

class ModelDeploymentMonitoringBigQueryTable(google.protobuf.message.Message):
    """ModelDeploymentMonitoringBigQueryTable specifies the BigQuery table name
    as well as some information of the logs stored in this table.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class _LogSource:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _LogSourceEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_LogSource.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        LOG_SOURCE_UNSPECIFIED: ModelDeploymentMonitoringBigQueryTable.LogSource.ValueType = ...  # 0
        """Unspecified source."""

        TRAINING: ModelDeploymentMonitoringBigQueryTable.LogSource.ValueType = ...  # 1
        """Logs coming from Training dataset."""

        SERVING: ModelDeploymentMonitoringBigQueryTable.LogSource.ValueType = ...  # 2
        """Logs coming from Serving traffic."""

    class LogSource(_LogSource, metaclass=_LogSourceEnumTypeWrapper):
        """Indicates where does the log come from."""
        pass

    LOG_SOURCE_UNSPECIFIED: ModelDeploymentMonitoringBigQueryTable.LogSource.ValueType = ...  # 0
    """Unspecified source."""

    TRAINING: ModelDeploymentMonitoringBigQueryTable.LogSource.ValueType = ...  # 1
    """Logs coming from Training dataset."""

    SERVING: ModelDeploymentMonitoringBigQueryTable.LogSource.ValueType = ...  # 2
    """Logs coming from Serving traffic."""


    class _LogType:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _LogTypeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_LogType.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        LOG_TYPE_UNSPECIFIED: ModelDeploymentMonitoringBigQueryTable.LogType.ValueType = ...  # 0
        """Unspecified type."""

        PREDICT: ModelDeploymentMonitoringBigQueryTable.LogType.ValueType = ...  # 1
        """Predict logs."""

        EXPLAIN: ModelDeploymentMonitoringBigQueryTable.LogType.ValueType = ...  # 2
        """Explain logs."""

    class LogType(_LogType, metaclass=_LogTypeEnumTypeWrapper):
        """Indicates what type of traffic does the log belong to."""
        pass

    LOG_TYPE_UNSPECIFIED: ModelDeploymentMonitoringBigQueryTable.LogType.ValueType = ...  # 0
    """Unspecified type."""

    PREDICT: ModelDeploymentMonitoringBigQueryTable.LogType.ValueType = ...  # 1
    """Predict logs."""

    EXPLAIN: ModelDeploymentMonitoringBigQueryTable.LogType.ValueType = ...  # 2
    """Explain logs."""


    LOG_SOURCE_FIELD_NUMBER: builtins.int
    LOG_TYPE_FIELD_NUMBER: builtins.int
    BIGQUERY_TABLE_PATH_FIELD_NUMBER: builtins.int
    log_source: global___ModelDeploymentMonitoringBigQueryTable.LogSource.ValueType = ...
    """The source of log."""

    log_type: global___ModelDeploymentMonitoringBigQueryTable.LogType.ValueType = ...
    """The type of log."""

    bigquery_table_path: typing.Text = ...
    """The created BigQuery table to store logs. Customer could do their own query
    & analysis. Format:
    `bq://<project_id>.model_deployment_monitoring_<endpoint_id>.<tolower(log_source)>_<tolower(log_type)>`
    """

    def __init__(self,
        *,
        log_source : global___ModelDeploymentMonitoringBigQueryTable.LogSource.ValueType = ...,
        log_type : global___ModelDeploymentMonitoringBigQueryTable.LogType.ValueType = ...,
        bigquery_table_path : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["bigquery_table_path",b"bigquery_table_path","log_source",b"log_source","log_type",b"log_type"]) -> None: ...
global___ModelDeploymentMonitoringBigQueryTable = ModelDeploymentMonitoringBigQueryTable

class ModelDeploymentMonitoringObjectiveConfig(google.protobuf.message.Message):
    """ModelDeploymentMonitoringObjectiveConfig contains the pair of
    deployed_model_id to ModelMonitoringObjectiveConfig.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    DEPLOYED_MODEL_ID_FIELD_NUMBER: builtins.int
    OBJECTIVE_CONFIG_FIELD_NUMBER: builtins.int
    deployed_model_id: typing.Text = ...
    """The DeployedModel ID of the objective config."""

    @property
    def objective_config(self) -> google.cloud.aiplatform.v1beta1.model_monitoring_pb2.ModelMonitoringObjectiveConfig:
        """The objective config of for the modelmonitoring job of this deployed model."""
        pass
    def __init__(self,
        *,
        deployed_model_id : typing.Text = ...,
        objective_config : typing.Optional[google.cloud.aiplatform.v1beta1.model_monitoring_pb2.ModelMonitoringObjectiveConfig] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["objective_config",b"objective_config"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["deployed_model_id",b"deployed_model_id","objective_config",b"objective_config"]) -> None: ...
global___ModelDeploymentMonitoringObjectiveConfig = ModelDeploymentMonitoringObjectiveConfig

class ModelDeploymentMonitoringScheduleConfig(google.protobuf.message.Message):
    """The config for scheduling monitoring job."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    MONITOR_INTERVAL_FIELD_NUMBER: builtins.int
    @property
    def monitor_interval(self) -> google.protobuf.duration_pb2.Duration:
        """Required. The model monitoring job running interval. It will be rounded up to next
        full hour.
        """
        pass
    def __init__(self,
        *,
        monitor_interval : typing.Optional[google.protobuf.duration_pb2.Duration] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["monitor_interval",b"monitor_interval"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["monitor_interval",b"monitor_interval"]) -> None: ...
global___ModelDeploymentMonitoringScheduleConfig = ModelDeploymentMonitoringScheduleConfig

class ModelMonitoringStatsAnomalies(google.protobuf.message.Message):
    """Statistics and anomalies generated by Model Monitoring."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class FeatureHistoricStatsAnomalies(google.protobuf.message.Message):
        """Historical Stats (and Anomalies) for a specific Feature."""
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        FEATURE_DISPLAY_NAME_FIELD_NUMBER: builtins.int
        THRESHOLD_FIELD_NUMBER: builtins.int
        TRAINING_STATS_FIELD_NUMBER: builtins.int
        PREDICTION_STATS_FIELD_NUMBER: builtins.int
        feature_display_name: typing.Text = ...
        """Display Name of the Feature."""

        @property
        def threshold(self) -> google.cloud.aiplatform.v1beta1.model_monitoring_pb2.ThresholdConfig:
            """Threshold for anomaly detection."""
            pass
        @property
        def training_stats(self) -> google.cloud.aiplatform.v1beta1.feature_monitoring_stats_pb2.FeatureStatsAnomaly:
            """Stats calculated for the Training Dataset."""
            pass
        @property
        def prediction_stats(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[google.cloud.aiplatform.v1beta1.feature_monitoring_stats_pb2.FeatureStatsAnomaly]:
            """A list of historical stats generated by different time window's
            Prediction Dataset.
            """
            pass
        def __init__(self,
            *,
            feature_display_name : typing.Text = ...,
            threshold : typing.Optional[google.cloud.aiplatform.v1beta1.model_monitoring_pb2.ThresholdConfig] = ...,
            training_stats : typing.Optional[google.cloud.aiplatform.v1beta1.feature_monitoring_stats_pb2.FeatureStatsAnomaly] = ...,
            prediction_stats : typing.Optional[typing.Iterable[google.cloud.aiplatform.v1beta1.feature_monitoring_stats_pb2.FeatureStatsAnomaly]] = ...,
            ) -> None: ...
        def HasField(self, field_name: typing_extensions.Literal["threshold",b"threshold","training_stats",b"training_stats"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing_extensions.Literal["feature_display_name",b"feature_display_name","prediction_stats",b"prediction_stats","threshold",b"threshold","training_stats",b"training_stats"]) -> None: ...

    OBJECTIVE_FIELD_NUMBER: builtins.int
    DEPLOYED_MODEL_ID_FIELD_NUMBER: builtins.int
    ANOMALY_COUNT_FIELD_NUMBER: builtins.int
    FEATURE_STATS_FIELD_NUMBER: builtins.int
    objective: global___ModelDeploymentMonitoringObjectiveType.ValueType = ...
    """Model Monitoring Objective those stats and anomalies belonging to."""

    deployed_model_id: typing.Text = ...
    """Deployed Model ID."""

    anomaly_count: builtins.int = ...
    """Number of anomalies within all stats."""

    @property
    def feature_stats(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ModelMonitoringStatsAnomalies.FeatureHistoricStatsAnomalies]:
        """A list of historical Stats and Anomalies generated for all Features."""
        pass
    def __init__(self,
        *,
        objective : global___ModelDeploymentMonitoringObjectiveType.ValueType = ...,
        deployed_model_id : typing.Text = ...,
        anomaly_count : builtins.int = ...,
        feature_stats : typing.Optional[typing.Iterable[global___ModelMonitoringStatsAnomalies.FeatureHistoricStatsAnomalies]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["anomaly_count",b"anomaly_count","deployed_model_id",b"deployed_model_id","feature_stats",b"feature_stats","objective",b"objective"]) -> None: ...
global___ModelMonitoringStatsAnomalies = ModelMonitoringStatsAnomalies
