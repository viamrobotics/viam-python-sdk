"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import google.cloud.aiplatform.v1.artifact_pb2
import google.cloud.aiplatform.v1.context_pb2
import google.cloud.aiplatform.v1.encryption_spec_pb2
import google.cloud.aiplatform.v1.execution_pb2
import google.cloud.aiplatform.v1.pipeline_state_pb2
import google.cloud.aiplatform.v1.value_pb2
import google.protobuf.descriptor
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import google.protobuf.struct_pb2
import google.protobuf.timestamp_pb2
import google.rpc.status_pb2
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor = ...

class PipelineJob(google.protobuf.message.Message):
    """An instance of a machine learning PipelineJob."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class RuntimeConfig(google.protobuf.message.Message):
        """The runtime config of a PipelineJob."""
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        class ParametersEntry(google.protobuf.message.Message):
            DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
            KEY_FIELD_NUMBER: builtins.int
            VALUE_FIELD_NUMBER: builtins.int
            key: typing.Text = ...
            @property
            def value(self) -> google.cloud.aiplatform.v1.value_pb2.Value: ...
            def __init__(self,
                *,
                key : typing.Text = ...,
                value : typing.Optional[google.cloud.aiplatform.v1.value_pb2.Value] = ...,
                ) -> None: ...
            def HasField(self, field_name: typing_extensions.Literal["value",b"value"]) -> builtins.bool: ...
            def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

        class ParameterValuesEntry(google.protobuf.message.Message):
            DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
            KEY_FIELD_NUMBER: builtins.int
            VALUE_FIELD_NUMBER: builtins.int
            key: typing.Text = ...
            @property
            def value(self) -> google.protobuf.struct_pb2.Value: ...
            def __init__(self,
                *,
                key : typing.Text = ...,
                value : typing.Optional[google.protobuf.struct_pb2.Value] = ...,
                ) -> None: ...
            def HasField(self, field_name: typing_extensions.Literal["value",b"value"]) -> builtins.bool: ...
            def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

        PARAMETERS_FIELD_NUMBER: builtins.int
        GCS_OUTPUT_DIRECTORY_FIELD_NUMBER: builtins.int
        PARAMETER_VALUES_FIELD_NUMBER: builtins.int
        @property
        def parameters(self) -> google.protobuf.internal.containers.MessageMap[typing.Text, google.cloud.aiplatform.v1.value_pb2.Value]:
            """Deprecated. Use [RuntimeConfig.parameter_values][google.cloud.aiplatform.v1.PipelineJob.RuntimeConfig.parameter_values] instead. The runtime
            parameters of the PipelineJob. The parameters will be passed into
            [PipelineJob.pipeline_spec][google.cloud.aiplatform.v1.PipelineJob.pipeline_spec] to replace the placeholders at runtime.
            This field is used by pipelines built using
            `PipelineJob.pipeline_spec.schema_version` 2.0.0 or lower, such as
            pipelines built using Kubeflow Pipelines SDK 1.8 or lower.
            """
            pass
        gcs_output_directory: typing.Text = ...
        """Required. A path in a Cloud Storage bucket, which will be treated as the root
        output directory of the pipeline. It is used by the system to
        generate the paths of output artifacts. The artifact paths are generated
        with a sub-path pattern `{job_id}/{task_id}/{output_key}` under the
        specified output directory. The service account specified in this
        pipeline must have the `storage.objects.get` and `storage.objects.create`
        permissions for this bucket.
        """

        @property
        def parameter_values(self) -> google.protobuf.internal.containers.MessageMap[typing.Text, google.protobuf.struct_pb2.Value]:
            """The runtime parameters of the PipelineJob. The parameters will be
            passed into [PipelineJob.pipeline_spec][google.cloud.aiplatform.v1.PipelineJob.pipeline_spec] to replace the placeholders
            at runtime. This field is used by pipelines built using
            `PipelineJob.pipeline_spec.schema_version` 2.1.0, such as pipelines built
            using Kubeflow Pipelines SDK 1.9 or higher and the v2 DSL.
            """
            pass
        def __init__(self,
            *,
            parameters : typing.Optional[typing.Mapping[typing.Text, google.cloud.aiplatform.v1.value_pb2.Value]] = ...,
            gcs_output_directory : typing.Text = ...,
            parameter_values : typing.Optional[typing.Mapping[typing.Text, google.protobuf.struct_pb2.Value]] = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["gcs_output_directory",b"gcs_output_directory","parameter_values",b"parameter_values","parameters",b"parameters"]) -> None: ...

    class LabelsEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: typing.Text = ...
        value: typing.Text = ...
        def __init__(self,
            *,
            key : typing.Text = ...,
            value : typing.Text = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

    NAME_FIELD_NUMBER: builtins.int
    DISPLAY_NAME_FIELD_NUMBER: builtins.int
    CREATE_TIME_FIELD_NUMBER: builtins.int
    START_TIME_FIELD_NUMBER: builtins.int
    END_TIME_FIELD_NUMBER: builtins.int
    UPDATE_TIME_FIELD_NUMBER: builtins.int
    PIPELINE_SPEC_FIELD_NUMBER: builtins.int
    STATE_FIELD_NUMBER: builtins.int
    JOB_DETAIL_FIELD_NUMBER: builtins.int
    ERROR_FIELD_NUMBER: builtins.int
    LABELS_FIELD_NUMBER: builtins.int
    RUNTIME_CONFIG_FIELD_NUMBER: builtins.int
    ENCRYPTION_SPEC_FIELD_NUMBER: builtins.int
    SERVICE_ACCOUNT_FIELD_NUMBER: builtins.int
    NETWORK_FIELD_NUMBER: builtins.int
    name: typing.Text = ...
    """Output only. The resource name of the PipelineJob."""

    display_name: typing.Text = ...
    """The display name of the Pipeline.
    The name can be up to 128 characters long and can be consist of any UTF-8
    characters.
    """

    @property
    def create_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Output only. Pipeline creation time."""
        pass
    @property
    def start_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Output only. Pipeline start time."""
        pass
    @property
    def end_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Output only. Pipeline end time."""
        pass
    @property
    def update_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Output only. Timestamp when this PipelineJob was most recently updated."""
        pass
    @property
    def pipeline_spec(self) -> google.protobuf.struct_pb2.Struct:
        """Required. The spec of the pipeline."""
        pass
    state: google.cloud.aiplatform.v1.pipeline_state_pb2.PipelineState.ValueType = ...
    """Output only. The detailed state of the job."""

    @property
    def job_detail(self) -> global___PipelineJobDetail:
        """Output only. The details of pipeline run. Not available in the list view."""
        pass
    @property
    def error(self) -> google.rpc.status_pb2.Status:
        """Output only. The error that occurred during pipeline execution.
        Only populated when the pipeline's state is FAILED or CANCELLED.
        """
        pass
    @property
    def labels(self) -> google.protobuf.internal.containers.ScalarMap[typing.Text, typing.Text]:
        """The labels with user-defined metadata to organize PipelineJob.

        Label keys and values can be no longer than 64 characters
        (Unicode codepoints), can only contain lowercase letters, numeric
        characters, underscores and dashes. International characters are allowed.

        See https://goo.gl/xmQnxf for more information and examples of labels.
        """
        pass
    @property
    def runtime_config(self) -> global___PipelineJob.RuntimeConfig:
        """Runtime config of the pipeline."""
        pass
    @property
    def encryption_spec(self) -> google.cloud.aiplatform.v1.encryption_spec_pb2.EncryptionSpec:
        """Customer-managed encryption key spec for a pipelineJob. If set, this
        PipelineJob and all of its sub-resources will be secured by this key.
        """
        pass
    service_account: typing.Text = ...
    """The service account that the pipeline workload runs as.
    If not specified, the Compute Engine default service account in the project
    will be used.
    See
    https://cloud.google.com/compute/docs/access/service-accounts#default_service_account

    Users starting the pipeline must have the `iam.serviceAccounts.actAs`
    permission on this service account.
    """

    network: typing.Text = ...
    """The full name of the Compute Engine
    [network](/compute/docs/networks-and-firewalls#networks) to which the
    Pipeline Job's workload should be peered. For example,
    `projects/12345/global/networks/myVPC`.
    [Format](/compute/docs/reference/rest/v1/networks/insert)
    is of the form `projects/{project}/global/networks/{network}`.
    Where {project} is a project number, as in `12345`, and {network} is a
    network name.

    Private services access must already be configured for the network.
    Pipeline job will apply the network configuration to the GCP resources
    being launched, if applied, such as Vertex AI
    Training or Dataflow job. If left unspecified, the workload is not peered
    with any network.
    """

    def __init__(self,
        *,
        name : typing.Text = ...,
        display_name : typing.Text = ...,
        create_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        start_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        end_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        update_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        pipeline_spec : typing.Optional[google.protobuf.struct_pb2.Struct] = ...,
        state : google.cloud.aiplatform.v1.pipeline_state_pb2.PipelineState.ValueType = ...,
        job_detail : typing.Optional[global___PipelineJobDetail] = ...,
        error : typing.Optional[google.rpc.status_pb2.Status] = ...,
        labels : typing.Optional[typing.Mapping[typing.Text, typing.Text]] = ...,
        runtime_config : typing.Optional[global___PipelineJob.RuntimeConfig] = ...,
        encryption_spec : typing.Optional[google.cloud.aiplatform.v1.encryption_spec_pb2.EncryptionSpec] = ...,
        service_account : typing.Text = ...,
        network : typing.Text = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["create_time",b"create_time","encryption_spec",b"encryption_spec","end_time",b"end_time","error",b"error","job_detail",b"job_detail","pipeline_spec",b"pipeline_spec","runtime_config",b"runtime_config","start_time",b"start_time","update_time",b"update_time"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["create_time",b"create_time","display_name",b"display_name","encryption_spec",b"encryption_spec","end_time",b"end_time","error",b"error","job_detail",b"job_detail","labels",b"labels","name",b"name","network",b"network","pipeline_spec",b"pipeline_spec","runtime_config",b"runtime_config","service_account",b"service_account","start_time",b"start_time","state",b"state","update_time",b"update_time"]) -> None: ...
global___PipelineJob = PipelineJob

class PipelineJobDetail(google.protobuf.message.Message):
    """The runtime detail of PipelineJob."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    PIPELINE_CONTEXT_FIELD_NUMBER: builtins.int
    PIPELINE_RUN_CONTEXT_FIELD_NUMBER: builtins.int
    TASK_DETAILS_FIELD_NUMBER: builtins.int
    @property
    def pipeline_context(self) -> google.cloud.aiplatform.v1.context_pb2.Context:
        """Output only. The context of the pipeline."""
        pass
    @property
    def pipeline_run_context(self) -> google.cloud.aiplatform.v1.context_pb2.Context:
        """Output only. The context of the current pipeline run."""
        pass
    @property
    def task_details(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___PipelineTaskDetail]:
        """Output only. The runtime details of the tasks under the pipeline."""
        pass
    def __init__(self,
        *,
        pipeline_context : typing.Optional[google.cloud.aiplatform.v1.context_pb2.Context] = ...,
        pipeline_run_context : typing.Optional[google.cloud.aiplatform.v1.context_pb2.Context] = ...,
        task_details : typing.Optional[typing.Iterable[global___PipelineTaskDetail]] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["pipeline_context",b"pipeline_context","pipeline_run_context",b"pipeline_run_context"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["pipeline_context",b"pipeline_context","pipeline_run_context",b"pipeline_run_context","task_details",b"task_details"]) -> None: ...
global___PipelineJobDetail = PipelineJobDetail

class PipelineTaskDetail(google.protobuf.message.Message):
    """The runtime detail of a task execution."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class _State:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _StateEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_State.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        STATE_UNSPECIFIED: PipelineTaskDetail.State.ValueType = ...  # 0
        """Unspecified."""

        PENDING: PipelineTaskDetail.State.ValueType = ...  # 1
        """Specifies pending state for the task."""

        RUNNING: PipelineTaskDetail.State.ValueType = ...  # 2
        """Specifies task is being executed."""

        SUCCEEDED: PipelineTaskDetail.State.ValueType = ...  # 3
        """Specifies task completed successfully."""

        CANCEL_PENDING: PipelineTaskDetail.State.ValueType = ...  # 4
        """Specifies Task cancel is in pending state."""

        CANCELLING: PipelineTaskDetail.State.ValueType = ...  # 5
        """Specifies task is being cancelled."""

        CANCELLED: PipelineTaskDetail.State.ValueType = ...  # 6
        """Specifies task was cancelled."""

        FAILED: PipelineTaskDetail.State.ValueType = ...  # 7
        """Specifies task failed."""

        SKIPPED: PipelineTaskDetail.State.ValueType = ...  # 8
        """Specifies task was skipped due to cache hit."""

        NOT_TRIGGERED: PipelineTaskDetail.State.ValueType = ...  # 9
        """Specifies that the task was not triggered because the task's trigger
        policy is not satisfied. The trigger policy is specified in the
        `condition` field of [PipelineJob.pipeline_spec][google.cloud.aiplatform.v1.PipelineJob.pipeline_spec].
        """

    class State(_State, metaclass=_StateEnumTypeWrapper):
        """Specifies state of TaskExecution"""
        pass

    STATE_UNSPECIFIED: PipelineTaskDetail.State.ValueType = ...  # 0
    """Unspecified."""

    PENDING: PipelineTaskDetail.State.ValueType = ...  # 1
    """Specifies pending state for the task."""

    RUNNING: PipelineTaskDetail.State.ValueType = ...  # 2
    """Specifies task is being executed."""

    SUCCEEDED: PipelineTaskDetail.State.ValueType = ...  # 3
    """Specifies task completed successfully."""

    CANCEL_PENDING: PipelineTaskDetail.State.ValueType = ...  # 4
    """Specifies Task cancel is in pending state."""

    CANCELLING: PipelineTaskDetail.State.ValueType = ...  # 5
    """Specifies task is being cancelled."""

    CANCELLED: PipelineTaskDetail.State.ValueType = ...  # 6
    """Specifies task was cancelled."""

    FAILED: PipelineTaskDetail.State.ValueType = ...  # 7
    """Specifies task failed."""

    SKIPPED: PipelineTaskDetail.State.ValueType = ...  # 8
    """Specifies task was skipped due to cache hit."""

    NOT_TRIGGERED: PipelineTaskDetail.State.ValueType = ...  # 9
    """Specifies that the task was not triggered because the task's trigger
    policy is not satisfied. The trigger policy is specified in the
    `condition` field of [PipelineJob.pipeline_spec][google.cloud.aiplatform.v1.PipelineJob.pipeline_spec].
    """


    class PipelineTaskStatus(google.protobuf.message.Message):
        """A single record of the task status."""
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        UPDATE_TIME_FIELD_NUMBER: builtins.int
        STATE_FIELD_NUMBER: builtins.int
        ERROR_FIELD_NUMBER: builtins.int
        @property
        def update_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
            """Output only. Update time of this status."""
            pass
        state: global___PipelineTaskDetail.State.ValueType = ...
        """Output only. The state of the task."""

        @property
        def error(self) -> google.rpc.status_pb2.Status:
            """Output only. The error that occurred during the state. May be set when the state is
            any of the non-final state (PENDING/RUNNING/CANCELLING) or FAILED state.
            If the state is FAILED, the error here is final and not going to be
            retried.
            If the state is a non-final state, the error indicates a system-error
            being retried.
            """
            pass
        def __init__(self,
            *,
            update_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
            state : global___PipelineTaskDetail.State.ValueType = ...,
            error : typing.Optional[google.rpc.status_pb2.Status] = ...,
            ) -> None: ...
        def HasField(self, field_name: typing_extensions.Literal["error",b"error","update_time",b"update_time"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing_extensions.Literal["error",b"error","state",b"state","update_time",b"update_time"]) -> None: ...

    class ArtifactList(google.protobuf.message.Message):
        """A list of artifact metadata."""
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        ARTIFACTS_FIELD_NUMBER: builtins.int
        @property
        def artifacts(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[google.cloud.aiplatform.v1.artifact_pb2.Artifact]:
            """Output only. A list of artifact metadata."""
            pass
        def __init__(self,
            *,
            artifacts : typing.Optional[typing.Iterable[google.cloud.aiplatform.v1.artifact_pb2.Artifact]] = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["artifacts",b"artifacts"]) -> None: ...

    class InputsEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: typing.Text = ...
        @property
        def value(self) -> global___PipelineTaskDetail.ArtifactList: ...
        def __init__(self,
            *,
            key : typing.Text = ...,
            value : typing.Optional[global___PipelineTaskDetail.ArtifactList] = ...,
            ) -> None: ...
        def HasField(self, field_name: typing_extensions.Literal["value",b"value"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

    class OutputsEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: typing.Text = ...
        @property
        def value(self) -> global___PipelineTaskDetail.ArtifactList: ...
        def __init__(self,
            *,
            key : typing.Text = ...,
            value : typing.Optional[global___PipelineTaskDetail.ArtifactList] = ...,
            ) -> None: ...
        def HasField(self, field_name: typing_extensions.Literal["value",b"value"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

    TASK_ID_FIELD_NUMBER: builtins.int
    PARENT_TASK_ID_FIELD_NUMBER: builtins.int
    TASK_NAME_FIELD_NUMBER: builtins.int
    CREATE_TIME_FIELD_NUMBER: builtins.int
    START_TIME_FIELD_NUMBER: builtins.int
    END_TIME_FIELD_NUMBER: builtins.int
    EXECUTOR_DETAIL_FIELD_NUMBER: builtins.int
    STATE_FIELD_NUMBER: builtins.int
    EXECUTION_FIELD_NUMBER: builtins.int
    ERROR_FIELD_NUMBER: builtins.int
    PIPELINE_TASK_STATUS_FIELD_NUMBER: builtins.int
    INPUTS_FIELD_NUMBER: builtins.int
    OUTPUTS_FIELD_NUMBER: builtins.int
    task_id: builtins.int = ...
    """Output only. The system generated ID of the task."""

    parent_task_id: builtins.int = ...
    """Output only. The id of the parent task if the task is within a component scope.
    Empty if the task is at the root level.
    """

    task_name: typing.Text = ...
    """Output only. The user specified name of the task that is defined in
    [PipelineJob.spec][].
    """

    @property
    def create_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Output only. Task create time."""
        pass
    @property
    def start_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Output only. Task start time."""
        pass
    @property
    def end_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Output only. Task end time."""
        pass
    @property
    def executor_detail(self) -> global___PipelineTaskExecutorDetail:
        """Output only. The detailed execution info."""
        pass
    state: global___PipelineTaskDetail.State.ValueType = ...
    """Output only. State of the task."""

    @property
    def execution(self) -> google.cloud.aiplatform.v1.execution_pb2.Execution:
        """Output only. The execution metadata of the task."""
        pass
    @property
    def error(self) -> google.rpc.status_pb2.Status:
        """Output only. The error that occurred during task execution.
        Only populated when the task's state is FAILED or CANCELLED.
        """
        pass
    @property
    def pipeline_task_status(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___PipelineTaskDetail.PipelineTaskStatus]:
        """Output only. A list of task status. This field keeps a record of task status evolving
        over time.
        """
        pass
    @property
    def inputs(self) -> google.protobuf.internal.containers.MessageMap[typing.Text, global___PipelineTaskDetail.ArtifactList]:
        """Output only. The runtime input artifacts of the task."""
        pass
    @property
    def outputs(self) -> google.protobuf.internal.containers.MessageMap[typing.Text, global___PipelineTaskDetail.ArtifactList]:
        """Output only. The runtime output artifacts of the task."""
        pass
    def __init__(self,
        *,
        task_id : builtins.int = ...,
        parent_task_id : builtins.int = ...,
        task_name : typing.Text = ...,
        create_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        start_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        end_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        executor_detail : typing.Optional[global___PipelineTaskExecutorDetail] = ...,
        state : global___PipelineTaskDetail.State.ValueType = ...,
        execution : typing.Optional[google.cloud.aiplatform.v1.execution_pb2.Execution] = ...,
        error : typing.Optional[google.rpc.status_pb2.Status] = ...,
        pipeline_task_status : typing.Optional[typing.Iterable[global___PipelineTaskDetail.PipelineTaskStatus]] = ...,
        inputs : typing.Optional[typing.Mapping[typing.Text, global___PipelineTaskDetail.ArtifactList]] = ...,
        outputs : typing.Optional[typing.Mapping[typing.Text, global___PipelineTaskDetail.ArtifactList]] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["create_time",b"create_time","end_time",b"end_time","error",b"error","execution",b"execution","executor_detail",b"executor_detail","start_time",b"start_time"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["create_time",b"create_time","end_time",b"end_time","error",b"error","execution",b"execution","executor_detail",b"executor_detail","inputs",b"inputs","outputs",b"outputs","parent_task_id",b"parent_task_id","pipeline_task_status",b"pipeline_task_status","start_time",b"start_time","state",b"state","task_id",b"task_id","task_name",b"task_name"]) -> None: ...
global___PipelineTaskDetail = PipelineTaskDetail

class PipelineTaskExecutorDetail(google.protobuf.message.Message):
    """The runtime detail of a pipeline executor."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class ContainerDetail(google.protobuf.message.Message):
        """The detail of a container execution. It contains the job names of the
        lifecycle of a container execution.
        """
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        MAIN_JOB_FIELD_NUMBER: builtins.int
        PRE_CACHING_CHECK_JOB_FIELD_NUMBER: builtins.int
        main_job: typing.Text = ...
        """Output only. The name of the [CustomJob][google.cloud.aiplatform.v1.CustomJob] for the main container execution."""

        pre_caching_check_job: typing.Text = ...
        """Output only. The name of the [CustomJob][google.cloud.aiplatform.v1.CustomJob] for the pre-caching-check container
        execution. This job will be available if the
        [PipelineJob.pipeline_spec][google.cloud.aiplatform.v1.PipelineJob.pipeline_spec] specifies the `pre_caching_check` hook in
        the lifecycle events.
        """

        def __init__(self,
            *,
            main_job : typing.Text = ...,
            pre_caching_check_job : typing.Text = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["main_job",b"main_job","pre_caching_check_job",b"pre_caching_check_job"]) -> None: ...

    class CustomJobDetail(google.protobuf.message.Message):
        """The detailed info for a custom job executor."""
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        JOB_FIELD_NUMBER: builtins.int
        job: typing.Text = ...
        """Output only. The name of the [CustomJob][google.cloud.aiplatform.v1.CustomJob]."""

        def __init__(self,
            *,
            job : typing.Text = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["job",b"job"]) -> None: ...

    CONTAINER_DETAIL_FIELD_NUMBER: builtins.int
    CUSTOM_JOB_DETAIL_FIELD_NUMBER: builtins.int
    @property
    def container_detail(self) -> global___PipelineTaskExecutorDetail.ContainerDetail:
        """Output only. The detailed info for a container executor."""
        pass
    @property
    def custom_job_detail(self) -> global___PipelineTaskExecutorDetail.CustomJobDetail:
        """Output only. The detailed info for a custom job executor."""
        pass
    def __init__(self,
        *,
        container_detail : typing.Optional[global___PipelineTaskExecutorDetail.ContainerDetail] = ...,
        custom_job_detail : typing.Optional[global___PipelineTaskExecutorDetail.CustomJobDetail] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["container_detail",b"container_detail","custom_job_detail",b"custom_job_detail","details",b"details"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["container_detail",b"container_detail","custom_job_detail",b"custom_job_detail","details",b"details"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["details",b"details"]) -> typing.Optional[typing_extensions.Literal["container_detail","custom_job_detail"]]: ...
global___PipelineTaskExecutorDetail = PipelineTaskExecutorDetail
