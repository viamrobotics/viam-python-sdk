"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import google.cloud.datalabeling.v1beta1.annotation_pb2
import google.cloud.datalabeling.v1beta1.annotation_spec_set_pb2
import google.protobuf.descriptor
import google.protobuf.internal.containers
import google.protobuf.message
import google.protobuf.timestamp_pb2
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor = ...

class Evaluation(google.protobuf.message.Message):
    """Describes an evaluation between a machine learning model's predictions and
    ground truth labels. Created when an [EvaluationJob][google.cloud.datalabeling.v1beta1.EvaluationJob] runs successfully.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    NAME_FIELD_NUMBER: builtins.int
    CONFIG_FIELD_NUMBER: builtins.int
    EVALUATION_JOB_RUN_TIME_FIELD_NUMBER: builtins.int
    CREATE_TIME_FIELD_NUMBER: builtins.int
    EVALUATION_METRICS_FIELD_NUMBER: builtins.int
    ANNOTATION_TYPE_FIELD_NUMBER: builtins.int
    EVALUATED_ITEM_COUNT_FIELD_NUMBER: builtins.int
    name: typing.Text = ...
    """Output only. Resource name of an evaluation. The name has the following
    format:

    "projects/<var>{project_id}</var>/datasets/<var>{dataset_id}</var>/evaluations/<var>{evaluation_id</var>}'
    """

    @property
    def config(self) -> global___EvaluationConfig:
        """Output only. Options used in the evaluation job that created this
        evaluation.
        """
        pass
    @property
    def evaluation_job_run_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Output only. Timestamp for when the evaluation job that created this
        evaluation ran.
        """
        pass
    @property
    def create_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Output only. Timestamp for when this evaluation was created."""
        pass
    @property
    def evaluation_metrics(self) -> global___EvaluationMetrics:
        """Output only. Metrics comparing predictions to ground truth labels."""
        pass
    annotation_type: google.cloud.datalabeling.v1beta1.annotation_pb2.AnnotationType.ValueType = ...
    """Output only. Type of task that the model version being evaluated performs,
    as defined in the

    [evaluationJobConfig.inputConfig.annotationType][google.cloud.datalabeling.v1beta1.EvaluationJobConfig.input_config]
    field of the evaluation job that created this evaluation.
    """

    evaluated_item_count: builtins.int = ...
    """Output only. The number of items in the ground truth dataset that were used
    for this evaluation. Only populated when the evaulation is for certain
    AnnotationTypes.
    """

    def __init__(self,
        *,
        name : typing.Text = ...,
        config : typing.Optional[global___EvaluationConfig] = ...,
        evaluation_job_run_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        create_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        evaluation_metrics : typing.Optional[global___EvaluationMetrics] = ...,
        annotation_type : google.cloud.datalabeling.v1beta1.annotation_pb2.AnnotationType.ValueType = ...,
        evaluated_item_count : builtins.int = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["config",b"config","create_time",b"create_time","evaluation_job_run_time",b"evaluation_job_run_time","evaluation_metrics",b"evaluation_metrics"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["annotation_type",b"annotation_type","config",b"config","create_time",b"create_time","evaluated_item_count",b"evaluated_item_count","evaluation_job_run_time",b"evaluation_job_run_time","evaluation_metrics",b"evaluation_metrics","name",b"name"]) -> None: ...
global___Evaluation = Evaluation

class EvaluationConfig(google.protobuf.message.Message):
    """Configuration details used for calculating evaluation metrics and creating an
    [Evaluation][google.cloud.datalabeling.v1beta1.Evaluation].
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    BOUNDING_BOX_EVALUATION_OPTIONS_FIELD_NUMBER: builtins.int
    @property
    def bounding_box_evaluation_options(self) -> global___BoundingBoxEvaluationOptions:
        """Only specify this field if the related model performs image object
        detection (`IMAGE_BOUNDING_BOX_ANNOTATION`). Describes how to evaluate
        bounding boxes.
        """
        pass
    def __init__(self,
        *,
        bounding_box_evaluation_options : typing.Optional[global___BoundingBoxEvaluationOptions] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["bounding_box_evaluation_options",b"bounding_box_evaluation_options","vertical_option",b"vertical_option"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["bounding_box_evaluation_options",b"bounding_box_evaluation_options","vertical_option",b"vertical_option"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["vertical_option",b"vertical_option"]) -> typing.Optional[typing_extensions.Literal["bounding_box_evaluation_options"]]: ...
global___EvaluationConfig = EvaluationConfig

class BoundingBoxEvaluationOptions(google.protobuf.message.Message):
    """Options regarding evaluation between bounding boxes."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    IOU_THRESHOLD_FIELD_NUMBER: builtins.int
    iou_threshold: builtins.float = ...
    """Minimum
    [intersection-over-union

    (IOU)](/vision/automl/object-detection/docs/evaluate#intersection-over-union)
    required for 2 bounding boxes to be considered a match. This must be a
    number between 0 and 1.
    """

    def __init__(self,
        *,
        iou_threshold : builtins.float = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["iou_threshold",b"iou_threshold"]) -> None: ...
global___BoundingBoxEvaluationOptions = BoundingBoxEvaluationOptions

class EvaluationMetrics(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    CLASSIFICATION_METRICS_FIELD_NUMBER: builtins.int
    OBJECT_DETECTION_METRICS_FIELD_NUMBER: builtins.int
    @property
    def classification_metrics(self) -> global___ClassificationMetrics: ...
    @property
    def object_detection_metrics(self) -> global___ObjectDetectionMetrics: ...
    def __init__(self,
        *,
        classification_metrics : typing.Optional[global___ClassificationMetrics] = ...,
        object_detection_metrics : typing.Optional[global___ObjectDetectionMetrics] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["classification_metrics",b"classification_metrics","metrics",b"metrics","object_detection_metrics",b"object_detection_metrics"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["classification_metrics",b"classification_metrics","metrics",b"metrics","object_detection_metrics",b"object_detection_metrics"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["metrics",b"metrics"]) -> typing.Optional[typing_extensions.Literal["classification_metrics","object_detection_metrics"]]: ...
global___EvaluationMetrics = EvaluationMetrics

class ClassificationMetrics(google.protobuf.message.Message):
    """Metrics calculated for a classification model."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    PR_CURVE_FIELD_NUMBER: builtins.int
    CONFUSION_MATRIX_FIELD_NUMBER: builtins.int
    @property
    def pr_curve(self) -> global___PrCurve:
        """Precision-recall curve based on ground truth labels, predicted labels, and
        scores for the predicted labels.
        """
        pass
    @property
    def confusion_matrix(self) -> global___ConfusionMatrix:
        """Confusion matrix of predicted labels vs. ground truth labels."""
        pass
    def __init__(self,
        *,
        pr_curve : typing.Optional[global___PrCurve] = ...,
        confusion_matrix : typing.Optional[global___ConfusionMatrix] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["confusion_matrix",b"confusion_matrix","pr_curve",b"pr_curve"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["confusion_matrix",b"confusion_matrix","pr_curve",b"pr_curve"]) -> None: ...
global___ClassificationMetrics = ClassificationMetrics

class ObjectDetectionMetrics(google.protobuf.message.Message):
    """Metrics calculated for an image object detection (bounding box) model."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    PR_CURVE_FIELD_NUMBER: builtins.int
    @property
    def pr_curve(self) -> global___PrCurve:
        """Precision-recall curve."""
        pass
    def __init__(self,
        *,
        pr_curve : typing.Optional[global___PrCurve] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["pr_curve",b"pr_curve"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["pr_curve",b"pr_curve"]) -> None: ...
global___ObjectDetectionMetrics = ObjectDetectionMetrics

class PrCurve(google.protobuf.message.Message):
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class ConfidenceMetricsEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        CONFIDENCE_THRESHOLD_FIELD_NUMBER: builtins.int
        RECALL_FIELD_NUMBER: builtins.int
        PRECISION_FIELD_NUMBER: builtins.int
        F1_SCORE_FIELD_NUMBER: builtins.int
        RECALL_AT1_FIELD_NUMBER: builtins.int
        PRECISION_AT1_FIELD_NUMBER: builtins.int
        F1_SCORE_AT1_FIELD_NUMBER: builtins.int
        RECALL_AT5_FIELD_NUMBER: builtins.int
        PRECISION_AT5_FIELD_NUMBER: builtins.int
        F1_SCORE_AT5_FIELD_NUMBER: builtins.int
        confidence_threshold: builtins.float = ...
        """Threshold used for this entry.

        For classification tasks, this is a classification threshold: a
        predicted label is categorized as positive or negative (in the context of
        this point on the PR curve) based on whether the label's score meets this
        threshold.

        For image object detection (bounding box) tasks, this is the
        [intersection-over-union

        (IOU)](/vision/automl/object-detection/docs/evaluate#intersection-over-union)
        threshold for the context of this point on the PR curve.
        """

        recall: builtins.float = ...
        """Recall value."""

        precision: builtins.float = ...
        """Precision value."""

        f1_score: builtins.float = ...
        """Harmonic mean of recall and precision."""

        recall_at1: builtins.float = ...
        """Recall value for entries with label that has highest score."""

        precision_at1: builtins.float = ...
        """Precision value for entries with label that has highest score."""

        f1_score_at1: builtins.float = ...
        """The harmonic mean of [recall_at1][google.cloud.datalabeling.v1beta1.PrCurve.ConfidenceMetricsEntry.recall_at1] and [precision_at1][google.cloud.datalabeling.v1beta1.PrCurve.ConfidenceMetricsEntry.precision_at1]."""

        recall_at5: builtins.float = ...
        """Recall value for entries with label that has highest 5 scores."""

        precision_at5: builtins.float = ...
        """Precision value for entries with label that has highest 5 scores."""

        f1_score_at5: builtins.float = ...
        """The harmonic mean of [recall_at5][google.cloud.datalabeling.v1beta1.PrCurve.ConfidenceMetricsEntry.recall_at5] and [precision_at5][google.cloud.datalabeling.v1beta1.PrCurve.ConfidenceMetricsEntry.precision_at5]."""

        def __init__(self,
            *,
            confidence_threshold : builtins.float = ...,
            recall : builtins.float = ...,
            precision : builtins.float = ...,
            f1_score : builtins.float = ...,
            recall_at1 : builtins.float = ...,
            precision_at1 : builtins.float = ...,
            f1_score_at1 : builtins.float = ...,
            recall_at5 : builtins.float = ...,
            precision_at5 : builtins.float = ...,
            f1_score_at5 : builtins.float = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["confidence_threshold",b"confidence_threshold","f1_score",b"f1_score","f1_score_at1",b"f1_score_at1","f1_score_at5",b"f1_score_at5","precision",b"precision","precision_at1",b"precision_at1","precision_at5",b"precision_at5","recall",b"recall","recall_at1",b"recall_at1","recall_at5",b"recall_at5"]) -> None: ...

    ANNOTATION_SPEC_FIELD_NUMBER: builtins.int
    AREA_UNDER_CURVE_FIELD_NUMBER: builtins.int
    CONFIDENCE_METRICS_ENTRIES_FIELD_NUMBER: builtins.int
    MEAN_AVERAGE_PRECISION_FIELD_NUMBER: builtins.int
    @property
    def annotation_spec(self) -> google.cloud.datalabeling.v1beta1.annotation_spec_set_pb2.AnnotationSpec:
        """The annotation spec of the label for which the precision-recall curve
        calculated. If this field is empty, that means the precision-recall curve
        is an aggregate curve for all labels.
        """
        pass
    area_under_curve: builtins.float = ...
    """Area under the precision-recall curve. Not to be confused with area under
    a receiver operating characteristic (ROC) curve.
    """

    @property
    def confidence_metrics_entries(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___PrCurve.ConfidenceMetricsEntry]:
        """Entries that make up the precision-recall graph. Each entry is a "point" on
        the graph drawn for a different `confidence_threshold`.
        """
        pass
    mean_average_precision: builtins.float = ...
    """Mean average prcision of this curve."""

    def __init__(self,
        *,
        annotation_spec : typing.Optional[google.cloud.datalabeling.v1beta1.annotation_spec_set_pb2.AnnotationSpec] = ...,
        area_under_curve : builtins.float = ...,
        confidence_metrics_entries : typing.Optional[typing.Iterable[global___PrCurve.ConfidenceMetricsEntry]] = ...,
        mean_average_precision : builtins.float = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["annotation_spec",b"annotation_spec"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["annotation_spec",b"annotation_spec","area_under_curve",b"area_under_curve","confidence_metrics_entries",b"confidence_metrics_entries","mean_average_precision",b"mean_average_precision"]) -> None: ...
global___PrCurve = PrCurve

class ConfusionMatrix(google.protobuf.message.Message):
    """Confusion matrix of the model running the classification. Only applicable
    when the metrics entry aggregates multiple labels. Not applicable when the
    entry is for a single label.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class ConfusionMatrixEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        ANNOTATION_SPEC_FIELD_NUMBER: builtins.int
        ITEM_COUNT_FIELD_NUMBER: builtins.int
        @property
        def annotation_spec(self) -> google.cloud.datalabeling.v1beta1.annotation_spec_set_pb2.AnnotationSpec:
            """The annotation spec of a predicted label."""
            pass
        item_count: builtins.int = ...
        """Number of items predicted to have this label. (The ground truth label for
        these items is the `Row.annotationSpec` of this entry's parent.)
        """

        def __init__(self,
            *,
            annotation_spec : typing.Optional[google.cloud.datalabeling.v1beta1.annotation_spec_set_pb2.AnnotationSpec] = ...,
            item_count : builtins.int = ...,
            ) -> None: ...
        def HasField(self, field_name: typing_extensions.Literal["annotation_spec",b"annotation_spec"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing_extensions.Literal["annotation_spec",b"annotation_spec","item_count",b"item_count"]) -> None: ...

    class Row(google.protobuf.message.Message):
        """A row in the confusion matrix. Each entry in this row has the same
        ground truth label.
        """
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        ANNOTATION_SPEC_FIELD_NUMBER: builtins.int
        ENTRIES_FIELD_NUMBER: builtins.int
        @property
        def annotation_spec(self) -> google.cloud.datalabeling.v1beta1.annotation_spec_set_pb2.AnnotationSpec:
            """The annotation spec of the ground truth label for this row."""
            pass
        @property
        def entries(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ConfusionMatrix.ConfusionMatrixEntry]:
            """A list of the confusion matrix entries. One entry for each possible
            predicted label.
            """
            pass
        def __init__(self,
            *,
            annotation_spec : typing.Optional[google.cloud.datalabeling.v1beta1.annotation_spec_set_pb2.AnnotationSpec] = ...,
            entries : typing.Optional[typing.Iterable[global___ConfusionMatrix.ConfusionMatrixEntry]] = ...,
            ) -> None: ...
        def HasField(self, field_name: typing_extensions.Literal["annotation_spec",b"annotation_spec"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing_extensions.Literal["annotation_spec",b"annotation_spec","entries",b"entries"]) -> None: ...

    ROW_FIELD_NUMBER: builtins.int
    @property
    def row(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ConfusionMatrix.Row]: ...
    def __init__(self,
        *,
        row : typing.Optional[typing.Iterable[global___ConfusionMatrix.Row]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["row",b"row"]) -> None: ...
global___ConfusionMatrix = ConfusionMatrix
