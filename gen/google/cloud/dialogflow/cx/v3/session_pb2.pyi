"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import google.cloud.dialogflow.cx.v3.audio_config_pb2
import google.cloud.dialogflow.cx.v3.intent_pb2
import google.cloud.dialogflow.cx.v3.page_pb2
import google.cloud.dialogflow.cx.v3.response_message_pb2
import google.cloud.dialogflow.cx.v3.session_entity_type_pb2
import google.protobuf.descriptor
import google.protobuf.duration_pb2
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import google.protobuf.struct_pb2
import google.rpc.status_pb2
import google.type.latlng_pb2
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor = ...

class DetectIntentRequest(google.protobuf.message.Message):
    """The request to detect user's intent."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    SESSION_FIELD_NUMBER: builtins.int
    QUERY_PARAMS_FIELD_NUMBER: builtins.int
    QUERY_INPUT_FIELD_NUMBER: builtins.int
    OUTPUT_AUDIO_CONFIG_FIELD_NUMBER: builtins.int
    session: typing.Text = ...
    """Required. The name of the session this query is sent to.
    Format: `projects/<Project ID>/locations/<Location ID>/agents/<Agent
    ID>/sessions/<Session ID>` or `projects/<Project ID>/locations/<Location
    ID>/agents/<Agent ID>/environments/<Environment ID>/sessions/<Session ID>`.
    If `Environment ID` is not specified, we assume default 'draft'
    environment.
    It's up to the API caller to choose an appropriate `Session ID`. It can be
    a random number or some type of session identifiers (preferably hashed).
    The length of the `Session ID` must not exceed 36 characters.

    For more information, see the [sessions
    guide](https://cloud.google.com/dialogflow/cx/docs/concept/session).

    Note: Always use agent versions for production traffic.
    See [Versions and
    environments](https://cloud.google.com/dialogflow/cx/docs/concept/version).
    """

    @property
    def query_params(self) -> global___QueryParameters:
        """The parameters of this query."""
        pass
    @property
    def query_input(self) -> global___QueryInput:
        """Required. The input specification."""
        pass
    @property
    def output_audio_config(self) -> google.cloud.dialogflow.cx.v3.audio_config_pb2.OutputAudioConfig:
        """Instructs the speech synthesizer how to generate the output audio."""
        pass
    def __init__(self,
        *,
        session : typing.Text = ...,
        query_params : typing.Optional[global___QueryParameters] = ...,
        query_input : typing.Optional[global___QueryInput] = ...,
        output_audio_config : typing.Optional[google.cloud.dialogflow.cx.v3.audio_config_pb2.OutputAudioConfig] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["output_audio_config",b"output_audio_config","query_input",b"query_input","query_params",b"query_params"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["output_audio_config",b"output_audio_config","query_input",b"query_input","query_params",b"query_params","session",b"session"]) -> None: ...
global___DetectIntentRequest = DetectIntentRequest

class DetectIntentResponse(google.protobuf.message.Message):
    """The message returned from the DetectIntent method."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class _ResponseType:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _ResponseTypeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_ResponseType.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        RESPONSE_TYPE_UNSPECIFIED: DetectIntentResponse.ResponseType.ValueType = ...  # 0
        """Not specified. This should never happen."""

        PARTIAL: DetectIntentResponse.ResponseType.ValueType = ...  # 1
        """Partial response. e.g. Aggregated responses in a Fulfillment that enables
        `return_partial_response` can be returned as partial response.
        WARNING: partial response is not eligible for barge-in.
        """

        FINAL: DetectIntentResponse.ResponseType.ValueType = ...  # 2
        """Final response."""

    class ResponseType(_ResponseType, metaclass=_ResponseTypeEnumTypeWrapper):
        """Represents different DetectIntentResponse types."""
        pass

    RESPONSE_TYPE_UNSPECIFIED: DetectIntentResponse.ResponseType.ValueType = ...  # 0
    """Not specified. This should never happen."""

    PARTIAL: DetectIntentResponse.ResponseType.ValueType = ...  # 1
    """Partial response. e.g. Aggregated responses in a Fulfillment that enables
    `return_partial_response` can be returned as partial response.
    WARNING: partial response is not eligible for barge-in.
    """

    FINAL: DetectIntentResponse.ResponseType.ValueType = ...  # 2
    """Final response."""


    RESPONSE_ID_FIELD_NUMBER: builtins.int
    QUERY_RESULT_FIELD_NUMBER: builtins.int
    OUTPUT_AUDIO_FIELD_NUMBER: builtins.int
    OUTPUT_AUDIO_CONFIG_FIELD_NUMBER: builtins.int
    RESPONSE_TYPE_FIELD_NUMBER: builtins.int
    ALLOW_CANCELLATION_FIELD_NUMBER: builtins.int
    response_id: typing.Text = ...
    """Output only. The unique identifier of the response. It can be used to
    locate a response in the training example set or for reporting issues.
    """

    @property
    def query_result(self) -> global___QueryResult:
        """The result of the conversational query."""
        pass
    output_audio: builtins.bytes = ...
    """The audio data bytes encoded as specified in the request.
    Note: The output audio is generated based on the values of default platform
    text responses found in the
    [`query_result.response_messages`][google.cloud.dialogflow.cx.v3.QueryResult.response_messages] field. If
    multiple default text responses exist, they will be concatenated when
    generating audio. If no default platform text responses exist, the
    generated audio content will be empty.

    In some scenarios, multiple output audio fields may be present in the
    response structure. In these cases, only the top-most-level audio output
    has content.
    """

    @property
    def output_audio_config(self) -> google.cloud.dialogflow.cx.v3.audio_config_pb2.OutputAudioConfig:
        """The config used by the speech synthesizer to generate the output audio."""
        pass
    response_type: global___DetectIntentResponse.ResponseType.ValueType = ...
    """Response type."""

    allow_cancellation: builtins.bool = ...
    """Indicates whether the partial response can be cancelled when a later
    response arrives. e.g. if the agent specified some music as partial
    response, it can be cancelled.
    """

    def __init__(self,
        *,
        response_id : typing.Text = ...,
        query_result : typing.Optional[global___QueryResult] = ...,
        output_audio : builtins.bytes = ...,
        output_audio_config : typing.Optional[google.cloud.dialogflow.cx.v3.audio_config_pb2.OutputAudioConfig] = ...,
        response_type : global___DetectIntentResponse.ResponseType.ValueType = ...,
        allow_cancellation : builtins.bool = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["output_audio_config",b"output_audio_config","query_result",b"query_result"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["allow_cancellation",b"allow_cancellation","output_audio",b"output_audio","output_audio_config",b"output_audio_config","query_result",b"query_result","response_id",b"response_id","response_type",b"response_type"]) -> None: ...
global___DetectIntentResponse = DetectIntentResponse

class StreamingDetectIntentRequest(google.protobuf.message.Message):
    """The top-level message sent by the client to the
    [Sessions.StreamingDetectIntent][google.cloud.dialogflow.cx.v3.Sessions.StreamingDetectIntent] method.

    Multiple request messages should be sent in order:

    1.  The first message must contain
        [session][google.cloud.dialogflow.cx.v3.StreamingDetectIntentRequest.session],
        [query_input][google.cloud.dialogflow.cx.v3.StreamingDetectIntentRequest.query_input] plus optionally
        [query_params][google.cloud.dialogflow.cx.v3.StreamingDetectIntentRequest.query_params]. If the client
        wants to receive an audio response, it should also contain
        [output_audio_config][google.cloud.dialogflow.cx.v3.StreamingDetectIntentRequest.output_audio_config].

    2.  If [query_input][google.cloud.dialogflow.cx.v3.StreamingDetectIntentRequest.query_input] was set to
        [query_input.audio.config][google.cloud.dialogflow.cx.v3.AudioInput.config], all subsequent messages
        must contain [query_input.audio.audio][google.cloud.dialogflow.cx.v3.AudioInput.audio] to continue with
        Speech recognition.
        If you decide to rather detect an intent from text
        input after you already started Speech recognition, please send a message
        with [query_input.text][google.cloud.dialogflow.cx.v3.QueryInput.text].

        However, note that:

        * Dialogflow will bill you for the audio duration so far.
        * Dialogflow discards all Speech recognition results in favor of the
          input text.
        * Dialogflow will use the language code from the first message.

    After you sent all input, you must half-close or abort the request stream.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    SESSION_FIELD_NUMBER: builtins.int
    QUERY_PARAMS_FIELD_NUMBER: builtins.int
    QUERY_INPUT_FIELD_NUMBER: builtins.int
    OUTPUT_AUDIO_CONFIG_FIELD_NUMBER: builtins.int
    ENABLE_PARTIAL_RESPONSE_FIELD_NUMBER: builtins.int
    session: typing.Text = ...
    """The name of the session this query is sent to.
    Format: `projects/<Project ID>/locations/<Location ID>/agents/<Agent
    ID>/sessions/<Session ID>` or `projects/<Project ID>/locations/<Location
    ID>/agents/<Agent ID>/environments/<Environment ID>/sessions/<Session ID>`.
    If `Environment ID` is not specified, we assume default 'draft'
    environment.
    It's up to the API caller to choose an appropriate `Session ID`. It can be
    a random number or some type of session identifiers (preferably hashed).
    The length of the `Session ID` must not exceed 36 characters.
    Note: session must be set in the first request.

    For more information, see the [sessions
    guide](https://cloud.google.com/dialogflow/cx/docs/concept/session).

    Note: Always use agent versions for production traffic.
    See [Versions and
    environments](https://cloud.google.com/dialogflow/cx/docs/concept/version).
    """

    @property
    def query_params(self) -> global___QueryParameters:
        """The parameters of this query."""
        pass
    @property
    def query_input(self) -> global___QueryInput:
        """Required. The input specification."""
        pass
    @property
    def output_audio_config(self) -> google.cloud.dialogflow.cx.v3.audio_config_pb2.OutputAudioConfig:
        """Instructs the speech synthesizer how to generate the output audio."""
        pass
    enable_partial_response: builtins.bool = ...
    """Enable partial detect intent response. If this flag is not enabled,
    response stream still contains only one final `DetectIntentResponse` even
    if some `Fulfillment`s in the agent have been configured to return partial
    responses.
    """

    def __init__(self,
        *,
        session : typing.Text = ...,
        query_params : typing.Optional[global___QueryParameters] = ...,
        query_input : typing.Optional[global___QueryInput] = ...,
        output_audio_config : typing.Optional[google.cloud.dialogflow.cx.v3.audio_config_pb2.OutputAudioConfig] = ...,
        enable_partial_response : builtins.bool = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["output_audio_config",b"output_audio_config","query_input",b"query_input","query_params",b"query_params"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["enable_partial_response",b"enable_partial_response","output_audio_config",b"output_audio_config","query_input",b"query_input","query_params",b"query_params","session",b"session"]) -> None: ...
global___StreamingDetectIntentRequest = StreamingDetectIntentRequest

class StreamingDetectIntentResponse(google.protobuf.message.Message):
    """The top-level message returned from the
    [StreamingDetectIntent][google.cloud.dialogflow.cx.v3.Sessions.StreamingDetectIntent] method.

    Multiple response messages (N) can be returned in order.

    The first (N-1) responses set either the `recognition_result` or
    `detect_intent_response` field, depending on the request:

    *   If the `StreamingDetectIntentRequest.query_input.audio` field was
        set, and the `StreamingDetectIntentRequest.enable_partial_response`
        field was false, the `recognition_result` field is populated for each
        of the (N-1) responses.
        See the [StreamingRecognitionResult][google.cloud.dialogflow.cx.v3.StreamingRecognitionResult] message for details
        about the result message sequence.

    *   If the `StreamingDetectIntentRequest.enable_partial_response` field was
        true, the `detect_intent_response` field is populated for each
        of the (N-1) responses, where 1 <= N <= 4.
        These responses set the [DetectIntentResponse.response_type][google.cloud.dialogflow.cx.v3.DetectIntentResponse.response_type] field
        to `PARTIAL`.

    For the final Nth response message, the `detect_intent_response` is fully
    populated, and [DetectIntentResponse.response_type][google.cloud.dialogflow.cx.v3.DetectIntentResponse.response_type] is set to `FINAL`.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    RECOGNITION_RESULT_FIELD_NUMBER: builtins.int
    DETECT_INTENT_RESPONSE_FIELD_NUMBER: builtins.int
    @property
    def recognition_result(self) -> global___StreamingRecognitionResult:
        """The result of speech recognition."""
        pass
    @property
    def detect_intent_response(self) -> global___DetectIntentResponse:
        """The response from detect intent."""
        pass
    def __init__(self,
        *,
        recognition_result : typing.Optional[global___StreamingRecognitionResult] = ...,
        detect_intent_response : typing.Optional[global___DetectIntentResponse] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["detect_intent_response",b"detect_intent_response","recognition_result",b"recognition_result","response",b"response"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["detect_intent_response",b"detect_intent_response","recognition_result",b"recognition_result","response",b"response"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["response",b"response"]) -> typing.Optional[typing_extensions.Literal["recognition_result","detect_intent_response"]]: ...
global___StreamingDetectIntentResponse = StreamingDetectIntentResponse

class StreamingRecognitionResult(google.protobuf.message.Message):
    """Contains a speech recognition result corresponding to a portion of the audio
    that is currently being processed or an indication that this is the end
    of the single requested utterance.

    While end-user audio is being processed, Dialogflow sends a series of
    results. Each result may contain a `transcript` value. A transcript
    represents a portion of the utterance. While the recognizer is processing
    audio, transcript values may be interim values or finalized values.
    Once a transcript is finalized, the `is_final` value is set to true and
    processing continues for the next transcript.

    If `StreamingDetectIntentRequest.query_input.audio.config.single_utterance`
    was true, and the recognizer has completed processing audio,
    the `message_type` value is set to `END_OF_SINGLE_UTTERANCE and the
    following (last) result contains the last finalized transcript.

    The complete end-user utterance is determined by concatenating the
    finalized transcript values received for the series of results.

    In the following example, single utterance is enabled. In the case where
    single utterance is not enabled, result 7 would not occur.

    ```
    Num | transcript              | message_type            | is_final
    --- | ----------------------- | ----------------------- | --------
    1   | "tube"                  | TRANSCRIPT              | false
    2   | "to be a"               | TRANSCRIPT              | false
    3   | "to be"                 | TRANSCRIPT              | false
    4   | "to be or not to be"    | TRANSCRIPT              | true
    5   | "that's"                | TRANSCRIPT              | false
    6   | "that is                | TRANSCRIPT              | false
    7   | unset                   | END_OF_SINGLE_UTTERANCE | unset
    8   | " that is the question" | TRANSCRIPT              | true
    ```

    Concatenating the finalized transcripts with `is_final` set to true,
    the complete utterance becomes "to be or not to be that is the question".
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class _MessageType:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _MessageTypeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_MessageType.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        MESSAGE_TYPE_UNSPECIFIED: StreamingRecognitionResult.MessageType.ValueType = ...  # 0
        """Not specified. Should never be used."""

        TRANSCRIPT: StreamingRecognitionResult.MessageType.ValueType = ...  # 1
        """Message contains a (possibly partial) transcript."""

        END_OF_SINGLE_UTTERANCE: StreamingRecognitionResult.MessageType.ValueType = ...  # 2
        """Event indicates that the server has detected the end of the user's speech
        utterance and expects no additional speech. Therefore, the server will
        not process additional audio (although it may subsequently return
        additional results). The client should stop sending additional audio
        data, half-close the gRPC connection, and wait for any additional results
        until the server closes the gRPC connection. This message is only sent if
        [`single_utterance`][google.cloud.dialogflow.cx.v3.InputAudioConfig.single_utterance] was set to
        `true`, and is not used otherwise.
        """

    class MessageType(_MessageType, metaclass=_MessageTypeEnumTypeWrapper):
        """Type of the response message."""
        pass

    MESSAGE_TYPE_UNSPECIFIED: StreamingRecognitionResult.MessageType.ValueType = ...  # 0
    """Not specified. Should never be used."""

    TRANSCRIPT: StreamingRecognitionResult.MessageType.ValueType = ...  # 1
    """Message contains a (possibly partial) transcript."""

    END_OF_SINGLE_UTTERANCE: StreamingRecognitionResult.MessageType.ValueType = ...  # 2
    """Event indicates that the server has detected the end of the user's speech
    utterance and expects no additional speech. Therefore, the server will
    not process additional audio (although it may subsequently return
    additional results). The client should stop sending additional audio
    data, half-close the gRPC connection, and wait for any additional results
    until the server closes the gRPC connection. This message is only sent if
    [`single_utterance`][google.cloud.dialogflow.cx.v3.InputAudioConfig.single_utterance] was set to
    `true`, and is not used otherwise.
    """


    MESSAGE_TYPE_FIELD_NUMBER: builtins.int
    TRANSCRIPT_FIELD_NUMBER: builtins.int
    IS_FINAL_FIELD_NUMBER: builtins.int
    CONFIDENCE_FIELD_NUMBER: builtins.int
    STABILITY_FIELD_NUMBER: builtins.int
    SPEECH_WORD_INFO_FIELD_NUMBER: builtins.int
    SPEECH_END_OFFSET_FIELD_NUMBER: builtins.int
    LANGUAGE_CODE_FIELD_NUMBER: builtins.int
    message_type: global___StreamingRecognitionResult.MessageType.ValueType = ...
    """Type of the result message."""

    transcript: typing.Text = ...
    """Transcript text representing the words that the user spoke.
    Populated if and only if `message_type` = `TRANSCRIPT`.
    """

    is_final: builtins.bool = ...
    """If `false`, the `StreamingRecognitionResult` represents an
    interim result that may change. If `true`, the recognizer will not return
    any further hypotheses about this piece of the audio. May only be populated
    for `message_type` = `TRANSCRIPT`.
    """

    confidence: builtins.float = ...
    """The Speech confidence between 0.0 and 1.0 for the current portion of audio.
    A higher number indicates an estimated greater likelihood that the
    recognized words are correct. The default of 0.0 is a sentinel value
    indicating that confidence was not set.

    This field is typically only provided if `is_final` is true and you should
    not rely on it being accurate or even set.
    """

    stability: builtins.float = ...
    """An estimate of the likelihood that the speech recognizer will
    not change its guess about this interim recognition result:
    * If the value is unspecified or 0.0, Dialogflow didn't compute the
      stability. In particular, Dialogflow will only provide stability for
      `TRANSCRIPT` results with `is_final = false`.
    * Otherwise, the value is in (0.0, 1.0] where 0.0 means completely
      unstable and 1.0 means completely stable.
    """

    @property
    def speech_word_info(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[google.cloud.dialogflow.cx.v3.audio_config_pb2.SpeechWordInfo]:
        """Word-specific information for the words recognized by Speech in
        [transcript][google.cloud.dialogflow.cx.v3.StreamingRecognitionResult.transcript]. Populated if and only if `message_type` = `TRANSCRIPT` and
        [InputAudioConfig.enable_word_info] is set.
        """
        pass
    @property
    def speech_end_offset(self) -> google.protobuf.duration_pb2.Duration:
        """Time offset of the end of this Speech recognition result relative to the
        beginning of the audio. Only populated for `message_type` =
        `TRANSCRIPT`.
        """
        pass
    language_code: typing.Text = ...
    """Detected language code for the transcript."""

    def __init__(self,
        *,
        message_type : global___StreamingRecognitionResult.MessageType.ValueType = ...,
        transcript : typing.Text = ...,
        is_final : builtins.bool = ...,
        confidence : builtins.float = ...,
        stability : builtins.float = ...,
        speech_word_info : typing.Optional[typing.Iterable[google.cloud.dialogflow.cx.v3.audio_config_pb2.SpeechWordInfo]] = ...,
        speech_end_offset : typing.Optional[google.protobuf.duration_pb2.Duration] = ...,
        language_code : typing.Text = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["speech_end_offset",b"speech_end_offset"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["confidence",b"confidence","is_final",b"is_final","language_code",b"language_code","message_type",b"message_type","speech_end_offset",b"speech_end_offset","speech_word_info",b"speech_word_info","stability",b"stability","transcript",b"transcript"]) -> None: ...
global___StreamingRecognitionResult = StreamingRecognitionResult

class QueryParameters(google.protobuf.message.Message):
    """Represents the parameters of a conversational query."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class WebhookHeadersEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: typing.Text = ...
        value: typing.Text = ...
        def __init__(self,
            *,
            key : typing.Text = ...,
            value : typing.Text = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

    TIME_ZONE_FIELD_NUMBER: builtins.int
    GEO_LOCATION_FIELD_NUMBER: builtins.int
    SESSION_ENTITY_TYPES_FIELD_NUMBER: builtins.int
    PAYLOAD_FIELD_NUMBER: builtins.int
    PARAMETERS_FIELD_NUMBER: builtins.int
    CURRENT_PAGE_FIELD_NUMBER: builtins.int
    DISABLE_WEBHOOK_FIELD_NUMBER: builtins.int
    ANALYZE_QUERY_TEXT_SENTIMENT_FIELD_NUMBER: builtins.int
    WEBHOOK_HEADERS_FIELD_NUMBER: builtins.int
    FLOW_VERSIONS_FIELD_NUMBER: builtins.int
    time_zone: typing.Text = ...
    """The time zone of this conversational query from the [time zone
    database](https://www.iana.org/time-zones), e.g., America/New_York,
    Europe/Paris. If not provided, the time zone specified in the agent is
    used.
    """

    @property
    def geo_location(self) -> google.type.latlng_pb2.LatLng:
        """The geo location of this conversational query."""
        pass
    @property
    def session_entity_types(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[google.cloud.dialogflow.cx.v3.session_entity_type_pb2.SessionEntityType]:
        """Additional session entity types to replace or extend developer entity types
        with. The entity synonyms apply to all languages and persist for the
        session of this query.
        """
        pass
    @property
    def payload(self) -> google.protobuf.struct_pb2.Struct:
        """This field can be used to pass custom data into the webhook associated with
        the agent. Arbitrary JSON objects are supported.
        Some integrations that query a Dialogflow agent may provide additional
        information in the payload.
        In particular, for the Dialogflow Phone Gateway integration, this field has
        the form:
        ```
        {
         "telephony": {
           "caller_id": "+18558363987"
         }
        }
        ```
        """
        pass
    @property
    def parameters(self) -> google.protobuf.struct_pb2.Struct:
        """Additional parameters to be put into [session
        parameters][SessionInfo.parameters]. To remove a
        parameter from the session, clients should explicitly set the parameter
        value to null.

        You can reference the session parameters in the agent with the following
        format: $session.params.parameter-id.

        Depending on your protocol or client library language, this is a
        map, associative array, symbol table, dictionary, or JSON object
        composed of a collection of (MapKey, MapValue) pairs:

        -   MapKey type: string
        -   MapKey value: parameter name
        -   MapValue type:
            -   If parameter's entity type is a composite entity: map
            -   Else: depending on parameter value type, could be one of string,
                number, boolean, null, list or map
        -   MapValue value:
            -   If parameter's entity type is a composite entity:
                map from composite entity property names to property values
            -   Else: parameter value
        """
        pass
    current_page: typing.Text = ...
    """The unique identifier of the [page][google.cloud.dialogflow.cx.v3.Page] to override the [current
    page][QueryResult.current_page] in the session.
    Format: `projects/<Project ID>/locations/<Location ID>/agents/<Agent
    ID>/flows/<Flow ID>/pages/<Page ID>`.

    If `current_page` is specified, the previous state of the session will be
    ignored by Dialogflow, including the [previous
    page][QueryResult.current_page] and the [previous session
    parameters][QueryResult.parameters].
    In most cases, [current_page][google.cloud.dialogflow.cx.v3.QueryParameters.current_page] and
    [parameters][google.cloud.dialogflow.cx.v3.QueryParameters.parameters] should be configured together to
    direct a session to a specific state.
    """

    disable_webhook: builtins.bool = ...
    """Whether to disable webhook calls for this request."""

    analyze_query_text_sentiment: builtins.bool = ...
    """Configures whether sentiment analysis should be performed. If not
    provided, sentiment analysis is not performed.
    """

    @property
    def webhook_headers(self) -> google.protobuf.internal.containers.ScalarMap[typing.Text, typing.Text]:
        """This field can be used to pass HTTP headers for a webhook
        call. These headers will be sent to webhook along with the headers that
        have been configured through Dialogflow web console. The headers defined
        within this field will overwrite the headers configured through Dialogflow
        console if there is a conflict. Header names are case-insensitive.
        Google's specified headers are not allowed. Including: "Host",
        "Content-Length", "Connection", "From", "User-Agent", "Accept-Encoding",
        "If-Modified-Since", "If-None-Match", "X-Forwarded-For", etc.
        """
        pass
    @property
    def flow_versions(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
        """A list of flow versions to override for the request.
        Format: `projects/<Project ID>/locations/<Location ID>/agents/<Agent
        ID>/flows/<Flow ID>/versions/<Version ID>`.

        If version 1 of flow X is included in this list, the traffic of
        flow X will go through version 1 regardless of the version configuration in
        the environment. Each flow can have at most one version specified in this
        list.
        """
        pass
    def __init__(self,
        *,
        time_zone : typing.Text = ...,
        geo_location : typing.Optional[google.type.latlng_pb2.LatLng] = ...,
        session_entity_types : typing.Optional[typing.Iterable[google.cloud.dialogflow.cx.v3.session_entity_type_pb2.SessionEntityType]] = ...,
        payload : typing.Optional[google.protobuf.struct_pb2.Struct] = ...,
        parameters : typing.Optional[google.protobuf.struct_pb2.Struct] = ...,
        current_page : typing.Text = ...,
        disable_webhook : builtins.bool = ...,
        analyze_query_text_sentiment : builtins.bool = ...,
        webhook_headers : typing.Optional[typing.Mapping[typing.Text, typing.Text]] = ...,
        flow_versions : typing.Optional[typing.Iterable[typing.Text]] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["geo_location",b"geo_location","parameters",b"parameters","payload",b"payload"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["analyze_query_text_sentiment",b"analyze_query_text_sentiment","current_page",b"current_page","disable_webhook",b"disable_webhook","flow_versions",b"flow_versions","geo_location",b"geo_location","parameters",b"parameters","payload",b"payload","session_entity_types",b"session_entity_types","time_zone",b"time_zone","webhook_headers",b"webhook_headers"]) -> None: ...
global___QueryParameters = QueryParameters

class QueryInput(google.protobuf.message.Message):
    """Represents the query input. It can contain one of:

    1.  A conversational query in the form of text.

    2.  An intent query that specifies which intent to trigger.

    3.  Natural language speech audio to be processed.

    4.  An event to be triggered.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    TEXT_FIELD_NUMBER: builtins.int
    INTENT_FIELD_NUMBER: builtins.int
    AUDIO_FIELD_NUMBER: builtins.int
    EVENT_FIELD_NUMBER: builtins.int
    DTMF_FIELD_NUMBER: builtins.int
    LANGUAGE_CODE_FIELD_NUMBER: builtins.int
    @property
    def text(self) -> global___TextInput:
        """The natural language text to be processed."""
        pass
    @property
    def intent(self) -> global___IntentInput:
        """The intent to be triggered."""
        pass
    @property
    def audio(self) -> global___AudioInput:
        """The natural language speech audio to be processed."""
        pass
    @property
    def event(self) -> global___EventInput:
        """The event to be triggered."""
        pass
    @property
    def dtmf(self) -> global___DtmfInput:
        """The DTMF event to be handled."""
        pass
    language_code: typing.Text = ...
    """Required. The language of the input. See [Language
    Support](https://cloud.google.com/dialogflow/cx/docs/reference/language)
    for a list of the currently supported language codes. Note that queries in
    the same session do not necessarily need to specify the same language.
    """

    def __init__(self,
        *,
        text : typing.Optional[global___TextInput] = ...,
        intent : typing.Optional[global___IntentInput] = ...,
        audio : typing.Optional[global___AudioInput] = ...,
        event : typing.Optional[global___EventInput] = ...,
        dtmf : typing.Optional[global___DtmfInput] = ...,
        language_code : typing.Text = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["audio",b"audio","dtmf",b"dtmf","event",b"event","input",b"input","intent",b"intent","text",b"text"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["audio",b"audio","dtmf",b"dtmf","event",b"event","input",b"input","intent",b"intent","language_code",b"language_code","text",b"text"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["input",b"input"]) -> typing.Optional[typing_extensions.Literal["text","intent","audio","event","dtmf"]]: ...
global___QueryInput = QueryInput

class QueryResult(google.protobuf.message.Message):
    """Represents the result of a conversational query."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    TEXT_FIELD_NUMBER: builtins.int
    TRIGGER_INTENT_FIELD_NUMBER: builtins.int
    TRANSCRIPT_FIELD_NUMBER: builtins.int
    TRIGGER_EVENT_FIELD_NUMBER: builtins.int
    DTMF_FIELD_NUMBER: builtins.int
    LANGUAGE_CODE_FIELD_NUMBER: builtins.int
    PARAMETERS_FIELD_NUMBER: builtins.int
    RESPONSE_MESSAGES_FIELD_NUMBER: builtins.int
    WEBHOOK_STATUSES_FIELD_NUMBER: builtins.int
    WEBHOOK_PAYLOADS_FIELD_NUMBER: builtins.int
    CURRENT_PAGE_FIELD_NUMBER: builtins.int
    INTENT_FIELD_NUMBER: builtins.int
    INTENT_DETECTION_CONFIDENCE_FIELD_NUMBER: builtins.int
    MATCH_FIELD_NUMBER: builtins.int
    DIAGNOSTIC_INFO_FIELD_NUMBER: builtins.int
    SENTIMENT_ANALYSIS_RESULT_FIELD_NUMBER: builtins.int
    text: typing.Text = ...
    """If [natural language text][google.cloud.dialogflow.cx.v3.TextInput] was provided as input, this field
    will contain a copy of the text.
    """

    trigger_intent: typing.Text = ...
    """If an [intent][google.cloud.dialogflow.cx.v3.IntentInput] was provided as input, this field will
    contain a copy of the intent identifier.
    Format: `projects/<Project ID>/locations/<Location ID>/agents/<Agent
    ID>/intents/<Intent ID>`.
    """

    transcript: typing.Text = ...
    """If [natural language speech audio][google.cloud.dialogflow.cx.v3.AudioInput] was provided as input,
    this field will contain the transcript for the audio.
    """

    trigger_event: typing.Text = ...
    """If an [event][google.cloud.dialogflow.cx.v3.EventInput] was provided as input, this field will contain
    the name of the event.
    """

    @property
    def dtmf(self) -> global___DtmfInput:
        """If a [DTMF][DTMFInput] was provided as input, this field will contain
        a copy of the [DTMFInput][].
        """
        pass
    language_code: typing.Text = ...
    """The language that was triggered during intent detection.
    See [Language
    Support](https://cloud.google.com/dialogflow/cx/docs/reference/language)
    for a list of the currently supported language codes.
    """

    @property
    def parameters(self) -> google.protobuf.struct_pb2.Struct:
        """The collected [session parameters][google.cloud.dialogflow.cx.v3.SessionInfo.parameters].

        Depending on your protocol or client library language, this is a
        map, associative array, symbol table, dictionary, or JSON object
        composed of a collection of (MapKey, MapValue) pairs:

        -   MapKey type: string
        -   MapKey value: parameter name
        -   MapValue type:
            -   If parameter's entity type is a composite entity: map
            -   Else: depending on parameter value type, could be one of string,
                number, boolean, null, list or map
        -   MapValue value:
            -   If parameter's entity type is a composite entity:
                map from composite entity property names to property values
            -   Else: parameter value
        """
        pass
    @property
    def response_messages(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[google.cloud.dialogflow.cx.v3.response_message_pb2.ResponseMessage]:
        """The list of rich messages returned to the client. Responses vary from
        simple text messages to more sophisticated, structured payloads used
        to drive complex logic.
        """
        pass
    @property
    def webhook_statuses(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[google.rpc.status_pb2.Status]:
        """The list of webhook call status in the order of call sequence."""
        pass
    @property
    def webhook_payloads(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[google.protobuf.struct_pb2.Struct]:
        """The list of webhook payload in [WebhookResponse.payload][google.cloud.dialogflow.cx.v3.WebhookResponse.payload], in
        the order of call sequence. If some webhook call fails or doesn't return
        any payload, an empty `Struct` would be used instead.
        """
        pass
    @property
    def current_page(self) -> google.cloud.dialogflow.cx.v3.page_pb2.Page:
        """The current [Page][google.cloud.dialogflow.cx.v3.Page]. Some, not all fields are filled in this message,
        including but not limited to `name` and `display_name`.
        """
        pass
    @property
    def intent(self) -> google.cloud.dialogflow.cx.v3.intent_pb2.Intent:
        """The [Intent][google.cloud.dialogflow.cx.v3.Intent] that matched the conversational query. Some, not all fields
        are filled in this message, including but not limited to: `name` and
        `display_name`.
        This field is deprecated, please use [QueryResult.match][google.cloud.dialogflow.cx.v3.QueryResult.match] instead.
        """
        pass
    intent_detection_confidence: builtins.float = ...
    """The intent detection confidence. Values range from 0.0 (completely
    uncertain) to 1.0 (completely certain).
    This value is for informational purpose only and is only used to
    help match the best intent within the classification threshold.
    This value may change for the same end-user expression at any time due to a
    model retraining or change in implementation.
    This field is deprecated, please use [QueryResult.match][google.cloud.dialogflow.cx.v3.QueryResult.match] instead.
    """

    @property
    def match(self) -> global___Match:
        """Intent match result, could be an intent or an event."""
        pass
    @property
    def diagnostic_info(self) -> google.protobuf.struct_pb2.Struct:
        """The free-form diagnostic info. For example, this field could contain
        webhook call latency. The string keys of the Struct's fields map can change
        without notice.
        """
        pass
    @property
    def sentiment_analysis_result(self) -> global___SentimentAnalysisResult:
        """The sentiment analyss result, which depends on
        [`analyze_query_text_sentiment`]
        [google.cloud.dialogflow.cx.v3.QueryParameters.analyze_query_text_sentiment], specified in the request.
        """
        pass
    def __init__(self,
        *,
        text : typing.Text = ...,
        trigger_intent : typing.Text = ...,
        transcript : typing.Text = ...,
        trigger_event : typing.Text = ...,
        dtmf : typing.Optional[global___DtmfInput] = ...,
        language_code : typing.Text = ...,
        parameters : typing.Optional[google.protobuf.struct_pb2.Struct] = ...,
        response_messages : typing.Optional[typing.Iterable[google.cloud.dialogflow.cx.v3.response_message_pb2.ResponseMessage]] = ...,
        webhook_statuses : typing.Optional[typing.Iterable[google.rpc.status_pb2.Status]] = ...,
        webhook_payloads : typing.Optional[typing.Iterable[google.protobuf.struct_pb2.Struct]] = ...,
        current_page : typing.Optional[google.cloud.dialogflow.cx.v3.page_pb2.Page] = ...,
        intent : typing.Optional[google.cloud.dialogflow.cx.v3.intent_pb2.Intent] = ...,
        intent_detection_confidence : builtins.float = ...,
        match : typing.Optional[global___Match] = ...,
        diagnostic_info : typing.Optional[google.protobuf.struct_pb2.Struct] = ...,
        sentiment_analysis_result : typing.Optional[global___SentimentAnalysisResult] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["current_page",b"current_page","diagnostic_info",b"diagnostic_info","dtmf",b"dtmf","intent",b"intent","match",b"match","parameters",b"parameters","query",b"query","sentiment_analysis_result",b"sentiment_analysis_result","text",b"text","transcript",b"transcript","trigger_event",b"trigger_event","trigger_intent",b"trigger_intent"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["current_page",b"current_page","diagnostic_info",b"diagnostic_info","dtmf",b"dtmf","intent",b"intent","intent_detection_confidence",b"intent_detection_confidence","language_code",b"language_code","match",b"match","parameters",b"parameters","query",b"query","response_messages",b"response_messages","sentiment_analysis_result",b"sentiment_analysis_result","text",b"text","transcript",b"transcript","trigger_event",b"trigger_event","trigger_intent",b"trigger_intent","webhook_payloads",b"webhook_payloads","webhook_statuses",b"webhook_statuses"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["query",b"query"]) -> typing.Optional[typing_extensions.Literal["text","trigger_intent","transcript","trigger_event","dtmf"]]: ...
global___QueryResult = QueryResult

class TextInput(google.protobuf.message.Message):
    """Represents the natural language text to be processed."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    TEXT_FIELD_NUMBER: builtins.int
    text: typing.Text = ...
    """Required. The UTF-8 encoded natural language text to be processed. Text length must
    not exceed 256 characters.
    """

    def __init__(self,
        *,
        text : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["text",b"text"]) -> None: ...
global___TextInput = TextInput

class IntentInput(google.protobuf.message.Message):
    """Represents the intent to trigger programmatically rather than as a result of
    natural language processing.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    INTENT_FIELD_NUMBER: builtins.int
    intent: typing.Text = ...
    """Required. The unique identifier of the intent.
    Format: `projects/<Project ID>/locations/<Location ID>/agents/<Agent
    ID>/intents/<Intent ID>`.
    """

    def __init__(self,
        *,
        intent : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["intent",b"intent"]) -> None: ...
global___IntentInput = IntentInput

class AudioInput(google.protobuf.message.Message):
    """Represents the natural speech audio to be processed."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    CONFIG_FIELD_NUMBER: builtins.int
    AUDIO_FIELD_NUMBER: builtins.int
    @property
    def config(self) -> google.cloud.dialogflow.cx.v3.audio_config_pb2.InputAudioConfig:
        """Required. Instructs the speech recognizer how to process the speech audio."""
        pass
    audio: builtins.bytes = ...
    """The natural language speech audio to be processed.
    A single request can contain up to 1 minute of speech audio data.
    The [transcribed text][google.cloud.dialogflow.cx.v3.QueryResult.transcript] cannot contain more than 256
    bytes.

    For non-streaming audio detect intent, both `config` and `audio` must be
    provided.
    For streaming audio detect intent, `config` must be provided in
    the first request and `audio` must be provided in all following requests.
    """

    def __init__(self,
        *,
        config : typing.Optional[google.cloud.dialogflow.cx.v3.audio_config_pb2.InputAudioConfig] = ...,
        audio : builtins.bytes = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["config",b"config"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["audio",b"audio","config",b"config"]) -> None: ...
global___AudioInput = AudioInput

class EventInput(google.protobuf.message.Message):
    """Represents the event to trigger."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    EVENT_FIELD_NUMBER: builtins.int
    event: typing.Text = ...
    """Name of the event."""

    def __init__(self,
        *,
        event : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["event",b"event"]) -> None: ...
global___EventInput = EventInput

class DtmfInput(google.protobuf.message.Message):
    """Represents the input for dtmf event."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    DIGITS_FIELD_NUMBER: builtins.int
    FINISH_DIGIT_FIELD_NUMBER: builtins.int
    digits: typing.Text = ...
    """The dtmf digits."""

    finish_digit: typing.Text = ...
    """The finish digit (if any)."""

    def __init__(self,
        *,
        digits : typing.Text = ...,
        finish_digit : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["digits",b"digits","finish_digit",b"finish_digit"]) -> None: ...
global___DtmfInput = DtmfInput

class Match(google.protobuf.message.Message):
    """Represents one match result of [MatchIntent][]."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class _MatchType:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _MatchTypeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_MatchType.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        MATCH_TYPE_UNSPECIFIED: Match.MatchType.ValueType = ...  # 0
        """Not specified. Should never be used."""

        INTENT: Match.MatchType.ValueType = ...  # 1
        """The query was matched to an intent."""

        DIRECT_INTENT: Match.MatchType.ValueType = ...  # 2
        """The query directly triggered an intent."""

        PARAMETER_FILLING: Match.MatchType.ValueType = ...  # 3
        """The query was used for parameter filling."""

        NO_MATCH: Match.MatchType.ValueType = ...  # 4
        """No match was found for the query."""

        NO_INPUT: Match.MatchType.ValueType = ...  # 5
        """Indicates an empty query."""

        EVENT: Match.MatchType.ValueType = ...  # 6
        """The query directly triggered an event."""

    class MatchType(_MatchType, metaclass=_MatchTypeEnumTypeWrapper):
        """Type of a Match."""
        pass

    MATCH_TYPE_UNSPECIFIED: Match.MatchType.ValueType = ...  # 0
    """Not specified. Should never be used."""

    INTENT: Match.MatchType.ValueType = ...  # 1
    """The query was matched to an intent."""

    DIRECT_INTENT: Match.MatchType.ValueType = ...  # 2
    """The query directly triggered an intent."""

    PARAMETER_FILLING: Match.MatchType.ValueType = ...  # 3
    """The query was used for parameter filling."""

    NO_MATCH: Match.MatchType.ValueType = ...  # 4
    """No match was found for the query."""

    NO_INPUT: Match.MatchType.ValueType = ...  # 5
    """Indicates an empty query."""

    EVENT: Match.MatchType.ValueType = ...  # 6
    """The query directly triggered an event."""


    INTENT_FIELD_NUMBER: builtins.int
    EVENT_FIELD_NUMBER: builtins.int
    PARAMETERS_FIELD_NUMBER: builtins.int
    RESOLVED_INPUT_FIELD_NUMBER: builtins.int
    MATCH_TYPE_FIELD_NUMBER: builtins.int
    CONFIDENCE_FIELD_NUMBER: builtins.int
    @property
    def intent(self) -> google.cloud.dialogflow.cx.v3.intent_pb2.Intent:
        """The [Intent][google.cloud.dialogflow.cx.v3.Intent] that matched the query. Some, not all fields are filled in
        this message, including but not limited to: `name` and `display_name`. Only
        filled for [`INTENT`][google.cloud.dialogflow.cx.v3.Match.MatchType] match type.
        """
        pass
    event: typing.Text = ...
    """The event that matched the query. Only filled for
    [`EVENT`][google.cloud.dialogflow.cx.v3.Match.MatchType] match type.
    """

    @property
    def parameters(self) -> google.protobuf.struct_pb2.Struct:
        """The collection of parameters extracted from the query.

        Depending on your protocol or client library language, this is a
        map, associative array, symbol table, dictionary, or JSON object
        composed of a collection of (MapKey, MapValue) pairs:

        -   MapKey type: string
        -   MapKey value: parameter name
        -   MapValue type:
            -   If parameter's entity type is a composite entity: map
            -   Else: depending on parameter value type, could be one of string,
                number, boolean, null, list or map
        -   MapValue value:
            -   If parameter's entity type is a composite entity:
                map from composite entity property names to property values
            -   Else: parameter value
        """
        pass
    resolved_input: typing.Text = ...
    """Final text input which was matched during MatchIntent. This value can be
    different from original input sent in request because of spelling
    correction or other processing.
    """

    match_type: global___Match.MatchType.ValueType = ...
    """Type of this [Match][google.cloud.dialogflow.cx.v3.Match]."""

    confidence: builtins.float = ...
    """The confidence of this match. Values range from 0.0 (completely uncertain)
    to 1.0 (completely certain).
    This value is for informational purpose only and is only used to help match
    the best intent within the classification threshold. This value may change
    for the same end-user expression at any time due to a model retraining or
    change in implementation.
    """

    def __init__(self,
        *,
        intent : typing.Optional[google.cloud.dialogflow.cx.v3.intent_pb2.Intent] = ...,
        event : typing.Text = ...,
        parameters : typing.Optional[google.protobuf.struct_pb2.Struct] = ...,
        resolved_input : typing.Text = ...,
        match_type : global___Match.MatchType.ValueType = ...,
        confidence : builtins.float = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["intent",b"intent","parameters",b"parameters"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["confidence",b"confidence","event",b"event","intent",b"intent","match_type",b"match_type","parameters",b"parameters","resolved_input",b"resolved_input"]) -> None: ...
global___Match = Match

class MatchIntentRequest(google.protobuf.message.Message):
    """Request of [MatchIntent][]."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    SESSION_FIELD_NUMBER: builtins.int
    QUERY_PARAMS_FIELD_NUMBER: builtins.int
    QUERY_INPUT_FIELD_NUMBER: builtins.int
    session: typing.Text = ...
    """Required. The name of the session this query is sent to.
    Format: `projects/<Project ID>/locations/<Location ID>/agents/<Agent
    ID>/sessions/<Session ID>` or `projects/<Project ID>/locations/<Location
    ID>/agents/<Agent ID>/environments/<Environment ID>/sessions/<Session ID>`.
    If `Environment ID` is not specified, we assume default 'draft'
    environment.
    It's up to the API caller to choose an appropriate `Session ID`. It can be
    a random number or some type of session identifiers (preferably hashed).
    The length of the `Session ID` must not exceed 36 characters.

    For more information, see the [sessions
    guide](https://cloud.google.com/dialogflow/cx/docs/concept/session).
    """

    @property
    def query_params(self) -> global___QueryParameters:
        """The parameters of this query."""
        pass
    @property
    def query_input(self) -> global___QueryInput:
        """Required. The input specification."""
        pass
    def __init__(self,
        *,
        session : typing.Text = ...,
        query_params : typing.Optional[global___QueryParameters] = ...,
        query_input : typing.Optional[global___QueryInput] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["query_input",b"query_input","query_params",b"query_params"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["query_input",b"query_input","query_params",b"query_params","session",b"session"]) -> None: ...
global___MatchIntentRequest = MatchIntentRequest

class MatchIntentResponse(google.protobuf.message.Message):
    """Response of [MatchIntent][]."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    TEXT_FIELD_NUMBER: builtins.int
    TRIGGER_INTENT_FIELD_NUMBER: builtins.int
    TRANSCRIPT_FIELD_NUMBER: builtins.int
    TRIGGER_EVENT_FIELD_NUMBER: builtins.int
    MATCHES_FIELD_NUMBER: builtins.int
    CURRENT_PAGE_FIELD_NUMBER: builtins.int
    text: typing.Text = ...
    """If [natural language text][google.cloud.dialogflow.cx.v3.TextInput] was provided as input, this field
    will contain a copy of the text.
    """

    trigger_intent: typing.Text = ...
    """If an [intent][google.cloud.dialogflow.cx.v3.IntentInput] was provided as input, this field will
    contain a copy of the intent identifier.
    Format: `projects/<Project ID>/locations/<Location ID>/agents/<Agent
    ID>/intents/<Intent ID>`.
    """

    transcript: typing.Text = ...
    """If [natural language speech audio][google.cloud.dialogflow.cx.v3.AudioInput] was provided as input,
    this field will contain the transcript for the audio.
    """

    trigger_event: typing.Text = ...
    """If an [event][google.cloud.dialogflow.cx.v3.EventInput] was provided as input, this field will
    contain a copy of the event name.
    """

    @property
    def matches(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Match]:
        """Match results, if more than one, ordered descendingly by the confidence
        we have that the particular intent matches the query.
        """
        pass
    @property
    def current_page(self) -> google.cloud.dialogflow.cx.v3.page_pb2.Page:
        """The current [Page][google.cloud.dialogflow.cx.v3.Page]. Some, not all fields are filled in this message,
        including but not limited to `name` and `display_name`.
        """
        pass
    def __init__(self,
        *,
        text : typing.Text = ...,
        trigger_intent : typing.Text = ...,
        transcript : typing.Text = ...,
        trigger_event : typing.Text = ...,
        matches : typing.Optional[typing.Iterable[global___Match]] = ...,
        current_page : typing.Optional[google.cloud.dialogflow.cx.v3.page_pb2.Page] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["current_page",b"current_page","query",b"query","text",b"text","transcript",b"transcript","trigger_event",b"trigger_event","trigger_intent",b"trigger_intent"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["current_page",b"current_page","matches",b"matches","query",b"query","text",b"text","transcript",b"transcript","trigger_event",b"trigger_event","trigger_intent",b"trigger_intent"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["query",b"query"]) -> typing.Optional[typing_extensions.Literal["text","trigger_intent","transcript","trigger_event"]]: ...
global___MatchIntentResponse = MatchIntentResponse

class FulfillIntentRequest(google.protobuf.message.Message):
    """Request of [FulfillIntent][]"""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    MATCH_INTENT_REQUEST_FIELD_NUMBER: builtins.int
    MATCH_FIELD_NUMBER: builtins.int
    OUTPUT_AUDIO_CONFIG_FIELD_NUMBER: builtins.int
    @property
    def match_intent_request(self) -> global___MatchIntentRequest:
        """Must be same as the corresponding MatchIntent request, otherwise the
        behavior is undefined.
        """
        pass
    @property
    def match(self) -> global___Match:
        """The matched intent/event to fulfill."""
        pass
    @property
    def output_audio_config(self) -> google.cloud.dialogflow.cx.v3.audio_config_pb2.OutputAudioConfig:
        """Instructs the speech synthesizer how to generate output audio."""
        pass
    def __init__(self,
        *,
        match_intent_request : typing.Optional[global___MatchIntentRequest] = ...,
        match : typing.Optional[global___Match] = ...,
        output_audio_config : typing.Optional[google.cloud.dialogflow.cx.v3.audio_config_pb2.OutputAudioConfig] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["match",b"match","match_intent_request",b"match_intent_request","output_audio_config",b"output_audio_config"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["match",b"match","match_intent_request",b"match_intent_request","output_audio_config",b"output_audio_config"]) -> None: ...
global___FulfillIntentRequest = FulfillIntentRequest

class FulfillIntentResponse(google.protobuf.message.Message):
    """Response of [FulfillIntent][]"""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    RESPONSE_ID_FIELD_NUMBER: builtins.int
    QUERY_RESULT_FIELD_NUMBER: builtins.int
    OUTPUT_AUDIO_FIELD_NUMBER: builtins.int
    OUTPUT_AUDIO_CONFIG_FIELD_NUMBER: builtins.int
    response_id: typing.Text = ...
    """Output only. The unique identifier of the response. It can be used to
    locate a response in the training example set or for reporting issues.
    """

    @property
    def query_result(self) -> global___QueryResult:
        """The result of the conversational query."""
        pass
    output_audio: builtins.bytes = ...
    """The audio data bytes encoded as specified in the request.
    Note: The output audio is generated based on the values of default platform
    text responses found in the
    [`query_result.response_messages`][google.cloud.dialogflow.cx.v3.QueryResult.response_messages] field. If
    multiple default text responses exist, they will be concatenated when
    generating audio. If no default platform text responses exist, the
    generated audio content will be empty.

    In some scenarios, multiple output audio fields may be present in the
    response structure. In these cases, only the top-most-level audio output
    has content.
    """

    @property
    def output_audio_config(self) -> google.cloud.dialogflow.cx.v3.audio_config_pb2.OutputAudioConfig:
        """The config used by the speech synthesizer to generate the output audio."""
        pass
    def __init__(self,
        *,
        response_id : typing.Text = ...,
        query_result : typing.Optional[global___QueryResult] = ...,
        output_audio : builtins.bytes = ...,
        output_audio_config : typing.Optional[google.cloud.dialogflow.cx.v3.audio_config_pb2.OutputAudioConfig] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["output_audio_config",b"output_audio_config","query_result",b"query_result"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["output_audio",b"output_audio","output_audio_config",b"output_audio_config","query_result",b"query_result","response_id",b"response_id"]) -> None: ...
global___FulfillIntentResponse = FulfillIntentResponse

class SentimentAnalysisResult(google.protobuf.message.Message):
    """The result of sentiment analysis. Sentiment analysis inspects user input
    and identifies the prevailing subjective opinion, especially to determine a
    user's attitude as positive, negative, or neutral.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    SCORE_FIELD_NUMBER: builtins.int
    MAGNITUDE_FIELD_NUMBER: builtins.int
    score: builtins.float = ...
    """Sentiment score between -1.0 (negative sentiment) and 1.0 (positive
    sentiment).
    """

    magnitude: builtins.float = ...
    """A non-negative number in the [0, +inf) range, which represents the absolute
    magnitude of sentiment, regardless of score (positive or negative).
    """

    def __init__(self,
        *,
        score : builtins.float = ...,
        magnitude : builtins.float = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["magnitude",b"magnitude","score",b"score"]) -> None: ...
global___SentimentAnalysisResult = SentimentAnalysisResult
