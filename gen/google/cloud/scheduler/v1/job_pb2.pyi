"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import google.cloud.scheduler.v1.target_pb2
import google.protobuf.descriptor
import google.protobuf.duration_pb2
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import google.protobuf.timestamp_pb2
import google.rpc.status_pb2
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor = ...

class Job(google.protobuf.message.Message):
    """Configuration for a job.
    The maximum allowed size for a job is 100KB.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class _State:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _StateEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_State.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        STATE_UNSPECIFIED: Job.State.ValueType = ...  # 0
        """Unspecified state."""

        ENABLED: Job.State.ValueType = ...  # 1
        """The job is executing normally."""

        PAUSED: Job.State.ValueType = ...  # 2
        """The job is paused by the user. It will not execute. A user can
        intentionally pause the job using
        [PauseJobRequest][google.cloud.scheduler.v1.PauseJobRequest].
        """

        DISABLED: Job.State.ValueType = ...  # 3
        """The job is disabled by the system due to error. The user
        cannot directly set a job to be disabled.
        """

        UPDATE_FAILED: Job.State.ValueType = ...  # 4
        """The job state resulting from a failed [CloudScheduler.UpdateJob][google.cloud.scheduler.v1.CloudScheduler.UpdateJob]
        operation. To recover a job from this state, retry
        [CloudScheduler.UpdateJob][google.cloud.scheduler.v1.CloudScheduler.UpdateJob] until a successful response is received.
        """

    class State(_State, metaclass=_StateEnumTypeWrapper):
        """State of the job."""
        pass

    STATE_UNSPECIFIED: Job.State.ValueType = ...  # 0
    """Unspecified state."""

    ENABLED: Job.State.ValueType = ...  # 1
    """The job is executing normally."""

    PAUSED: Job.State.ValueType = ...  # 2
    """The job is paused by the user. It will not execute. A user can
    intentionally pause the job using
    [PauseJobRequest][google.cloud.scheduler.v1.PauseJobRequest].
    """

    DISABLED: Job.State.ValueType = ...  # 3
    """The job is disabled by the system due to error. The user
    cannot directly set a job to be disabled.
    """

    UPDATE_FAILED: Job.State.ValueType = ...  # 4
    """The job state resulting from a failed [CloudScheduler.UpdateJob][google.cloud.scheduler.v1.CloudScheduler.UpdateJob]
    operation. To recover a job from this state, retry
    [CloudScheduler.UpdateJob][google.cloud.scheduler.v1.CloudScheduler.UpdateJob] until a successful response is received.
    """


    NAME_FIELD_NUMBER: builtins.int
    DESCRIPTION_FIELD_NUMBER: builtins.int
    PUBSUB_TARGET_FIELD_NUMBER: builtins.int
    APP_ENGINE_HTTP_TARGET_FIELD_NUMBER: builtins.int
    HTTP_TARGET_FIELD_NUMBER: builtins.int
    SCHEDULE_FIELD_NUMBER: builtins.int
    TIME_ZONE_FIELD_NUMBER: builtins.int
    USER_UPDATE_TIME_FIELD_NUMBER: builtins.int
    STATE_FIELD_NUMBER: builtins.int
    STATUS_FIELD_NUMBER: builtins.int
    SCHEDULE_TIME_FIELD_NUMBER: builtins.int
    LAST_ATTEMPT_TIME_FIELD_NUMBER: builtins.int
    RETRY_CONFIG_FIELD_NUMBER: builtins.int
    ATTEMPT_DEADLINE_FIELD_NUMBER: builtins.int
    name: typing.Text = ...
    """Optionally caller-specified in [CreateJob][google.cloud.scheduler.v1.CloudScheduler.CreateJob], after
    which it becomes output only.

    The job name. For example:
    `projects/PROJECT_ID/locations/LOCATION_ID/jobs/JOB_ID`.

    * `PROJECT_ID` can contain letters ([A-Za-z]), numbers ([0-9]),
       hyphens (-), colons (:), or periods (.).
       For more information, see
       [Identifying
       projects](https://cloud.google.com/resource-manager/docs/creating-managing-projects#identifying_projects)
    * `LOCATION_ID` is the canonical ID for the job's location.
       The list of available locations can be obtained by calling
       [ListLocations][google.cloud.location.Locations.ListLocations].
       For more information, see https://cloud.google.com/about/locations/.
    * `JOB_ID` can contain only letters ([A-Za-z]), numbers ([0-9]),
       hyphens (-), or underscores (_). The maximum length is 500 characters.
    """

    description: typing.Text = ...
    """Optionally caller-specified in [CreateJob][google.cloud.scheduler.v1.CloudScheduler.CreateJob] or
    [UpdateJob][google.cloud.scheduler.v1.CloudScheduler.UpdateJob].

    A human-readable description for the job. This string must not contain
    more than 500 characters.
    """

    @property
    def pubsub_target(self) -> google.cloud.scheduler.v1.target_pb2.PubsubTarget:
        """Pub/Sub target."""
        pass
    @property
    def app_engine_http_target(self) -> google.cloud.scheduler.v1.target_pb2.AppEngineHttpTarget:
        """App Engine HTTP target."""
        pass
    @property
    def http_target(self) -> google.cloud.scheduler.v1.target_pb2.HttpTarget:
        """HTTP target."""
        pass
    schedule: typing.Text = ...
    """Required, except when used with [UpdateJob][google.cloud.scheduler.v1.CloudScheduler.UpdateJob].

    Describes the schedule on which the job will be executed.

    The schedule can be either of the following types:

    * [Crontab](http://en.wikipedia.org/wiki/Cron#Overview)
    * English-like
    [schedule](https://cloud.google.com/scheduler/docs/configuring/cron-job-schedules)

    As a general rule, execution `n + 1` of a job will not begin
    until execution `n` has finished. Cloud Scheduler will never
    allow two simultaneously outstanding executions. For example,
    this implies that if the `n+1`th execution is scheduled to run at
    16:00 but the `n`th execution takes until 16:15, the `n+1`th
    execution will not start until `16:15`.
    A scheduled start time will be delayed if the previous
    execution has not ended when its scheduled time occurs.

    If [retry_count][google.cloud.scheduler.v1.RetryConfig.retry_count] > 0 and a job attempt fails,
    the job will be tried a total of [retry_count][google.cloud.scheduler.v1.RetryConfig.retry_count]
    times, with exponential backoff, until the next scheduled start
    time.
    """

    time_zone: typing.Text = ...
    """Specifies the time zone to be used in interpreting
    [schedule][google.cloud.scheduler.v1.Job.schedule]. The value of this field must be a time
    zone name from the [tz database](http://en.wikipedia.org/wiki/Tz_database).

    Note that some time zones include a provision for
    daylight savings time. The rules for daylight saving time are
    determined by the chosen tz. For UTC use the string "utc". If a
    time zone is not specified, the default will be in UTC (also known
    as GMT).
    """

    @property
    def user_update_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Output only. The creation time of the job."""
        pass
    state: global___Job.State.ValueType = ...
    """Output only. State of the job."""

    @property
    def status(self) -> google.rpc.status_pb2.Status:
        """Output only. The response from the target for the last attempted execution."""
        pass
    @property
    def schedule_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Output only. The next time the job is scheduled. Note that this may be a
        retry of a previously failed attempt or the next execution time
        according to the schedule.
        """
        pass
    @property
    def last_attempt_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Output only. The time the last job attempt started."""
        pass
    @property
    def retry_config(self) -> global___RetryConfig:
        """Settings that determine the retry behavior."""
        pass
    @property
    def attempt_deadline(self) -> google.protobuf.duration_pb2.Duration:
        """The deadline for job attempts. If the request handler does not respond by
        this deadline then the request is cancelled and the attempt is marked as a
        `DEADLINE_EXCEEDED` failure. The failed attempt can be viewed in
        execution logs. Cloud Scheduler will retry the job according
        to the [RetryConfig][google.cloud.scheduler.v1.RetryConfig].

        The allowed duration for this deadline is:
        * For [HTTP targets][google.cloud.scheduler.v1.Job.http_target], between 15 seconds and 30 minutes.
        * For [App Engine HTTP targets][google.cloud.scheduler.v1.Job.app_engine_http_target], between 15
          seconds and 24 hours.
        """
        pass
    def __init__(self,
        *,
        name : typing.Text = ...,
        description : typing.Text = ...,
        pubsub_target : typing.Optional[google.cloud.scheduler.v1.target_pb2.PubsubTarget] = ...,
        app_engine_http_target : typing.Optional[google.cloud.scheduler.v1.target_pb2.AppEngineHttpTarget] = ...,
        http_target : typing.Optional[google.cloud.scheduler.v1.target_pb2.HttpTarget] = ...,
        schedule : typing.Text = ...,
        time_zone : typing.Text = ...,
        user_update_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        state : global___Job.State.ValueType = ...,
        status : typing.Optional[google.rpc.status_pb2.Status] = ...,
        schedule_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        last_attempt_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        retry_config : typing.Optional[global___RetryConfig] = ...,
        attempt_deadline : typing.Optional[google.protobuf.duration_pb2.Duration] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["app_engine_http_target",b"app_engine_http_target","attempt_deadline",b"attempt_deadline","http_target",b"http_target","last_attempt_time",b"last_attempt_time","pubsub_target",b"pubsub_target","retry_config",b"retry_config","schedule_time",b"schedule_time","status",b"status","target",b"target","user_update_time",b"user_update_time"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["app_engine_http_target",b"app_engine_http_target","attempt_deadline",b"attempt_deadline","description",b"description","http_target",b"http_target","last_attempt_time",b"last_attempt_time","name",b"name","pubsub_target",b"pubsub_target","retry_config",b"retry_config","schedule",b"schedule","schedule_time",b"schedule_time","state",b"state","status",b"status","target",b"target","time_zone",b"time_zone","user_update_time",b"user_update_time"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["target",b"target"]) -> typing.Optional[typing_extensions.Literal["pubsub_target","app_engine_http_target","http_target"]]: ...
global___Job = Job

class RetryConfig(google.protobuf.message.Message):
    """Settings that determine the retry behavior.

    By default, if a job does not complete successfully (meaning that
    an acknowledgement is not received from the handler, then it will be retried
    with exponential backoff according to the settings in [RetryConfig][google.cloud.scheduler.v1.RetryConfig].
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    RETRY_COUNT_FIELD_NUMBER: builtins.int
    MAX_RETRY_DURATION_FIELD_NUMBER: builtins.int
    MIN_BACKOFF_DURATION_FIELD_NUMBER: builtins.int
    MAX_BACKOFF_DURATION_FIELD_NUMBER: builtins.int
    MAX_DOUBLINGS_FIELD_NUMBER: builtins.int
    retry_count: builtins.int = ...
    """The number of attempts that the system will make to run a job using the
    exponential backoff procedure described by
    [max_doublings][google.cloud.scheduler.v1.RetryConfig.max_doublings].

    The default value of retry_count is zero.

    If retry_count is zero, a job attempt will *not* be retried if
    it fails. Instead the Cloud Scheduler system will wait for the
    next scheduled execution time.

    If retry_count is set to a non-zero number then Cloud Scheduler
    will retry failed attempts, using exponential backoff,
    retry_count times, or until the next scheduled execution time,
    whichever comes first.

    Values greater than 5 and negative values are not allowed.
    """

    @property
    def max_retry_duration(self) -> google.protobuf.duration_pb2.Duration:
        """The time limit for retrying a failed job, measured from time when an
        execution was first attempted. If specified with
        [retry_count][google.cloud.scheduler.v1.RetryConfig.retry_count], the job will be retried until both
        limits are reached.

        The default value for max_retry_duration is zero, which means retry
        duration is unlimited.
        """
        pass
    @property
    def min_backoff_duration(self) -> google.protobuf.duration_pb2.Duration:
        """The minimum amount of time to wait before retrying a job after
        it fails.

        The default value of this field is 5 seconds.
        """
        pass
    @property
    def max_backoff_duration(self) -> google.protobuf.duration_pb2.Duration:
        """The maximum amount of time to wait before retrying a job after
        it fails.

        The default value of this field is 1 hour.
        """
        pass
    max_doublings: builtins.int = ...
    """The time between retries will double `max_doublings` times.

    A job's retry interval starts at
    [min_backoff_duration][google.cloud.scheduler.v1.RetryConfig.min_backoff_duration], then doubles
    `max_doublings` times, then increases linearly, and finally
    retries retries at intervals of
    [max_backoff_duration][google.cloud.scheduler.v1.RetryConfig.max_backoff_duration] up to
    [retry_count][google.cloud.scheduler.v1.RetryConfig.retry_count] times.

    For example, if [min_backoff_duration][google.cloud.scheduler.v1.RetryConfig.min_backoff_duration] is
    10s, [max_backoff_duration][google.cloud.scheduler.v1.RetryConfig.max_backoff_duration] is 300s, and
    `max_doublings` is 3, then the a job will first be retried in 10s. The
    retry interval will double three times, and then increase linearly by
    2^3 * 10s.  Finally, the job will retry at intervals of
    [max_backoff_duration][google.cloud.scheduler.v1.RetryConfig.max_backoff_duration] until the job has
    been attempted [retry_count][google.cloud.scheduler.v1.RetryConfig.retry_count] times. Thus, the
    requests will retry at 10s, 20s, 40s, 80s, 160s, 240s, 300s, 300s, ....

    The default value of this field is 5.
    """

    def __init__(self,
        *,
        retry_count : builtins.int = ...,
        max_retry_duration : typing.Optional[google.protobuf.duration_pb2.Duration] = ...,
        min_backoff_duration : typing.Optional[google.protobuf.duration_pb2.Duration] = ...,
        max_backoff_duration : typing.Optional[google.protobuf.duration_pb2.Duration] = ...,
        max_doublings : builtins.int = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["max_backoff_duration",b"max_backoff_duration","max_retry_duration",b"max_retry_duration","min_backoff_duration",b"min_backoff_duration"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["max_backoff_duration",b"max_backoff_duration","max_doublings",b"max_doublings","max_retry_duration",b"max_retry_duration","min_backoff_duration",b"min_backoff_duration","retry_count",b"retry_count"]) -> None: ...
global___RetryConfig = RetryConfig
