"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import google.cloud.vision.v1p2beta1.geometry_pb2
import google.cloud.vision.v1p2beta1.text_annotation_pb2
import google.cloud.vision.v1p2beta1.web_detection_pb2
import google.protobuf.descriptor
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import google.protobuf.timestamp_pb2
import google.rpc.status_pb2
import google.type.color_pb2
import google.type.latlng_pb2
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor = ...

class _Likelihood:
    ValueType = typing.NewType('ValueType', builtins.int)
    V: typing_extensions.TypeAlias = ValueType
class _LikelihoodEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_Likelihood.ValueType], builtins.type):
    DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
    UNKNOWN: Likelihood.ValueType = ...  # 0
    """Unknown likelihood."""

    VERY_UNLIKELY: Likelihood.ValueType = ...  # 1
    """It is very unlikely that the image belongs to the specified vertical."""

    UNLIKELY: Likelihood.ValueType = ...  # 2
    """It is unlikely that the image belongs to the specified vertical."""

    POSSIBLE: Likelihood.ValueType = ...  # 3
    """It is possible that the image belongs to the specified vertical."""

    LIKELY: Likelihood.ValueType = ...  # 4
    """It is likely that the image belongs to the specified vertical."""

    VERY_LIKELY: Likelihood.ValueType = ...  # 5
    """It is very likely that the image belongs to the specified vertical."""

class Likelihood(_Likelihood, metaclass=_LikelihoodEnumTypeWrapper):
    """A bucketized representation of likelihood, which is intended to give clients
    highly stable results across model upgrades.
    """
    pass

UNKNOWN: Likelihood.ValueType = ...  # 0
"""Unknown likelihood."""

VERY_UNLIKELY: Likelihood.ValueType = ...  # 1
"""It is very unlikely that the image belongs to the specified vertical."""

UNLIKELY: Likelihood.ValueType = ...  # 2
"""It is unlikely that the image belongs to the specified vertical."""

POSSIBLE: Likelihood.ValueType = ...  # 3
"""It is possible that the image belongs to the specified vertical."""

LIKELY: Likelihood.ValueType = ...  # 4
"""It is likely that the image belongs to the specified vertical."""

VERY_LIKELY: Likelihood.ValueType = ...  # 5
"""It is very likely that the image belongs to the specified vertical."""

global___Likelihood = Likelihood


class Feature(google.protobuf.message.Message):
    """The type of Google Cloud Vision API detection to perform, and the maximum
    number of results to return for that type. Multiple `Feature` objects can
    be specified in the `features` list.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class _Type:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _TypeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_Type.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        TYPE_UNSPECIFIED: Feature.Type.ValueType = ...  # 0
        """Unspecified feature type."""

        FACE_DETECTION: Feature.Type.ValueType = ...  # 1
        """Run face detection."""

        LANDMARK_DETECTION: Feature.Type.ValueType = ...  # 2
        """Run landmark detection."""

        LOGO_DETECTION: Feature.Type.ValueType = ...  # 3
        """Run logo detection."""

        LABEL_DETECTION: Feature.Type.ValueType = ...  # 4
        """Run label detection."""

        TEXT_DETECTION: Feature.Type.ValueType = ...  # 5
        """Run text detection / optical character recognition (OCR). Text detection
        is optimized for areas of text within a larger image; if the image is
        a document, use `DOCUMENT_TEXT_DETECTION` instead.
        """

        DOCUMENT_TEXT_DETECTION: Feature.Type.ValueType = ...  # 11
        """Run dense text document OCR. Takes precedence when both
        `DOCUMENT_TEXT_DETECTION` and `TEXT_DETECTION` are present.
        """

        SAFE_SEARCH_DETECTION: Feature.Type.ValueType = ...  # 6
        """Run Safe Search to detect potentially unsafe
        or undesirable content.
        """

        IMAGE_PROPERTIES: Feature.Type.ValueType = ...  # 7
        """Compute a set of image properties, such as the
        image's dominant colors.
        """

        CROP_HINTS: Feature.Type.ValueType = ...  # 9
        """Run crop hints."""

        WEB_DETECTION: Feature.Type.ValueType = ...  # 10
        """Run web detection."""

    class Type(_Type, metaclass=_TypeEnumTypeWrapper):
        """Type of Google Cloud Vision API feature to be extracted."""
        pass

    TYPE_UNSPECIFIED: Feature.Type.ValueType = ...  # 0
    """Unspecified feature type."""

    FACE_DETECTION: Feature.Type.ValueType = ...  # 1
    """Run face detection."""

    LANDMARK_DETECTION: Feature.Type.ValueType = ...  # 2
    """Run landmark detection."""

    LOGO_DETECTION: Feature.Type.ValueType = ...  # 3
    """Run logo detection."""

    LABEL_DETECTION: Feature.Type.ValueType = ...  # 4
    """Run label detection."""

    TEXT_DETECTION: Feature.Type.ValueType = ...  # 5
    """Run text detection / optical character recognition (OCR). Text detection
    is optimized for areas of text within a larger image; if the image is
    a document, use `DOCUMENT_TEXT_DETECTION` instead.
    """

    DOCUMENT_TEXT_DETECTION: Feature.Type.ValueType = ...  # 11
    """Run dense text document OCR. Takes precedence when both
    `DOCUMENT_TEXT_DETECTION` and `TEXT_DETECTION` are present.
    """

    SAFE_SEARCH_DETECTION: Feature.Type.ValueType = ...  # 6
    """Run Safe Search to detect potentially unsafe
    or undesirable content.
    """

    IMAGE_PROPERTIES: Feature.Type.ValueType = ...  # 7
    """Compute a set of image properties, such as the
    image's dominant colors.
    """

    CROP_HINTS: Feature.Type.ValueType = ...  # 9
    """Run crop hints."""

    WEB_DETECTION: Feature.Type.ValueType = ...  # 10
    """Run web detection."""


    TYPE_FIELD_NUMBER: builtins.int
    MAX_RESULTS_FIELD_NUMBER: builtins.int
    MODEL_FIELD_NUMBER: builtins.int
    type: global___Feature.Type.ValueType = ...
    """The feature type."""

    max_results: builtins.int = ...
    """Maximum number of results of this type. Does not apply to
    `TEXT_DETECTION`, `DOCUMENT_TEXT_DETECTION`, or `CROP_HINTS`.
    """

    model: typing.Text = ...
    """Model to use for the feature.
    Supported values: "builtin/stable" (the default if unset) and
    "builtin/latest".
    """

    def __init__(self,
        *,
        type : global___Feature.Type.ValueType = ...,
        max_results : builtins.int = ...,
        model : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["max_results",b"max_results","model",b"model","type",b"type"]) -> None: ...
global___Feature = Feature

class ImageSource(google.protobuf.message.Message):
    """External image source (Google Cloud Storage or web URL image location)."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    GCS_IMAGE_URI_FIELD_NUMBER: builtins.int
    IMAGE_URI_FIELD_NUMBER: builtins.int
    gcs_image_uri: typing.Text = ...
    """**Use `image_uri` instead.**

    The Google Cloud Storage  URI of the form
    `gs://bucket_name/object_name`. Object versioning is not supported. See
    [Google Cloud Storage Request
    URIs](https://cloud.google.com/storage/docs/reference-uris) for more info.
    """

    image_uri: typing.Text = ...
    """The URI of the source image. Can be either:

    1. A Google Cloud Storage URI of the form
       `gs://bucket_name/object_name`. Object versioning is not supported. See
       [Google Cloud Storage Request
       URIs](https://cloud.google.com/storage/docs/reference-uris) for more
       info.

    2. A publicly-accessible image HTTP/HTTPS URL. When fetching images from
       HTTP/HTTPS URLs, Google cannot guarantee that the request will be
       completed. Your request may fail if the specified host denies the
       request (e.g. due to request throttling or DOS prevention), or if Google
       throttles requests to the site for abuse prevention. You should not
       depend on externally-hosted images for production applications.

    When both `gcs_image_uri` and `image_uri` are specified, `image_uri` takes
    precedence.
    """

    def __init__(self,
        *,
        gcs_image_uri : typing.Text = ...,
        image_uri : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["gcs_image_uri",b"gcs_image_uri","image_uri",b"image_uri"]) -> None: ...
global___ImageSource = ImageSource

class Image(google.protobuf.message.Message):
    """Client image to perform Google Cloud Vision API tasks over."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    CONTENT_FIELD_NUMBER: builtins.int
    SOURCE_FIELD_NUMBER: builtins.int
    content: builtins.bytes = ...
    """Image content, represented as a stream of bytes.
    Note: As with all `bytes` fields, protobuffers use a pure binary
    representation, whereas JSON representations use base64.
    """

    @property
    def source(self) -> global___ImageSource:
        """Google Cloud Storage image location, or publicly-accessible image
        URL. If both `content` and `source` are provided for an image, `content`
        takes precedence and is used to perform the image annotation request.
        """
        pass
    def __init__(self,
        *,
        content : builtins.bytes = ...,
        source : typing.Optional[global___ImageSource] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["source",b"source"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["content",b"content","source",b"source"]) -> None: ...
global___Image = Image

class FaceAnnotation(google.protobuf.message.Message):
    """A face annotation object contains the results of face detection."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class Landmark(google.protobuf.message.Message):
        """A face-specific landmark (for example, a face feature)."""
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        class _Type:
            ValueType = typing.NewType('ValueType', builtins.int)
            V: typing_extensions.TypeAlias = ValueType
        class _TypeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_Type.ValueType], builtins.type):
            DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
            UNKNOWN_LANDMARK: FaceAnnotation.Landmark.Type.ValueType = ...  # 0
            """Unknown face landmark detected. Should not be filled."""

            LEFT_EYE: FaceAnnotation.Landmark.Type.ValueType = ...  # 1
            """Left eye."""

            RIGHT_EYE: FaceAnnotation.Landmark.Type.ValueType = ...  # 2
            """Right eye."""

            LEFT_OF_LEFT_EYEBROW: FaceAnnotation.Landmark.Type.ValueType = ...  # 3
            """Left of left eyebrow."""

            RIGHT_OF_LEFT_EYEBROW: FaceAnnotation.Landmark.Type.ValueType = ...  # 4
            """Right of left eyebrow."""

            LEFT_OF_RIGHT_EYEBROW: FaceAnnotation.Landmark.Type.ValueType = ...  # 5
            """Left of right eyebrow."""

            RIGHT_OF_RIGHT_EYEBROW: FaceAnnotation.Landmark.Type.ValueType = ...  # 6
            """Right of right eyebrow."""

            MIDPOINT_BETWEEN_EYES: FaceAnnotation.Landmark.Type.ValueType = ...  # 7
            """Midpoint between eyes."""

            NOSE_TIP: FaceAnnotation.Landmark.Type.ValueType = ...  # 8
            """Nose tip."""

            UPPER_LIP: FaceAnnotation.Landmark.Type.ValueType = ...  # 9
            """Upper lip."""

            LOWER_LIP: FaceAnnotation.Landmark.Type.ValueType = ...  # 10
            """Lower lip."""

            MOUTH_LEFT: FaceAnnotation.Landmark.Type.ValueType = ...  # 11
            """Mouth left."""

            MOUTH_RIGHT: FaceAnnotation.Landmark.Type.ValueType = ...  # 12
            """Mouth right."""

            MOUTH_CENTER: FaceAnnotation.Landmark.Type.ValueType = ...  # 13
            """Mouth center."""

            NOSE_BOTTOM_RIGHT: FaceAnnotation.Landmark.Type.ValueType = ...  # 14
            """Nose, bottom right."""

            NOSE_BOTTOM_LEFT: FaceAnnotation.Landmark.Type.ValueType = ...  # 15
            """Nose, bottom left."""

            NOSE_BOTTOM_CENTER: FaceAnnotation.Landmark.Type.ValueType = ...  # 16
            """Nose, bottom center."""

            LEFT_EYE_TOP_BOUNDARY: FaceAnnotation.Landmark.Type.ValueType = ...  # 17
            """Left eye, top boundary."""

            LEFT_EYE_RIGHT_CORNER: FaceAnnotation.Landmark.Type.ValueType = ...  # 18
            """Left eye, right corner."""

            LEFT_EYE_BOTTOM_BOUNDARY: FaceAnnotation.Landmark.Type.ValueType = ...  # 19
            """Left eye, bottom boundary."""

            LEFT_EYE_LEFT_CORNER: FaceAnnotation.Landmark.Type.ValueType = ...  # 20
            """Left eye, left corner."""

            RIGHT_EYE_TOP_BOUNDARY: FaceAnnotation.Landmark.Type.ValueType = ...  # 21
            """Right eye, top boundary."""

            RIGHT_EYE_RIGHT_CORNER: FaceAnnotation.Landmark.Type.ValueType = ...  # 22
            """Right eye, right corner."""

            RIGHT_EYE_BOTTOM_BOUNDARY: FaceAnnotation.Landmark.Type.ValueType = ...  # 23
            """Right eye, bottom boundary."""

            RIGHT_EYE_LEFT_CORNER: FaceAnnotation.Landmark.Type.ValueType = ...  # 24
            """Right eye, left corner."""

            LEFT_EYEBROW_UPPER_MIDPOINT: FaceAnnotation.Landmark.Type.ValueType = ...  # 25
            """Left eyebrow, upper midpoint."""

            RIGHT_EYEBROW_UPPER_MIDPOINT: FaceAnnotation.Landmark.Type.ValueType = ...  # 26
            """Right eyebrow, upper midpoint."""

            LEFT_EAR_TRAGION: FaceAnnotation.Landmark.Type.ValueType = ...  # 27
            """Left ear tragion."""

            RIGHT_EAR_TRAGION: FaceAnnotation.Landmark.Type.ValueType = ...  # 28
            """Right ear tragion."""

            LEFT_EYE_PUPIL: FaceAnnotation.Landmark.Type.ValueType = ...  # 29
            """Left eye pupil."""

            RIGHT_EYE_PUPIL: FaceAnnotation.Landmark.Type.ValueType = ...  # 30
            """Right eye pupil."""

            FOREHEAD_GLABELLA: FaceAnnotation.Landmark.Type.ValueType = ...  # 31
            """Forehead glabella."""

            CHIN_GNATHION: FaceAnnotation.Landmark.Type.ValueType = ...  # 32
            """Chin gnathion."""

            CHIN_LEFT_GONION: FaceAnnotation.Landmark.Type.ValueType = ...  # 33
            """Chin left gonion."""

            CHIN_RIGHT_GONION: FaceAnnotation.Landmark.Type.ValueType = ...  # 34
            """Chin right gonion."""

        class Type(_Type, metaclass=_TypeEnumTypeWrapper):
            """Face landmark (feature) type.
            Left and right are defined from the vantage of the viewer of the image
            without considering mirror projections typical of photos. So, `LEFT_EYE`,
            typically, is the person's right eye.
            """
            pass

        UNKNOWN_LANDMARK: FaceAnnotation.Landmark.Type.ValueType = ...  # 0
        """Unknown face landmark detected. Should not be filled."""

        LEFT_EYE: FaceAnnotation.Landmark.Type.ValueType = ...  # 1
        """Left eye."""

        RIGHT_EYE: FaceAnnotation.Landmark.Type.ValueType = ...  # 2
        """Right eye."""

        LEFT_OF_LEFT_EYEBROW: FaceAnnotation.Landmark.Type.ValueType = ...  # 3
        """Left of left eyebrow."""

        RIGHT_OF_LEFT_EYEBROW: FaceAnnotation.Landmark.Type.ValueType = ...  # 4
        """Right of left eyebrow."""

        LEFT_OF_RIGHT_EYEBROW: FaceAnnotation.Landmark.Type.ValueType = ...  # 5
        """Left of right eyebrow."""

        RIGHT_OF_RIGHT_EYEBROW: FaceAnnotation.Landmark.Type.ValueType = ...  # 6
        """Right of right eyebrow."""

        MIDPOINT_BETWEEN_EYES: FaceAnnotation.Landmark.Type.ValueType = ...  # 7
        """Midpoint between eyes."""

        NOSE_TIP: FaceAnnotation.Landmark.Type.ValueType = ...  # 8
        """Nose tip."""

        UPPER_LIP: FaceAnnotation.Landmark.Type.ValueType = ...  # 9
        """Upper lip."""

        LOWER_LIP: FaceAnnotation.Landmark.Type.ValueType = ...  # 10
        """Lower lip."""

        MOUTH_LEFT: FaceAnnotation.Landmark.Type.ValueType = ...  # 11
        """Mouth left."""

        MOUTH_RIGHT: FaceAnnotation.Landmark.Type.ValueType = ...  # 12
        """Mouth right."""

        MOUTH_CENTER: FaceAnnotation.Landmark.Type.ValueType = ...  # 13
        """Mouth center."""

        NOSE_BOTTOM_RIGHT: FaceAnnotation.Landmark.Type.ValueType = ...  # 14
        """Nose, bottom right."""

        NOSE_BOTTOM_LEFT: FaceAnnotation.Landmark.Type.ValueType = ...  # 15
        """Nose, bottom left."""

        NOSE_BOTTOM_CENTER: FaceAnnotation.Landmark.Type.ValueType = ...  # 16
        """Nose, bottom center."""

        LEFT_EYE_TOP_BOUNDARY: FaceAnnotation.Landmark.Type.ValueType = ...  # 17
        """Left eye, top boundary."""

        LEFT_EYE_RIGHT_CORNER: FaceAnnotation.Landmark.Type.ValueType = ...  # 18
        """Left eye, right corner."""

        LEFT_EYE_BOTTOM_BOUNDARY: FaceAnnotation.Landmark.Type.ValueType = ...  # 19
        """Left eye, bottom boundary."""

        LEFT_EYE_LEFT_CORNER: FaceAnnotation.Landmark.Type.ValueType = ...  # 20
        """Left eye, left corner."""

        RIGHT_EYE_TOP_BOUNDARY: FaceAnnotation.Landmark.Type.ValueType = ...  # 21
        """Right eye, top boundary."""

        RIGHT_EYE_RIGHT_CORNER: FaceAnnotation.Landmark.Type.ValueType = ...  # 22
        """Right eye, right corner."""

        RIGHT_EYE_BOTTOM_BOUNDARY: FaceAnnotation.Landmark.Type.ValueType = ...  # 23
        """Right eye, bottom boundary."""

        RIGHT_EYE_LEFT_CORNER: FaceAnnotation.Landmark.Type.ValueType = ...  # 24
        """Right eye, left corner."""

        LEFT_EYEBROW_UPPER_MIDPOINT: FaceAnnotation.Landmark.Type.ValueType = ...  # 25
        """Left eyebrow, upper midpoint."""

        RIGHT_EYEBROW_UPPER_MIDPOINT: FaceAnnotation.Landmark.Type.ValueType = ...  # 26
        """Right eyebrow, upper midpoint."""

        LEFT_EAR_TRAGION: FaceAnnotation.Landmark.Type.ValueType = ...  # 27
        """Left ear tragion."""

        RIGHT_EAR_TRAGION: FaceAnnotation.Landmark.Type.ValueType = ...  # 28
        """Right ear tragion."""

        LEFT_EYE_PUPIL: FaceAnnotation.Landmark.Type.ValueType = ...  # 29
        """Left eye pupil."""

        RIGHT_EYE_PUPIL: FaceAnnotation.Landmark.Type.ValueType = ...  # 30
        """Right eye pupil."""

        FOREHEAD_GLABELLA: FaceAnnotation.Landmark.Type.ValueType = ...  # 31
        """Forehead glabella."""

        CHIN_GNATHION: FaceAnnotation.Landmark.Type.ValueType = ...  # 32
        """Chin gnathion."""

        CHIN_LEFT_GONION: FaceAnnotation.Landmark.Type.ValueType = ...  # 33
        """Chin left gonion."""

        CHIN_RIGHT_GONION: FaceAnnotation.Landmark.Type.ValueType = ...  # 34
        """Chin right gonion."""


        TYPE_FIELD_NUMBER: builtins.int
        POSITION_FIELD_NUMBER: builtins.int
        type: global___FaceAnnotation.Landmark.Type.ValueType = ...
        """Face landmark type."""

        @property
        def position(self) -> google.cloud.vision.v1p2beta1.geometry_pb2.Position:
            """Face landmark position."""
            pass
        def __init__(self,
            *,
            type : global___FaceAnnotation.Landmark.Type.ValueType = ...,
            position : typing.Optional[google.cloud.vision.v1p2beta1.geometry_pb2.Position] = ...,
            ) -> None: ...
        def HasField(self, field_name: typing_extensions.Literal["position",b"position"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing_extensions.Literal["position",b"position","type",b"type"]) -> None: ...

    BOUNDING_POLY_FIELD_NUMBER: builtins.int
    FD_BOUNDING_POLY_FIELD_NUMBER: builtins.int
    LANDMARKS_FIELD_NUMBER: builtins.int
    ROLL_ANGLE_FIELD_NUMBER: builtins.int
    PAN_ANGLE_FIELD_NUMBER: builtins.int
    TILT_ANGLE_FIELD_NUMBER: builtins.int
    DETECTION_CONFIDENCE_FIELD_NUMBER: builtins.int
    LANDMARKING_CONFIDENCE_FIELD_NUMBER: builtins.int
    JOY_LIKELIHOOD_FIELD_NUMBER: builtins.int
    SORROW_LIKELIHOOD_FIELD_NUMBER: builtins.int
    ANGER_LIKELIHOOD_FIELD_NUMBER: builtins.int
    SURPRISE_LIKELIHOOD_FIELD_NUMBER: builtins.int
    UNDER_EXPOSED_LIKELIHOOD_FIELD_NUMBER: builtins.int
    BLURRED_LIKELIHOOD_FIELD_NUMBER: builtins.int
    HEADWEAR_LIKELIHOOD_FIELD_NUMBER: builtins.int
    @property
    def bounding_poly(self) -> google.cloud.vision.v1p2beta1.geometry_pb2.BoundingPoly:
        """The bounding polygon around the face. The coordinates of the bounding box
        are in the original image's scale, as returned in `ImageParams`.
        The bounding box is computed to "frame" the face in accordance with human
        expectations. It is based on the landmarker results.
        Note that one or more x and/or y coordinates may not be generated in the
        `BoundingPoly` (the polygon will be unbounded) if only a partial face
        appears in the image to be annotated.
        """
        pass
    @property
    def fd_bounding_poly(self) -> google.cloud.vision.v1p2beta1.geometry_pb2.BoundingPoly:
        """The `fd_bounding_poly` bounding polygon is tighter than the
        `boundingPoly`, and encloses only the skin part of the face. Typically, it
        is used to eliminate the face from any image analysis that detects the
        "amount of skin" visible in an image. It is not based on the
        landmarker results, only on the initial face detection, hence
        the <code>fd</code> (face detection) prefix.
        """
        pass
    @property
    def landmarks(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___FaceAnnotation.Landmark]:
        """Detected face landmarks."""
        pass
    roll_angle: builtins.float = ...
    """Roll angle, which indicates the amount of clockwise/anti-clockwise rotation
    of the face relative to the image vertical about the axis perpendicular to
    the face. Range [-180,180].
    """

    pan_angle: builtins.float = ...
    """Yaw angle, which indicates the leftward/rightward angle that the face is
    pointing relative to the vertical plane perpendicular to the image. Range
    [-180,180].
    """

    tilt_angle: builtins.float = ...
    """Pitch angle, which indicates the upwards/downwards angle that the face is
    pointing relative to the image's horizontal plane. Range [-180,180].
    """

    detection_confidence: builtins.float = ...
    """Detection confidence. Range [0, 1]."""

    landmarking_confidence: builtins.float = ...
    """Face landmarking confidence. Range [0, 1]."""

    joy_likelihood: global___Likelihood.ValueType = ...
    """Joy likelihood."""

    sorrow_likelihood: global___Likelihood.ValueType = ...
    """Sorrow likelihood."""

    anger_likelihood: global___Likelihood.ValueType = ...
    """Anger likelihood."""

    surprise_likelihood: global___Likelihood.ValueType = ...
    """Surprise likelihood."""

    under_exposed_likelihood: global___Likelihood.ValueType = ...
    """Under-exposed likelihood."""

    blurred_likelihood: global___Likelihood.ValueType = ...
    """Blurred likelihood."""

    headwear_likelihood: global___Likelihood.ValueType = ...
    """Headwear likelihood."""

    def __init__(self,
        *,
        bounding_poly : typing.Optional[google.cloud.vision.v1p2beta1.geometry_pb2.BoundingPoly] = ...,
        fd_bounding_poly : typing.Optional[google.cloud.vision.v1p2beta1.geometry_pb2.BoundingPoly] = ...,
        landmarks : typing.Optional[typing.Iterable[global___FaceAnnotation.Landmark]] = ...,
        roll_angle : builtins.float = ...,
        pan_angle : builtins.float = ...,
        tilt_angle : builtins.float = ...,
        detection_confidence : builtins.float = ...,
        landmarking_confidence : builtins.float = ...,
        joy_likelihood : global___Likelihood.ValueType = ...,
        sorrow_likelihood : global___Likelihood.ValueType = ...,
        anger_likelihood : global___Likelihood.ValueType = ...,
        surprise_likelihood : global___Likelihood.ValueType = ...,
        under_exposed_likelihood : global___Likelihood.ValueType = ...,
        blurred_likelihood : global___Likelihood.ValueType = ...,
        headwear_likelihood : global___Likelihood.ValueType = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["bounding_poly",b"bounding_poly","fd_bounding_poly",b"fd_bounding_poly"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["anger_likelihood",b"anger_likelihood","blurred_likelihood",b"blurred_likelihood","bounding_poly",b"bounding_poly","detection_confidence",b"detection_confidence","fd_bounding_poly",b"fd_bounding_poly","headwear_likelihood",b"headwear_likelihood","joy_likelihood",b"joy_likelihood","landmarking_confidence",b"landmarking_confidence","landmarks",b"landmarks","pan_angle",b"pan_angle","roll_angle",b"roll_angle","sorrow_likelihood",b"sorrow_likelihood","surprise_likelihood",b"surprise_likelihood","tilt_angle",b"tilt_angle","under_exposed_likelihood",b"under_exposed_likelihood"]) -> None: ...
global___FaceAnnotation = FaceAnnotation

class LocationInfo(google.protobuf.message.Message):
    """Detected entity location information."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    LAT_LNG_FIELD_NUMBER: builtins.int
    @property
    def lat_lng(self) -> google.type.latlng_pb2.LatLng:
        """lat/long location coordinates."""
        pass
    def __init__(self,
        *,
        lat_lng : typing.Optional[google.type.latlng_pb2.LatLng] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["lat_lng",b"lat_lng"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["lat_lng",b"lat_lng"]) -> None: ...
global___LocationInfo = LocationInfo

class Property(google.protobuf.message.Message):
    """A `Property` consists of a user-supplied name/value pair."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    NAME_FIELD_NUMBER: builtins.int
    VALUE_FIELD_NUMBER: builtins.int
    UINT64_VALUE_FIELD_NUMBER: builtins.int
    name: typing.Text = ...
    """Name of the property."""

    value: typing.Text = ...
    """Value of the property."""

    uint64_value: builtins.int = ...
    """Value of numeric properties."""

    def __init__(self,
        *,
        name : typing.Text = ...,
        value : typing.Text = ...,
        uint64_value : builtins.int = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["name",b"name","uint64_value",b"uint64_value","value",b"value"]) -> None: ...
global___Property = Property

class EntityAnnotation(google.protobuf.message.Message):
    """Set of detected entity features."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    MID_FIELD_NUMBER: builtins.int
    LOCALE_FIELD_NUMBER: builtins.int
    DESCRIPTION_FIELD_NUMBER: builtins.int
    SCORE_FIELD_NUMBER: builtins.int
    CONFIDENCE_FIELD_NUMBER: builtins.int
    TOPICALITY_FIELD_NUMBER: builtins.int
    BOUNDING_POLY_FIELD_NUMBER: builtins.int
    LOCATIONS_FIELD_NUMBER: builtins.int
    PROPERTIES_FIELD_NUMBER: builtins.int
    mid: typing.Text = ...
    """Opaque entity ID. Some IDs may be available in
    [Google Knowledge Graph Search
    API](https://developers.google.com/knowledge-graph/).
    """

    locale: typing.Text = ...
    """The language code for the locale in which the entity textual
    `description` is expressed.
    """

    description: typing.Text = ...
    """Entity textual description, expressed in its `locale` language."""

    score: builtins.float = ...
    """Overall score of the result. Range [0, 1]."""

    confidence: builtins.float = ...
    """**Deprecated. Use `score` instead.**
    The accuracy of the entity detection in an image.
    For example, for an image in which the "Eiffel Tower" entity is detected,
    this field represents the confidence that there is a tower in the query
    image. Range [0, 1].
    """

    topicality: builtins.float = ...
    """The relevancy of the ICA (Image Content Annotation) label to the
    image. For example, the relevancy of "tower" is likely higher to an image
    containing the detected "Eiffel Tower" than to an image containing a
    detected distant towering building, even though the confidence that
    there is a tower in each image may be the same. Range [0, 1].
    """

    @property
    def bounding_poly(self) -> google.cloud.vision.v1p2beta1.geometry_pb2.BoundingPoly:
        """Image region to which this entity belongs. Not produced
        for `LABEL_DETECTION` features.
        """
        pass
    @property
    def locations(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___LocationInfo]:
        """The location information for the detected entity. Multiple
        `LocationInfo` elements can be present because one location may
        indicate the location of the scene in the image, and another location
        may indicate the location of the place where the image was taken.
        Location information is usually present for landmarks.
        """
        pass
    @property
    def properties(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Property]:
        """Some entities may have optional user-supplied `Property` (name/value)
        fields, such a score or string that qualifies the entity.
        """
        pass
    def __init__(self,
        *,
        mid : typing.Text = ...,
        locale : typing.Text = ...,
        description : typing.Text = ...,
        score : builtins.float = ...,
        confidence : builtins.float = ...,
        topicality : builtins.float = ...,
        bounding_poly : typing.Optional[google.cloud.vision.v1p2beta1.geometry_pb2.BoundingPoly] = ...,
        locations : typing.Optional[typing.Iterable[global___LocationInfo]] = ...,
        properties : typing.Optional[typing.Iterable[global___Property]] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["bounding_poly",b"bounding_poly"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["bounding_poly",b"bounding_poly","confidence",b"confidence","description",b"description","locale",b"locale","locations",b"locations","mid",b"mid","properties",b"properties","score",b"score","topicality",b"topicality"]) -> None: ...
global___EntityAnnotation = EntityAnnotation

class SafeSearchAnnotation(google.protobuf.message.Message):
    """Set of features pertaining to the image, computed by computer vision
    methods over safe-search verticals (for example, adult, spoof, medical,
    violence).
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    ADULT_FIELD_NUMBER: builtins.int
    SPOOF_FIELD_NUMBER: builtins.int
    MEDICAL_FIELD_NUMBER: builtins.int
    VIOLENCE_FIELD_NUMBER: builtins.int
    RACY_FIELD_NUMBER: builtins.int
    adult: global___Likelihood.ValueType = ...
    """Represents the adult content likelihood for the image. Adult content may
    contain elements such as nudity, pornographic images or cartoons, or
    sexual activities.
    """

    spoof: global___Likelihood.ValueType = ...
    """Spoof likelihood. The likelihood that an modification
    was made to the image's canonical version to make it appear
    funny or offensive.
    """

    medical: global___Likelihood.ValueType = ...
    """Likelihood that this is a medical image."""

    violence: global___Likelihood.ValueType = ...
    """Likelihood that this image contains violent content."""

    racy: global___Likelihood.ValueType = ...
    """Likelihood that the request image contains racy content. Racy content may
    include (but is not limited to) skimpy or sheer clothing, strategically
    covered nudity, lewd or provocative poses, or close-ups of sensitive
    body areas.
    """

    def __init__(self,
        *,
        adult : global___Likelihood.ValueType = ...,
        spoof : global___Likelihood.ValueType = ...,
        medical : global___Likelihood.ValueType = ...,
        violence : global___Likelihood.ValueType = ...,
        racy : global___Likelihood.ValueType = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["adult",b"adult","medical",b"medical","racy",b"racy","spoof",b"spoof","violence",b"violence"]) -> None: ...
global___SafeSearchAnnotation = SafeSearchAnnotation

class LatLongRect(google.protobuf.message.Message):
    """Rectangle determined by min and max `LatLng` pairs."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    MIN_LAT_LNG_FIELD_NUMBER: builtins.int
    MAX_LAT_LNG_FIELD_NUMBER: builtins.int
    @property
    def min_lat_lng(self) -> google.type.latlng_pb2.LatLng:
        """Min lat/long pair."""
        pass
    @property
    def max_lat_lng(self) -> google.type.latlng_pb2.LatLng:
        """Max lat/long pair."""
        pass
    def __init__(self,
        *,
        min_lat_lng : typing.Optional[google.type.latlng_pb2.LatLng] = ...,
        max_lat_lng : typing.Optional[google.type.latlng_pb2.LatLng] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["max_lat_lng",b"max_lat_lng","min_lat_lng",b"min_lat_lng"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["max_lat_lng",b"max_lat_lng","min_lat_lng",b"min_lat_lng"]) -> None: ...
global___LatLongRect = LatLongRect

class ColorInfo(google.protobuf.message.Message):
    """Color information consists of RGB channels, score, and the fraction of
    the image that the color occupies in the image.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    COLOR_FIELD_NUMBER: builtins.int
    SCORE_FIELD_NUMBER: builtins.int
    PIXEL_FRACTION_FIELD_NUMBER: builtins.int
    @property
    def color(self) -> google.type.color_pb2.Color:
        """RGB components of the color."""
        pass
    score: builtins.float = ...
    """Image-specific score for this color. Value in range [0, 1]."""

    pixel_fraction: builtins.float = ...
    """The fraction of pixels the color occupies in the image.
    Value in range [0, 1].
    """

    def __init__(self,
        *,
        color : typing.Optional[google.type.color_pb2.Color] = ...,
        score : builtins.float = ...,
        pixel_fraction : builtins.float = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["color",b"color"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["color",b"color","pixel_fraction",b"pixel_fraction","score",b"score"]) -> None: ...
global___ColorInfo = ColorInfo

class DominantColorsAnnotation(google.protobuf.message.Message):
    """Set of dominant colors and their corresponding scores."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    COLORS_FIELD_NUMBER: builtins.int
    @property
    def colors(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___ColorInfo]:
        """RGB color values with their score and pixel fraction."""
        pass
    def __init__(self,
        *,
        colors : typing.Optional[typing.Iterable[global___ColorInfo]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["colors",b"colors"]) -> None: ...
global___DominantColorsAnnotation = DominantColorsAnnotation

class ImageProperties(google.protobuf.message.Message):
    """Stores image properties, such as dominant colors."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    DOMINANT_COLORS_FIELD_NUMBER: builtins.int
    @property
    def dominant_colors(self) -> global___DominantColorsAnnotation:
        """If present, dominant colors completed successfully."""
        pass
    def __init__(self,
        *,
        dominant_colors : typing.Optional[global___DominantColorsAnnotation] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["dominant_colors",b"dominant_colors"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["dominant_colors",b"dominant_colors"]) -> None: ...
global___ImageProperties = ImageProperties

class CropHint(google.protobuf.message.Message):
    """Single crop hint that is used to generate a new crop when serving an image."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    BOUNDING_POLY_FIELD_NUMBER: builtins.int
    CONFIDENCE_FIELD_NUMBER: builtins.int
    IMPORTANCE_FRACTION_FIELD_NUMBER: builtins.int
    @property
    def bounding_poly(self) -> google.cloud.vision.v1p2beta1.geometry_pb2.BoundingPoly:
        """The bounding polygon for the crop region. The coordinates of the bounding
        box are in the original image's scale, as returned in `ImageParams`.
        """
        pass
    confidence: builtins.float = ...
    """Confidence of this being a salient region.  Range [0, 1]."""

    importance_fraction: builtins.float = ...
    """Fraction of importance of this salient region with respect to the original
    image.
    """

    def __init__(self,
        *,
        bounding_poly : typing.Optional[google.cloud.vision.v1p2beta1.geometry_pb2.BoundingPoly] = ...,
        confidence : builtins.float = ...,
        importance_fraction : builtins.float = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["bounding_poly",b"bounding_poly"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["bounding_poly",b"bounding_poly","confidence",b"confidence","importance_fraction",b"importance_fraction"]) -> None: ...
global___CropHint = CropHint

class CropHintsAnnotation(google.protobuf.message.Message):
    """Set of crop hints that are used to generate new crops when serving images."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    CROP_HINTS_FIELD_NUMBER: builtins.int
    @property
    def crop_hints(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___CropHint]:
        """Crop hint results."""
        pass
    def __init__(self,
        *,
        crop_hints : typing.Optional[typing.Iterable[global___CropHint]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["crop_hints",b"crop_hints"]) -> None: ...
global___CropHintsAnnotation = CropHintsAnnotation

class CropHintsParams(google.protobuf.message.Message):
    """Parameters for crop hints annotation request."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    ASPECT_RATIOS_FIELD_NUMBER: builtins.int
    @property
    def aspect_ratios(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[builtins.float]:
        """Aspect ratios in floats, representing the ratio of the width to the height
        of the image. For example, if the desired aspect ratio is 4/3, the
        corresponding float value should be 1.33333.  If not specified, the
        best possible crop is returned. The number of provided aspect ratios is
        limited to a maximum of 16; any aspect ratios provided after the 16th are
        ignored.
        """
        pass
    def __init__(self,
        *,
        aspect_ratios : typing.Optional[typing.Iterable[builtins.float]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["aspect_ratios",b"aspect_ratios"]) -> None: ...
global___CropHintsParams = CropHintsParams

class WebDetectionParams(google.protobuf.message.Message):
    """Parameters for web detection request."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    INCLUDE_GEO_RESULTS_FIELD_NUMBER: builtins.int
    include_geo_results: builtins.bool = ...
    """Whether to include results derived from the geo information in the image."""

    def __init__(self,
        *,
        include_geo_results : builtins.bool = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["include_geo_results",b"include_geo_results"]) -> None: ...
global___WebDetectionParams = WebDetectionParams

class TextDetectionParams(google.protobuf.message.Message):
    """Parameters for text detections. This is used to control TEXT_DETECTION and
    DOCUMENT_TEXT_DETECTION features.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    ENABLE_TEXT_DETECTION_CONFIDENCE_SCORE_FIELD_NUMBER: builtins.int
    enable_text_detection_confidence_score: builtins.bool = ...
    """By default, Cloud Vision API only includes confidence score for
    DOCUMENT_TEXT_DETECTION result. Set the flag to true to include confidence
    score for TEXT_DETECTION as well.
    """

    def __init__(self,
        *,
        enable_text_detection_confidence_score : builtins.bool = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["enable_text_detection_confidence_score",b"enable_text_detection_confidence_score"]) -> None: ...
global___TextDetectionParams = TextDetectionParams

class ImageContext(google.protobuf.message.Message):
    """Image context and/or feature-specific parameters."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    LAT_LONG_RECT_FIELD_NUMBER: builtins.int
    LANGUAGE_HINTS_FIELD_NUMBER: builtins.int
    CROP_HINTS_PARAMS_FIELD_NUMBER: builtins.int
    WEB_DETECTION_PARAMS_FIELD_NUMBER: builtins.int
    TEXT_DETECTION_PARAMS_FIELD_NUMBER: builtins.int
    @property
    def lat_long_rect(self) -> global___LatLongRect:
        """Not used."""
        pass
    @property
    def language_hints(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
        """List of languages to use for TEXT_DETECTION. In most cases, an empty value
        yields the best results since it enables automatic language detection. For
        languages based on the Latin alphabet, setting `language_hints` is not
        needed. In rare cases, when the language of the text in the image is known,
        setting a hint will help get better results (although it will be a
        significant hindrance if the hint is wrong). Text detection returns an
        error if one or more of the specified languages is not one of the
        [supported languages](https://cloud.google.com/vision/docs/languages).
        """
        pass
    @property
    def crop_hints_params(self) -> global___CropHintsParams:
        """Parameters for crop hints annotation request."""
        pass
    @property
    def web_detection_params(self) -> global___WebDetectionParams:
        """Parameters for web detection."""
        pass
    @property
    def text_detection_params(self) -> global___TextDetectionParams:
        """Parameters for text detection and document text detection."""
        pass
    def __init__(self,
        *,
        lat_long_rect : typing.Optional[global___LatLongRect] = ...,
        language_hints : typing.Optional[typing.Iterable[typing.Text]] = ...,
        crop_hints_params : typing.Optional[global___CropHintsParams] = ...,
        web_detection_params : typing.Optional[global___WebDetectionParams] = ...,
        text_detection_params : typing.Optional[global___TextDetectionParams] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["crop_hints_params",b"crop_hints_params","lat_long_rect",b"lat_long_rect","text_detection_params",b"text_detection_params","web_detection_params",b"web_detection_params"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["crop_hints_params",b"crop_hints_params","language_hints",b"language_hints","lat_long_rect",b"lat_long_rect","text_detection_params",b"text_detection_params","web_detection_params",b"web_detection_params"]) -> None: ...
global___ImageContext = ImageContext

class AnnotateImageRequest(google.protobuf.message.Message):
    """Request for performing Google Cloud Vision API tasks over a user-provided
    image, with user-requested features.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    IMAGE_FIELD_NUMBER: builtins.int
    FEATURES_FIELD_NUMBER: builtins.int
    IMAGE_CONTEXT_FIELD_NUMBER: builtins.int
    @property
    def image(self) -> global___Image:
        """The image to be processed."""
        pass
    @property
    def features(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Feature]:
        """Requested features."""
        pass
    @property
    def image_context(self) -> global___ImageContext:
        """Additional context that may accompany the image."""
        pass
    def __init__(self,
        *,
        image : typing.Optional[global___Image] = ...,
        features : typing.Optional[typing.Iterable[global___Feature]] = ...,
        image_context : typing.Optional[global___ImageContext] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["image",b"image","image_context",b"image_context"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["features",b"features","image",b"image","image_context",b"image_context"]) -> None: ...
global___AnnotateImageRequest = AnnotateImageRequest

class ImageAnnotationContext(google.protobuf.message.Message):
    """If an image was produced from a file (e.g. a PDF), this message gives
    information about the source of that image.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    URI_FIELD_NUMBER: builtins.int
    PAGE_NUMBER_FIELD_NUMBER: builtins.int
    uri: typing.Text = ...
    """The URI of the file used to produce the image."""

    page_number: builtins.int = ...
    """If the file was a PDF or TIFF, this field gives the page number within
    the file used to produce the image.
    """

    def __init__(self,
        *,
        uri : typing.Text = ...,
        page_number : builtins.int = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["page_number",b"page_number","uri",b"uri"]) -> None: ...
global___ImageAnnotationContext = ImageAnnotationContext

class AnnotateImageResponse(google.protobuf.message.Message):
    """Response to an image annotation request."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    FACE_ANNOTATIONS_FIELD_NUMBER: builtins.int
    LANDMARK_ANNOTATIONS_FIELD_NUMBER: builtins.int
    LOGO_ANNOTATIONS_FIELD_NUMBER: builtins.int
    LABEL_ANNOTATIONS_FIELD_NUMBER: builtins.int
    TEXT_ANNOTATIONS_FIELD_NUMBER: builtins.int
    FULL_TEXT_ANNOTATION_FIELD_NUMBER: builtins.int
    SAFE_SEARCH_ANNOTATION_FIELD_NUMBER: builtins.int
    IMAGE_PROPERTIES_ANNOTATION_FIELD_NUMBER: builtins.int
    CROP_HINTS_ANNOTATION_FIELD_NUMBER: builtins.int
    WEB_DETECTION_FIELD_NUMBER: builtins.int
    ERROR_FIELD_NUMBER: builtins.int
    CONTEXT_FIELD_NUMBER: builtins.int
    @property
    def face_annotations(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___FaceAnnotation]:
        """If present, face detection has completed successfully."""
        pass
    @property
    def landmark_annotations(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___EntityAnnotation]:
        """If present, landmark detection has completed successfully."""
        pass
    @property
    def logo_annotations(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___EntityAnnotation]:
        """If present, logo detection has completed successfully."""
        pass
    @property
    def label_annotations(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___EntityAnnotation]:
        """If present, label detection has completed successfully."""
        pass
    @property
    def text_annotations(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___EntityAnnotation]:
        """If present, text (OCR) detection has completed successfully."""
        pass
    @property
    def full_text_annotation(self) -> google.cloud.vision.v1p2beta1.text_annotation_pb2.TextAnnotation:
        """If present, text (OCR) detection or document (OCR) text detection has
        completed successfully.
        This annotation provides the structural hierarchy for the OCR detected
        text.
        """
        pass
    @property
    def safe_search_annotation(self) -> global___SafeSearchAnnotation:
        """If present, safe-search annotation has completed successfully."""
        pass
    @property
    def image_properties_annotation(self) -> global___ImageProperties:
        """If present, image properties were extracted successfully."""
        pass
    @property
    def crop_hints_annotation(self) -> global___CropHintsAnnotation:
        """If present, crop hints have completed successfully."""
        pass
    @property
    def web_detection(self) -> google.cloud.vision.v1p2beta1.web_detection_pb2.WebDetection:
        """If present, web detection has completed successfully."""
        pass
    @property
    def error(self) -> google.rpc.status_pb2.Status:
        """If set, represents the error message for the operation.
        Note that filled-in image annotations are guaranteed to be
        correct, even when `error` is set.
        """
        pass
    @property
    def context(self) -> global___ImageAnnotationContext:
        """If present, contextual information is needed to understand where this image
        comes from.
        """
        pass
    def __init__(self,
        *,
        face_annotations : typing.Optional[typing.Iterable[global___FaceAnnotation]] = ...,
        landmark_annotations : typing.Optional[typing.Iterable[global___EntityAnnotation]] = ...,
        logo_annotations : typing.Optional[typing.Iterable[global___EntityAnnotation]] = ...,
        label_annotations : typing.Optional[typing.Iterable[global___EntityAnnotation]] = ...,
        text_annotations : typing.Optional[typing.Iterable[global___EntityAnnotation]] = ...,
        full_text_annotation : typing.Optional[google.cloud.vision.v1p2beta1.text_annotation_pb2.TextAnnotation] = ...,
        safe_search_annotation : typing.Optional[global___SafeSearchAnnotation] = ...,
        image_properties_annotation : typing.Optional[global___ImageProperties] = ...,
        crop_hints_annotation : typing.Optional[global___CropHintsAnnotation] = ...,
        web_detection : typing.Optional[google.cloud.vision.v1p2beta1.web_detection_pb2.WebDetection] = ...,
        error : typing.Optional[google.rpc.status_pb2.Status] = ...,
        context : typing.Optional[global___ImageAnnotationContext] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["context",b"context","crop_hints_annotation",b"crop_hints_annotation","error",b"error","full_text_annotation",b"full_text_annotation","image_properties_annotation",b"image_properties_annotation","safe_search_annotation",b"safe_search_annotation","web_detection",b"web_detection"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["context",b"context","crop_hints_annotation",b"crop_hints_annotation","error",b"error","face_annotations",b"face_annotations","full_text_annotation",b"full_text_annotation","image_properties_annotation",b"image_properties_annotation","label_annotations",b"label_annotations","landmark_annotations",b"landmark_annotations","logo_annotations",b"logo_annotations","safe_search_annotation",b"safe_search_annotation","text_annotations",b"text_annotations","web_detection",b"web_detection"]) -> None: ...
global___AnnotateImageResponse = AnnotateImageResponse

class AnnotateFileResponse(google.protobuf.message.Message):
    """Response to a single file annotation request. A file may contain one or more
    images, which individually have their own responses.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    INPUT_CONFIG_FIELD_NUMBER: builtins.int
    RESPONSES_FIELD_NUMBER: builtins.int
    @property
    def input_config(self) -> global___InputConfig:
        """Information about the file for which this response is generated."""
        pass
    @property
    def responses(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___AnnotateImageResponse]:
        """Individual responses to images found within the file."""
        pass
    def __init__(self,
        *,
        input_config : typing.Optional[global___InputConfig] = ...,
        responses : typing.Optional[typing.Iterable[global___AnnotateImageResponse]] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["input_config",b"input_config"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["input_config",b"input_config","responses",b"responses"]) -> None: ...
global___AnnotateFileResponse = AnnotateFileResponse

class BatchAnnotateImagesRequest(google.protobuf.message.Message):
    """Multiple image annotation requests are batched into a single service call."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    REQUESTS_FIELD_NUMBER: builtins.int
    @property
    def requests(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___AnnotateImageRequest]:
        """Required. Individual image annotation requests for this batch."""
        pass
    def __init__(self,
        *,
        requests : typing.Optional[typing.Iterable[global___AnnotateImageRequest]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["requests",b"requests"]) -> None: ...
global___BatchAnnotateImagesRequest = BatchAnnotateImagesRequest

class BatchAnnotateImagesResponse(google.protobuf.message.Message):
    """Response to a batch image annotation request."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    RESPONSES_FIELD_NUMBER: builtins.int
    @property
    def responses(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___AnnotateImageResponse]:
        """Individual responses to image annotation requests within the batch."""
        pass
    def __init__(self,
        *,
        responses : typing.Optional[typing.Iterable[global___AnnotateImageResponse]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["responses",b"responses"]) -> None: ...
global___BatchAnnotateImagesResponse = BatchAnnotateImagesResponse

class AsyncAnnotateFileRequest(google.protobuf.message.Message):
    """An offline file annotation request."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    INPUT_CONFIG_FIELD_NUMBER: builtins.int
    FEATURES_FIELD_NUMBER: builtins.int
    IMAGE_CONTEXT_FIELD_NUMBER: builtins.int
    OUTPUT_CONFIG_FIELD_NUMBER: builtins.int
    @property
    def input_config(self) -> global___InputConfig:
        """Required. Information about the input file."""
        pass
    @property
    def features(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___Feature]:
        """Required. Requested features."""
        pass
    @property
    def image_context(self) -> global___ImageContext:
        """Additional context that may accompany the image(s) in the file."""
        pass
    @property
    def output_config(self) -> global___OutputConfig:
        """Required. The desired output location and metadata (e.g. format)."""
        pass
    def __init__(self,
        *,
        input_config : typing.Optional[global___InputConfig] = ...,
        features : typing.Optional[typing.Iterable[global___Feature]] = ...,
        image_context : typing.Optional[global___ImageContext] = ...,
        output_config : typing.Optional[global___OutputConfig] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["image_context",b"image_context","input_config",b"input_config","output_config",b"output_config"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["features",b"features","image_context",b"image_context","input_config",b"input_config","output_config",b"output_config"]) -> None: ...
global___AsyncAnnotateFileRequest = AsyncAnnotateFileRequest

class AsyncAnnotateFileResponse(google.protobuf.message.Message):
    """The response for a single offline file annotation request."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    OUTPUT_CONFIG_FIELD_NUMBER: builtins.int
    @property
    def output_config(self) -> global___OutputConfig:
        """The output location and metadata from AsyncAnnotateFileRequest."""
        pass
    def __init__(self,
        *,
        output_config : typing.Optional[global___OutputConfig] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["output_config",b"output_config"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["output_config",b"output_config"]) -> None: ...
global___AsyncAnnotateFileResponse = AsyncAnnotateFileResponse

class AsyncBatchAnnotateFilesRequest(google.protobuf.message.Message):
    """Multiple async file annotation requests are batched into a single service
    call.
    """
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    REQUESTS_FIELD_NUMBER: builtins.int
    @property
    def requests(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___AsyncAnnotateFileRequest]:
        """Required. Individual async file annotation requests for this batch."""
        pass
    def __init__(self,
        *,
        requests : typing.Optional[typing.Iterable[global___AsyncAnnotateFileRequest]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["requests",b"requests"]) -> None: ...
global___AsyncBatchAnnotateFilesRequest = AsyncBatchAnnotateFilesRequest

class AsyncBatchAnnotateFilesResponse(google.protobuf.message.Message):
    """Response to an async batch file annotation request."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    RESPONSES_FIELD_NUMBER: builtins.int
    @property
    def responses(self) -> google.protobuf.internal.containers.RepeatedCompositeFieldContainer[global___AsyncAnnotateFileResponse]:
        """The list of file annotation responses, one for each request in
        AsyncBatchAnnotateFilesRequest.
        """
        pass
    def __init__(self,
        *,
        responses : typing.Optional[typing.Iterable[global___AsyncAnnotateFileResponse]] = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["responses",b"responses"]) -> None: ...
global___AsyncBatchAnnotateFilesResponse = AsyncBatchAnnotateFilesResponse

class InputConfig(google.protobuf.message.Message):
    """The desired input location and metadata."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    GCS_SOURCE_FIELD_NUMBER: builtins.int
    MIME_TYPE_FIELD_NUMBER: builtins.int
    @property
    def gcs_source(self) -> global___GcsSource:
        """The Google Cloud Storage location to read the input from."""
        pass
    mime_type: typing.Text = ...
    """The type of the file. Currently only "application/pdf" and "image/tiff"
    are supported. Wildcards are not supported.
    """

    def __init__(self,
        *,
        gcs_source : typing.Optional[global___GcsSource] = ...,
        mime_type : typing.Text = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["gcs_source",b"gcs_source"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["gcs_source",b"gcs_source","mime_type",b"mime_type"]) -> None: ...
global___InputConfig = InputConfig

class OutputConfig(google.protobuf.message.Message):
    """The desired output location and metadata."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    GCS_DESTINATION_FIELD_NUMBER: builtins.int
    BATCH_SIZE_FIELD_NUMBER: builtins.int
    @property
    def gcs_destination(self) -> global___GcsDestination:
        """The Google Cloud Storage location to write the output(s) to."""
        pass
    batch_size: builtins.int = ...
    """The max number of response protos to put into each output JSON file on GCS.
    The valid range is [1, 100]. If not specified, the default value is 20.

    For example, for one pdf file with 100 pages, 100 response protos will
    be generated. If `batch_size` = 20, then 5 json files each
    containing 20 response protos will be written under the prefix
    `gcs_destination`.`uri`.

    Currently, batch_size only applies to GcsDestination, with potential future
    support for other output configurations.
    """

    def __init__(self,
        *,
        gcs_destination : typing.Optional[global___GcsDestination] = ...,
        batch_size : builtins.int = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["gcs_destination",b"gcs_destination"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["batch_size",b"batch_size","gcs_destination",b"gcs_destination"]) -> None: ...
global___OutputConfig = OutputConfig

class GcsSource(google.protobuf.message.Message):
    """The Google Cloud Storage location where the input will be read from."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    URI_FIELD_NUMBER: builtins.int
    uri: typing.Text = ...
    """Google Cloud Storage URI for the input file. This must only be a GCS
    object. Wildcards are not currently supported.
    """

    def __init__(self,
        *,
        uri : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["uri",b"uri"]) -> None: ...
global___GcsSource = GcsSource

class GcsDestination(google.protobuf.message.Message):
    """The Google Cloud Storage location where the output will be written to."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    URI_FIELD_NUMBER: builtins.int
    uri: typing.Text = ...
    """Google Cloud Storage URI where the results will be stored. Results will
    be in JSON format and preceded by its corresponding input URI. This field
    can either represent a single file, or a prefix for multiple outputs.
    Prefixes must end in a `/`.

    Examples:

    *    File: gs://bucket-name/filename.json
    *    Prefix: gs://bucket-name/prefix/here/
    *    File: gs://bucket-name/prefix/here

    If multiple outputs, each response is still AnnotateFileResponse, each of
    which contains some subset of the full list of AnnotateImageResponse.
    Multiple outputs can happen if, for example, the output JSON is too large
    and overflows into multiple sharded files.
    """

    def __init__(self,
        *,
        uri : typing.Text = ...,
        ) -> None: ...
    def ClearField(self, field_name: typing_extensions.Literal["uri",b"uri"]) -> None: ...
global___GcsDestination = GcsDestination

class OperationMetadata(google.protobuf.message.Message):
    """Contains metadata for the BatchAnnotateImages operation."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class _State:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _StateEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_State.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        STATE_UNSPECIFIED: OperationMetadata.State.ValueType = ...  # 0
        """Invalid."""

        CREATED: OperationMetadata.State.ValueType = ...  # 1
        """Request is received."""

        RUNNING: OperationMetadata.State.ValueType = ...  # 2
        """Request is actively being processed."""

        DONE: OperationMetadata.State.ValueType = ...  # 3
        """The batch processing is done."""

        CANCELLED: OperationMetadata.State.ValueType = ...  # 4
        """The batch processing was cancelled."""

    class State(_State, metaclass=_StateEnumTypeWrapper):
        """Batch operation states."""
        pass

    STATE_UNSPECIFIED: OperationMetadata.State.ValueType = ...  # 0
    """Invalid."""

    CREATED: OperationMetadata.State.ValueType = ...  # 1
    """Request is received."""

    RUNNING: OperationMetadata.State.ValueType = ...  # 2
    """Request is actively being processed."""

    DONE: OperationMetadata.State.ValueType = ...  # 3
    """The batch processing is done."""

    CANCELLED: OperationMetadata.State.ValueType = ...  # 4
    """The batch processing was cancelled."""


    STATE_FIELD_NUMBER: builtins.int
    CREATE_TIME_FIELD_NUMBER: builtins.int
    UPDATE_TIME_FIELD_NUMBER: builtins.int
    state: global___OperationMetadata.State.ValueType = ...
    """Current state of the batch operation."""

    @property
    def create_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """The time when the batch request was received."""
        pass
    @property
    def update_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """The time when the operation result was last updated."""
        pass
    def __init__(self,
        *,
        state : global___OperationMetadata.State.ValueType = ...,
        create_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        update_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["create_time",b"create_time","update_time",b"update_time"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["create_time",b"create_time","state",b"state","update_time",b"update_time"]) -> None: ...
global___OperationMetadata = OperationMetadata
