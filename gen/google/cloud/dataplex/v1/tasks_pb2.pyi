"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
"""
import builtins
import google.cloud.dataplex.v1.resources_pb2
import google.protobuf.descriptor
import google.protobuf.duration_pb2
import google.protobuf.internal.containers
import google.protobuf.internal.enum_type_wrapper
import google.protobuf.message
import google.protobuf.timestamp_pb2
import typing
import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor = ...

class Task(google.protobuf.message.Message):
    """A task represents a user-visible job."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class InfrastructureSpec(google.protobuf.message.Message):
        """Configuration for the underlying infrastructure used to run workloads."""
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        class BatchComputeResources(google.protobuf.message.Message):
            """Batch compute resources associated with the task."""
            DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
            EXECUTORS_COUNT_FIELD_NUMBER: builtins.int
            MAX_EXECUTORS_COUNT_FIELD_NUMBER: builtins.int
            executors_count: builtins.int = ...
            """Optional. Total number of job executors."""

            max_executors_count: builtins.int = ...
            """Optional. Max configurable executors.
            If max_executors_count > executors_count, then auto-scaling is enabled.
            """

            def __init__(self,
                *,
                executors_count : builtins.int = ...,
                max_executors_count : builtins.int = ...,
                ) -> None: ...
            def ClearField(self, field_name: typing_extensions.Literal["executors_count",b"executors_count","max_executors_count",b"max_executors_count"]) -> None: ...

        class ContainerImageRuntime(google.protobuf.message.Message):
            """Container Image Runtime Configuration used with Batch execution."""
            DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
            class PropertiesEntry(google.protobuf.message.Message):
                DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
                KEY_FIELD_NUMBER: builtins.int
                VALUE_FIELD_NUMBER: builtins.int
                key: typing.Text = ...
                value: typing.Text = ...
                def __init__(self,
                    *,
                    key : typing.Text = ...,
                    value : typing.Text = ...,
                    ) -> None: ...
                def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

            JAVA_JARS_FIELD_NUMBER: builtins.int
            PYTHON_PACKAGES_FIELD_NUMBER: builtins.int
            PROPERTIES_FIELD_NUMBER: builtins.int
            @property
            def java_jars(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
                """Optional. A list of Java JARS to add to the classpath.
                Valid input includes Cloud Storage URIs to Jar binaries.
                For example, `gs://bucket-name/my/path/to/file.jar`.
                """
                pass
            @property
            def python_packages(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
                """Optional. A list of python packages to be installed.
                Valid formats include Cloud Storage URI to a PIP installable library.
                For example, `gs://bucket-name/my/path/to/lib.tar.gz`.
                """
                pass
            @property
            def properties(self) -> google.protobuf.internal.containers.ScalarMap[typing.Text, typing.Text]:
                """Optional. Override to common configuration of open source components installed on
                the Dataproc cluster.
                The properties to set on daemon config files.
                Property keys are specified in `prefix:property` format, for example
                `core:hadoop.tmp.dir`.
                For more information, see [Cluster
                properties](https://cloud.google.com/dataproc/docs/concepts/cluster-properties).
                """
                pass
            def __init__(self,
                *,
                java_jars : typing.Optional[typing.Iterable[typing.Text]] = ...,
                python_packages : typing.Optional[typing.Iterable[typing.Text]] = ...,
                properties : typing.Optional[typing.Mapping[typing.Text, typing.Text]] = ...,
                ) -> None: ...
            def ClearField(self, field_name: typing_extensions.Literal["java_jars",b"java_jars","properties",b"properties","python_packages",b"python_packages"]) -> None: ...

        class VpcNetwork(google.protobuf.message.Message):
            """Cloud VPC Network used to run the infrastructure."""
            DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
            NETWORK_FIELD_NUMBER: builtins.int
            SUB_NETWORK_FIELD_NUMBER: builtins.int
            NETWORK_TAGS_FIELD_NUMBER: builtins.int
            network: typing.Text = ...
            """Optional. The Cloud VPC network in which the job is run. By default, the Cloud
            VPC network named Default within the project is used.
            """

            sub_network: typing.Text = ...
            """Optional. The Cloud VPC sub-network in which the job is run."""

            @property
            def network_tags(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
                """Optional. List of network tags to apply to the job."""
                pass
            def __init__(self,
                *,
                network : typing.Text = ...,
                sub_network : typing.Text = ...,
                network_tags : typing.Optional[typing.Iterable[typing.Text]] = ...,
                ) -> None: ...
            def HasField(self, field_name: typing_extensions.Literal["network",b"network","network_name",b"network_name","sub_network",b"sub_network"]) -> builtins.bool: ...
            def ClearField(self, field_name: typing_extensions.Literal["network",b"network","network_name",b"network_name","network_tags",b"network_tags","sub_network",b"sub_network"]) -> None: ...
            def WhichOneof(self, oneof_group: typing_extensions.Literal["network_name",b"network_name"]) -> typing.Optional[typing_extensions.Literal["network","sub_network"]]: ...

        BATCH_FIELD_NUMBER: builtins.int
        CONTAINER_IMAGE_FIELD_NUMBER: builtins.int
        VPC_NETWORK_FIELD_NUMBER: builtins.int
        @property
        def batch(self) -> global___Task.InfrastructureSpec.BatchComputeResources:
            """Compute resources needed for a Task when using Dataproc Serverless."""
            pass
        @property
        def container_image(self) -> global___Task.InfrastructureSpec.ContainerImageRuntime:
            """Container Image Runtime Configuration."""
            pass
        @property
        def vpc_network(self) -> global___Task.InfrastructureSpec.VpcNetwork:
            """Vpc network."""
            pass
        def __init__(self,
            *,
            batch : typing.Optional[global___Task.InfrastructureSpec.BatchComputeResources] = ...,
            container_image : typing.Optional[global___Task.InfrastructureSpec.ContainerImageRuntime] = ...,
            vpc_network : typing.Optional[global___Task.InfrastructureSpec.VpcNetwork] = ...,
            ) -> None: ...
        def HasField(self, field_name: typing_extensions.Literal["batch",b"batch","container_image",b"container_image","network",b"network","resources",b"resources","runtime",b"runtime","vpc_network",b"vpc_network"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing_extensions.Literal["batch",b"batch","container_image",b"container_image","network",b"network","resources",b"resources","runtime",b"runtime","vpc_network",b"vpc_network"]) -> None: ...
        @typing.overload
        def WhichOneof(self, oneof_group: typing_extensions.Literal["network",b"network"]) -> typing.Optional[typing_extensions.Literal["vpc_network"]]: ...
        @typing.overload
        def WhichOneof(self, oneof_group: typing_extensions.Literal["resources",b"resources"]) -> typing.Optional[typing_extensions.Literal["batch"]]: ...
        @typing.overload
        def WhichOneof(self, oneof_group: typing_extensions.Literal["runtime",b"runtime"]) -> typing.Optional[typing_extensions.Literal["container_image"]]: ...

    class TriggerSpec(google.protobuf.message.Message):
        """Task scheduling and trigger settings."""
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        class _Type:
            ValueType = typing.NewType('ValueType', builtins.int)
            V: typing_extensions.TypeAlias = ValueType
        class _TypeEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_Type.ValueType], builtins.type):
            DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
            TYPE_UNSPECIFIED: Task.TriggerSpec.Type.ValueType = ...  # 0
            """Unspecified trigger type."""

            ON_DEMAND: Task.TriggerSpec.Type.ValueType = ...  # 1
            """The task runs one-time shortly after Task Creation."""

            RECURRING: Task.TriggerSpec.Type.ValueType = ...  # 2
            """The task is scheduled to run periodically."""

        class Type(_Type, metaclass=_TypeEnumTypeWrapper):
            """Determines how often and when the job will run."""
            pass

        TYPE_UNSPECIFIED: Task.TriggerSpec.Type.ValueType = ...  # 0
        """Unspecified trigger type."""

        ON_DEMAND: Task.TriggerSpec.Type.ValueType = ...  # 1
        """The task runs one-time shortly after Task Creation."""

        RECURRING: Task.TriggerSpec.Type.ValueType = ...  # 2
        """The task is scheduled to run periodically."""


        TYPE_FIELD_NUMBER: builtins.int
        START_TIME_FIELD_NUMBER: builtins.int
        DISABLED_FIELD_NUMBER: builtins.int
        MAX_RETRIES_FIELD_NUMBER: builtins.int
        SCHEDULE_FIELD_NUMBER: builtins.int
        type: global___Task.TriggerSpec.Type.ValueType = ...
        """Required. Immutable. Trigger type of the user-specified Task."""

        @property
        def start_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
            """Optional. The first run of the task will be after this time.
            If not specified, the task will run shortly after being submitted if
            ON_DEMAND and based on the schedule if RECURRING.
            """
            pass
        disabled: builtins.bool = ...
        """Optional. Prevent the task from executing.
        This does not cancel already running tasks. It is intended to temporarily
        disable RECURRING tasks.
        """

        max_retries: builtins.int = ...
        """Optional. Number of retry attempts before aborting.
        Set to zero to never attempt to retry a failed task.
        """

        schedule: typing.Text = ...
        """Optional. Cron schedule (https://en.wikipedia.org/wiki/Cron) for running
        tasks periodically.
        To explicitly set a timezone to the cron tab, apply a prefix in the
        cron tab: "CRON_TZ=${IANA_TIME_ZONE}" or "TZ=${IANA_TIME_ZONE}".
        The ${IANA_TIME_ZONE} may only be a valid string from IANA time zone
        database. For example, "CRON_TZ=America/New_York 1 * * * *", or
        "TZ=America/New_York 1 * * * *".
        This field is required for RECURRING tasks.
        """

        def __init__(self,
            *,
            type : global___Task.TriggerSpec.Type.ValueType = ...,
            start_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
            disabled : builtins.bool = ...,
            max_retries : builtins.int = ...,
            schedule : typing.Text = ...,
            ) -> None: ...
        def HasField(self, field_name: typing_extensions.Literal["schedule",b"schedule","start_time",b"start_time","trigger",b"trigger"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing_extensions.Literal["disabled",b"disabled","max_retries",b"max_retries","schedule",b"schedule","start_time",b"start_time","trigger",b"trigger","type",b"type"]) -> None: ...
        def WhichOneof(self, oneof_group: typing_extensions.Literal["trigger",b"trigger"]) -> typing.Optional[typing_extensions.Literal["schedule"]]: ...

    class ExecutionSpec(google.protobuf.message.Message):
        """Execution related settings, like retry and service_account."""
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        class ArgsEntry(google.protobuf.message.Message):
            DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
            KEY_FIELD_NUMBER: builtins.int
            VALUE_FIELD_NUMBER: builtins.int
            key: typing.Text = ...
            value: typing.Text = ...
            def __init__(self,
                *,
                key : typing.Text = ...,
                value : typing.Text = ...,
                ) -> None: ...
            def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

        ARGS_FIELD_NUMBER: builtins.int
        SERVICE_ACCOUNT_FIELD_NUMBER: builtins.int
        MAX_JOB_EXECUTION_LIFETIME_FIELD_NUMBER: builtins.int
        @property
        def args(self) -> google.protobuf.internal.containers.ScalarMap[typing.Text, typing.Text]:
            """Optional. The arguments to pass to the task.
            The args can use placeholders of the format ${placeholder} as
            part of key/value string. These will be interpolated before passing the
            args to the driver. Currently supported placeholders:
            - ${task_id}
            - ${job_time}
            To pass positional args, set the key as TASK_ARGS. The value should be a
            comma-separated string of all the positional arguments. To use a
            delimiter other than comma, refer to
            https://cloud.google.com/sdk/gcloud/reference/topic/escaping. In case of
            other keys being present in the args, then TASK_ARGS will be passed as
            the last argument.
            """
            pass
        service_account: typing.Text = ...
        """Required. Service account to use to execute a task.
        If not provided, the default Compute service account for the project is
        used.
        """

        @property
        def max_job_execution_lifetime(self) -> google.protobuf.duration_pb2.Duration:
            """Optional. The maximum duration after which the job execution is expired."""
            pass
        def __init__(self,
            *,
            args : typing.Optional[typing.Mapping[typing.Text, typing.Text]] = ...,
            service_account : typing.Text = ...,
            max_job_execution_lifetime : typing.Optional[google.protobuf.duration_pb2.Duration] = ...,
            ) -> None: ...
        def HasField(self, field_name: typing_extensions.Literal["max_job_execution_lifetime",b"max_job_execution_lifetime"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing_extensions.Literal["args",b"args","max_job_execution_lifetime",b"max_job_execution_lifetime","service_account",b"service_account"]) -> None: ...

    class SparkTaskConfig(google.protobuf.message.Message):
        """User-specified config for running a Spark task."""
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        MAIN_JAR_FILE_URI_FIELD_NUMBER: builtins.int
        MAIN_CLASS_FIELD_NUMBER: builtins.int
        PYTHON_SCRIPT_FILE_FIELD_NUMBER: builtins.int
        SQL_SCRIPT_FILE_FIELD_NUMBER: builtins.int
        SQL_SCRIPT_FIELD_NUMBER: builtins.int
        FILE_URIS_FIELD_NUMBER: builtins.int
        ARCHIVE_URIS_FIELD_NUMBER: builtins.int
        INFRASTRUCTURE_SPEC_FIELD_NUMBER: builtins.int
        main_jar_file_uri: typing.Text = ...
        """The Cloud Storage URI of the jar file that contains the main class.
        The execution args are passed in as a sequence of named process
        arguments (`--key=value`).
        """

        main_class: typing.Text = ...
        """The name of the driver's main class. The jar file that contains the
        class must be in the default CLASSPATH or specified in
        `jar_file_uris`.
        The execution args are passed in as a sequence of named process
        arguments (`--key=value`).
        """

        python_script_file: typing.Text = ...
        """The Gcloud Storage URI of the main Python file to use as the driver.
        Must be a .py file. The execution args are passed in as a sequence of
        named process arguments (`--key=value`).
        """

        sql_script_file: typing.Text = ...
        """A reference to a query file. This can be the Cloud Storage URI of the
        query file or it can the path to a SqlScript Content. The execution
        args are used to declare a set of script variables
        (`set key="value";`).
        """

        sql_script: typing.Text = ...
        """The query text.
        The execution args are used to declare a set of script variables
        (`set key="value";`).
        """

        @property
        def file_uris(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
            """Optional. Cloud Storage URIs of files to be placed in the working directory of each
            executor.
            """
            pass
        @property
        def archive_uris(self) -> google.protobuf.internal.containers.RepeatedScalarFieldContainer[typing.Text]:
            """Optional. Cloud Storage URIs of archives to be extracted into the working directory
            of each executor. Supported file types: .jar, .tar, .tar.gz, .tgz, and
            .zip.
            """
            pass
        @property
        def infrastructure_spec(self) -> global___Task.InfrastructureSpec:
            """Optional. Infrastructure specification for the execution."""
            pass
        def __init__(self,
            *,
            main_jar_file_uri : typing.Text = ...,
            main_class : typing.Text = ...,
            python_script_file : typing.Text = ...,
            sql_script_file : typing.Text = ...,
            sql_script : typing.Text = ...,
            file_uris : typing.Optional[typing.Iterable[typing.Text]] = ...,
            archive_uris : typing.Optional[typing.Iterable[typing.Text]] = ...,
            infrastructure_spec : typing.Optional[global___Task.InfrastructureSpec] = ...,
            ) -> None: ...
        def HasField(self, field_name: typing_extensions.Literal["driver",b"driver","infrastructure_spec",b"infrastructure_spec","main_class",b"main_class","main_jar_file_uri",b"main_jar_file_uri","python_script_file",b"python_script_file","sql_script",b"sql_script","sql_script_file",b"sql_script_file"]) -> builtins.bool: ...
        def ClearField(self, field_name: typing_extensions.Literal["archive_uris",b"archive_uris","driver",b"driver","file_uris",b"file_uris","infrastructure_spec",b"infrastructure_spec","main_class",b"main_class","main_jar_file_uri",b"main_jar_file_uri","python_script_file",b"python_script_file","sql_script",b"sql_script","sql_script_file",b"sql_script_file"]) -> None: ...
        def WhichOneof(self, oneof_group: typing_extensions.Literal["driver",b"driver"]) -> typing.Optional[typing_extensions.Literal["main_jar_file_uri","main_class","python_script_file","sql_script_file","sql_script"]]: ...

    class LabelsEntry(google.protobuf.message.Message):
        DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
        KEY_FIELD_NUMBER: builtins.int
        VALUE_FIELD_NUMBER: builtins.int
        key: typing.Text = ...
        value: typing.Text = ...
        def __init__(self,
            *,
            key : typing.Text = ...,
            value : typing.Text = ...,
            ) -> None: ...
        def ClearField(self, field_name: typing_extensions.Literal["key",b"key","value",b"value"]) -> None: ...

    NAME_FIELD_NUMBER: builtins.int
    UID_FIELD_NUMBER: builtins.int
    CREATE_TIME_FIELD_NUMBER: builtins.int
    UPDATE_TIME_FIELD_NUMBER: builtins.int
    DESCRIPTION_FIELD_NUMBER: builtins.int
    DISPLAY_NAME_FIELD_NUMBER: builtins.int
    STATE_FIELD_NUMBER: builtins.int
    LABELS_FIELD_NUMBER: builtins.int
    TRIGGER_SPEC_FIELD_NUMBER: builtins.int
    EXECUTION_SPEC_FIELD_NUMBER: builtins.int
    SPARK_FIELD_NUMBER: builtins.int
    name: typing.Text = ...
    """Output only. The relative resource name of the task, of the form:
    projects/{project_number}/locations/{location_id}/lakes/{lake_id}/
    tasks/{task_id}.
    """

    uid: typing.Text = ...
    """Output only. System generated globally unique ID for the task. This ID will be
    different if the task is deleted and re-created with the same name.
    """

    @property
    def create_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Output only. The time when the task was created."""
        pass
    @property
    def update_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Output only. The time when the task was last updated."""
        pass
    description: typing.Text = ...
    """Optional. Description of the task."""

    display_name: typing.Text = ...
    """Optional. User friendly display name."""

    state: google.cloud.dataplex.v1.resources_pb2.State.ValueType = ...
    """Output only. Current state of the task."""

    @property
    def labels(self) -> google.protobuf.internal.containers.ScalarMap[typing.Text, typing.Text]:
        """Optional. User-defined labels for the task."""
        pass
    @property
    def trigger_spec(self) -> global___Task.TriggerSpec:
        """Required. Spec related to how often and when a task should be triggered."""
        pass
    @property
    def execution_spec(self) -> global___Task.ExecutionSpec:
        """Required. Spec related to how a task is executed."""
        pass
    @property
    def spark(self) -> global___Task.SparkTaskConfig:
        """Config related to running custom Spark tasks."""
        pass
    def __init__(self,
        *,
        name : typing.Text = ...,
        uid : typing.Text = ...,
        create_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        update_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        description : typing.Text = ...,
        display_name : typing.Text = ...,
        state : google.cloud.dataplex.v1.resources_pb2.State.ValueType = ...,
        labels : typing.Optional[typing.Mapping[typing.Text, typing.Text]] = ...,
        trigger_spec : typing.Optional[global___Task.TriggerSpec] = ...,
        execution_spec : typing.Optional[global___Task.ExecutionSpec] = ...,
        spark : typing.Optional[global___Task.SparkTaskConfig] = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["config",b"config","create_time",b"create_time","execution_spec",b"execution_spec","spark",b"spark","trigger_spec",b"trigger_spec","update_time",b"update_time"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["config",b"config","create_time",b"create_time","description",b"description","display_name",b"display_name","execution_spec",b"execution_spec","labels",b"labels","name",b"name","spark",b"spark","state",b"state","trigger_spec",b"trigger_spec","uid",b"uid","update_time",b"update_time"]) -> None: ...
    def WhichOneof(self, oneof_group: typing_extensions.Literal["config",b"config"]) -> typing.Optional[typing_extensions.Literal["spark"]]: ...
global___Task = Task

class Job(google.protobuf.message.Message):
    """A job represents an instance of a task."""
    DESCRIPTOR: google.protobuf.descriptor.Descriptor = ...
    class _Service:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _ServiceEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_Service.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        SERVICE_UNSPECIFIED: Job.Service.ValueType = ...  # 0
        """Service used to run the job is unspecified."""

        DATAPROC: Job.Service.ValueType = ...  # 1
        """Dataproc service is used to run this job."""

    class Service(_Service, metaclass=_ServiceEnumTypeWrapper):
        pass

    SERVICE_UNSPECIFIED: Job.Service.ValueType = ...  # 0
    """Service used to run the job is unspecified."""

    DATAPROC: Job.Service.ValueType = ...  # 1
    """Dataproc service is used to run this job."""


    class _State:
        ValueType = typing.NewType('ValueType', builtins.int)
        V: typing_extensions.TypeAlias = ValueType
    class _StateEnumTypeWrapper(google.protobuf.internal.enum_type_wrapper._EnumTypeWrapper[_State.ValueType], builtins.type):
        DESCRIPTOR: google.protobuf.descriptor.EnumDescriptor = ...
        STATE_UNSPECIFIED: Job.State.ValueType = ...  # 0
        """The job state is unknown."""

        RUNNING: Job.State.ValueType = ...  # 1
        """The job is running."""

        CANCELLING: Job.State.ValueType = ...  # 2
        """The job is cancelling."""

        CANCELLED: Job.State.ValueType = ...  # 3
        """The job cancellation was successful."""

        SUCCEEDED: Job.State.ValueType = ...  # 4
        """The job completed successfully."""

        FAILED: Job.State.ValueType = ...  # 5
        """The job is no longer running due to an error."""

        ABORTED: Job.State.ValueType = ...  # 6
        """The job was cancelled outside of Dataplex."""

    class State(_State, metaclass=_StateEnumTypeWrapper):
        pass

    STATE_UNSPECIFIED: Job.State.ValueType = ...  # 0
    """The job state is unknown."""

    RUNNING: Job.State.ValueType = ...  # 1
    """The job is running."""

    CANCELLING: Job.State.ValueType = ...  # 2
    """The job is cancelling."""

    CANCELLED: Job.State.ValueType = ...  # 3
    """The job cancellation was successful."""

    SUCCEEDED: Job.State.ValueType = ...  # 4
    """The job completed successfully."""

    FAILED: Job.State.ValueType = ...  # 5
    """The job is no longer running due to an error."""

    ABORTED: Job.State.ValueType = ...  # 6
    """The job was cancelled outside of Dataplex."""


    NAME_FIELD_NUMBER: builtins.int
    UID_FIELD_NUMBER: builtins.int
    START_TIME_FIELD_NUMBER: builtins.int
    END_TIME_FIELD_NUMBER: builtins.int
    STATE_FIELD_NUMBER: builtins.int
    RETRY_COUNT_FIELD_NUMBER: builtins.int
    SERVICE_FIELD_NUMBER: builtins.int
    SERVICE_JOB_FIELD_NUMBER: builtins.int
    MESSAGE_FIELD_NUMBER: builtins.int
    name: typing.Text = ...
    """Output only. The relative resource name of the job, of the form:
    `projects/{project_number}/locations/{location_id}/lakes/{lake_id}/tasks/{task_id}/jobs/{job_id}`.
    """

    uid: typing.Text = ...
    """Output only. System generated globally unique ID for the job."""

    @property
    def start_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Output only. The time when the job was started."""
        pass
    @property
    def end_time(self) -> google.protobuf.timestamp_pb2.Timestamp:
        """Output only. The time when the job ended."""
        pass
    state: global___Job.State.ValueType = ...
    """Output only. Execution state for the job."""

    retry_count: builtins.int = ...
    """Output only. The number of times the job has been retried (excluding the
    initial attempt).
    """

    service: global___Job.Service.ValueType = ...
    """Output only. The underlying service running a job."""

    service_job: typing.Text = ...
    """Output only. The full resource name for the job run under a particular service."""

    message: typing.Text = ...
    """Output only. Additional information about the current state."""

    def __init__(self,
        *,
        name : typing.Text = ...,
        uid : typing.Text = ...,
        start_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        end_time : typing.Optional[google.protobuf.timestamp_pb2.Timestamp] = ...,
        state : global___Job.State.ValueType = ...,
        retry_count : builtins.int = ...,
        service : global___Job.Service.ValueType = ...,
        service_job : typing.Text = ...,
        message : typing.Text = ...,
        ) -> None: ...
    def HasField(self, field_name: typing_extensions.Literal["end_time",b"end_time","start_time",b"start_time"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing_extensions.Literal["end_time",b"end_time","message",b"message","name",b"name","retry_count",b"retry_count","service",b"service","service_job",b"service_job","start_time",b"start_time","state",b"state","uid",b"uid"]) -> None: ...
global___Job = Job
