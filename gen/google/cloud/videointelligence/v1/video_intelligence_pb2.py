# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: google/cloud/videointelligence/v1/video_intelligence.proto
"""Generated protocol buffer code."""
from google.protobuf.internal import enum_type_wrapper
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import message as _message
from google.protobuf import reflection as _reflection
from google.protobuf import symbol_database as _symbol_database
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from google.api import annotations_pb2 as google_dot_api_dot_annotations__pb2
from google.api import client_pb2 as google_dot_api_dot_client__pb2
from google.api import field_behavior_pb2 as google_dot_api_dot_field__behavior__pb2
from google.longrunning import operations_pb2 as google_dot_longrunning_dot_operations__pb2
from google.protobuf import duration_pb2 as google_dot_protobuf_dot_duration__pb2
from google.protobuf import timestamp_pb2 as google_dot_protobuf_dot_timestamp__pb2
from google.rpc import status_pb2 as google_dot_rpc_dot_status__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n:google/cloud/videointelligence/v1/video_intelligence.proto\x12!google.cloud.videointelligence.v1\x1a\x1cgoogle/api/annotations.proto\x1a\x17google/api/client.proto\x1a\x1fgoogle/api/field_behavior.proto\x1a#google/longrunning/operations.proto\x1a\x1egoogle/protobuf/duration.proto\x1a\x1fgoogle/protobuf/timestamp.proto\x1a\x17google/rpc/status.proto\"\xc8\x02\n\x14\x41nnotateVideoRequest\x12\x1b\n\tinput_uri\x18\x01 \x01(\tR\x08inputUri\x12#\n\rinput_content\x18\x06 \x01(\x0cR\x0cinputContent\x12L\n\x08\x66\x65\x61tures\x18\x02 \x03(\x0e\x32*.google.cloud.videointelligence.v1.FeatureB\x04\xe2\x41\x01\x02R\x08\x66\x65\x61tures\x12T\n\rvideo_context\x18\x03 \x01(\x0b\x32/.google.cloud.videointelligence.v1.VideoContextR\x0cvideoContext\x12#\n\noutput_uri\x18\x04 \x01(\tB\x04\xe2\x41\x01\x01R\toutputUri\x12%\n\x0blocation_id\x18\x05 \x01(\tB\x04\xe2\x41\x01\x01R\nlocationId\"\x8f\x08\n\x0cVideoContext\x12K\n\x08segments\x18\x01 \x03(\x0b\x32/.google.cloud.videointelligence.v1.VideoSegmentR\x08segments\x12m\n\x16label_detection_config\x18\x02 \x01(\x0b\x32\x37.google.cloud.videointelligence.v1.LabelDetectionConfigR\x14labelDetectionConfig\x12}\n\x1cshot_change_detection_config\x18\x03 \x01(\x0b\x32<.google.cloud.videointelligence.v1.ShotChangeDetectionConfigR\x19shotChangeDetectionConfig\x12\x8c\x01\n!explicit_content_detection_config\x18\x04 \x01(\x0b\x32\x41.google.cloud.videointelligence.v1.ExplicitContentDetectionConfigR\x1e\x65xplicitContentDetectionConfig\x12j\n\x15\x66\x61\x63\x65_detection_config\x18\x05 \x01(\x0b\x32\x36.google.cloud.videointelligence.v1.FaceDetectionConfigR\x13\x66\x61\x63\x65\x44\x65tectionConfig\x12|\n\x1bspeech_transcription_config\x18\x06 \x01(\x0b\x32<.google.cloud.videointelligence.v1.SpeechTranscriptionConfigR\x19speechTranscriptionConfig\x12j\n\x15text_detection_config\x18\x08 \x01(\x0b\x32\x36.google.cloud.videointelligence.v1.TextDetectionConfigR\x13textDetectionConfig\x12p\n\x17person_detection_config\x18\x0b \x01(\x0b\x32\x38.google.cloud.videointelligence.v1.PersonDetectionConfigR\x15personDetectionConfig\x12m\n\x16object_tracking_config\x18\r \x01(\x0b\x32\x37.google.cloud.videointelligence.v1.ObjectTrackingConfigR\x14objectTrackingConfig\"\xbe\x02\n\x14LabelDetectionConfig\x12g\n\x14label_detection_mode\x18\x01 \x01(\x0e\x32\x35.google.cloud.videointelligence.v1.LabelDetectionModeR\x12labelDetectionMode\x12+\n\x11stationary_camera\x18\x02 \x01(\x08R\x10stationaryCamera\x12\x14\n\x05model\x18\x03 \x01(\tR\x05model\x12<\n\x1a\x66rame_confidence_threshold\x18\x04 \x01(\x02R\x18\x66rameConfidenceThreshold\x12<\n\x1avideo_confidence_threshold\x18\x05 \x01(\x02R\x18videoConfidenceThreshold\"1\n\x19ShotChangeDetectionConfig\x12\x14\n\x05model\x18\x01 \x01(\tR\x05model\",\n\x14ObjectTrackingConfig\x12\x14\n\x05model\x18\x01 \x01(\tR\x05model\"\x90\x01\n\x13\x46\x61\x63\x65\x44\x65tectionConfig\x12\x14\n\x05model\x18\x01 \x01(\tR\x05model\x12\x34\n\x16include_bounding_boxes\x18\x02 \x01(\x08R\x14includeBoundingBoxes\x12-\n\x12include_attributes\x18\x05 \x01(\x08R\x11includeAttributes\"\xb2\x01\n\x15PersonDetectionConfig\x12\x34\n\x16include_bounding_boxes\x18\x01 \x01(\x08R\x14includeBoundingBoxes\x12\x34\n\x16include_pose_landmarks\x18\x02 \x01(\x08R\x14includePoseLandmarks\x12-\n\x12include_attributes\x18\x03 \x01(\x08R\x11includeAttributes\"6\n\x1e\x45xplicitContentDetectionConfig\x12\x14\n\x05model\x18\x01 \x01(\tR\x05model\"R\n\x13TextDetectionConfig\x12%\n\x0elanguage_hints\x18\x01 \x03(\tR\rlanguageHints\x12\x14\n\x05model\x18\x02 \x01(\tR\x05model\"\x98\x01\n\x0cVideoSegment\x12\x45\n\x11start_time_offset\x18\x01 \x01(\x0b\x32\x19.google.protobuf.DurationR\x0fstartTimeOffset\x12\x41\n\x0f\x65nd_time_offset\x18\x02 \x01(\x0b\x32\x19.google.protobuf.DurationR\rendTimeOffset\"y\n\x0cLabelSegment\x12I\n\x07segment\x18\x01 \x01(\x0b\x32/.google.cloud.videointelligence.v1.VideoSegmentR\x07segment\x12\x1e\n\nconfidence\x18\x02 \x01(\x02R\nconfidence\"h\n\nLabelFrame\x12:\n\x0btime_offset\x18\x01 \x01(\x0b\x32\x19.google.protobuf.DurationR\ntimeOffset\x12\x1e\n\nconfidence\x18\x02 \x01(\x02R\nconfidence\"l\n\x06\x45ntity\x12\x1b\n\tentity_id\x18\x01 \x01(\tR\x08\x65ntityId\x12 \n\x0b\x64\x65scription\x18\x02 \x01(\tR\x0b\x64\x65scription\x12#\n\rlanguage_code\x18\x03 \x01(\tR\x0clanguageCode\"\xda\x02\n\x0fLabelAnnotation\x12\x41\n\x06\x65ntity\x18\x01 \x01(\x0b\x32).google.cloud.videointelligence.v1.EntityR\x06\x65ntity\x12V\n\x11\x63\x61tegory_entities\x18\x02 \x03(\x0b\x32).google.cloud.videointelligence.v1.EntityR\x10\x63\x61tegoryEntities\x12K\n\x08segments\x18\x03 \x03(\x0b\x32/.google.cloud.videointelligence.v1.LabelSegmentR\x08segments\x12\x45\n\x06\x66rames\x18\x04 \x03(\x0b\x32-.google.cloud.videointelligence.v1.LabelFrameR\x06\x66rames\x12\x18\n\x07version\x18\x05 \x01(\tR\x07version\"\xb8\x01\n\x14\x45xplicitContentFrame\x12:\n\x0btime_offset\x18\x01 \x01(\x0b\x32\x19.google.protobuf.DurationR\ntimeOffset\x12\x64\n\x16pornography_likelihood\x18\x02 \x01(\x0e\x32-.google.cloud.videointelligence.v1.LikelihoodR\x15pornographyLikelihood\"\x86\x01\n\x19\x45xplicitContentAnnotation\x12O\n\x06\x66rames\x18\x01 \x03(\x0b\x32\x37.google.cloud.videointelligence.v1.ExplicitContentFrameR\x06\x66rames\x12\x18\n\x07version\x18\x02 \x01(\tR\x07version\"k\n\x15NormalizedBoundingBox\x12\x12\n\x04left\x18\x01 \x01(\x02R\x04left\x12\x10\n\x03top\x18\x02 \x01(\x02R\x03top\x12\x14\n\x05right\x18\x03 \x01(\x02R\x05right\x12\x16\n\x06\x62ottom\x18\x04 \x01(\x02R\x06\x62ottom\"\x93\x01\n\x17\x46\x61\x63\x65\x44\x65tectionAnnotation\x12@\n\x06tracks\x18\x03 \x03(\x0b\x32(.google.cloud.videointelligence.v1.TrackR\x06tracks\x12\x1c\n\tthumbnail\x18\x04 \x01(\x0cR\tthumbnail\x12\x18\n\x07version\x18\x05 \x01(\tR\x07version\"w\n\x19PersonDetectionAnnotation\x12@\n\x06tracks\x18\x01 \x03(\x0b\x32(.google.cloud.videointelligence.v1.TrackR\x06tracks\x12\x18\n\x07version\x18\x02 \x01(\tR\x07version\"X\n\x0b\x46\x61\x63\x65Segment\x12I\n\x07segment\x18\x01 \x01(\x0b\x32/.google.cloud.videointelligence.v1.VideoSegmentR\x07segment\"\xc1\x01\n\tFaceFrame\x12t\n\x19normalized_bounding_boxes\x18\x01 \x03(\x0b\x32\x38.google.cloud.videointelligence.v1.NormalizedBoundingBoxR\x17normalizedBoundingBoxes\x12:\n\x0btime_offset\x18\x02 \x01(\x0b\x32\x19.google.protobuf.DurationR\ntimeOffset:\x02\x18\x01\"\xc4\x01\n\x0e\x46\x61\x63\x65\x41nnotation\x12\x1c\n\tthumbnail\x18\x01 \x01(\x0cR\tthumbnail\x12J\n\x08segments\x18\x02 \x03(\x0b\x32..google.cloud.videointelligence.v1.FaceSegmentR\x08segments\x12\x44\n\x06\x66rames\x18\x03 \x03(\x0b\x32,.google.cloud.videointelligence.v1.FaceFrameR\x06\x66rames:\x02\x18\x01\"\xf6\x02\n\x11TimestampedObject\x12p\n\x17normalized_bounding_box\x18\x01 \x01(\x0b\x32\x38.google.cloud.videointelligence.v1.NormalizedBoundingBoxR\x15normalizedBoundingBox\x12:\n\x0btime_offset\x18\x02 \x01(\x0b\x32\x19.google.protobuf.DurationR\ntimeOffset\x12Z\n\nattributes\x18\x03 \x03(\x0b\x32\x34.google.cloud.videointelligence.v1.DetectedAttributeB\x04\xe2\x41\x01\x01R\nattributes\x12W\n\tlandmarks\x18\x04 \x03(\x0b\x32\x33.google.cloud.videointelligence.v1.DetectedLandmarkB\x04\xe2\x41\x01\x01R\tlandmarks\"\xbb\x02\n\x05Track\x12I\n\x07segment\x18\x01 \x01(\x0b\x32/.google.cloud.videointelligence.v1.VideoSegmentR\x07segment\x12\x65\n\x13timestamped_objects\x18\x02 \x03(\x0b\x32\x34.google.cloud.videointelligence.v1.TimestampedObjectR\x12timestampedObjects\x12Z\n\nattributes\x18\x03 \x03(\x0b\x32\x34.google.cloud.videointelligence.v1.DetectedAttributeB\x04\xe2\x41\x01\x01R\nattributes\x12$\n\nconfidence\x18\x04 \x01(\x02\x42\x04\xe2\x41\x01\x01R\nconfidence\"]\n\x11\x44\x65tectedAttribute\x12\x12\n\x04name\x18\x01 \x01(\tR\x04name\x12\x1e\n\nconfidence\x18\x02 \x01(\x02R\nconfidence\x12\x14\n\x05value\x18\x03 \x01(\tR\x05value\"\x91\x01\n\x10\x44\x65tectedLandmark\x12\x12\n\x04name\x18\x01 \x01(\tR\x04name\x12I\n\x05point\x18\x02 \x01(\x0b\x32\x33.google.cloud.videointelligence.v1.NormalizedVertexR\x05point\x12\x1e\n\nconfidence\x18\x03 \x01(\x02R\nconfidence\"\xca\r\n\x16VideoAnnotationResults\x12\x1b\n\tinput_uri\x18\x01 \x01(\tR\x08inputUri\x12I\n\x07segment\x18\n \x01(\x0b\x32/.google.cloud.videointelligence.v1.VideoSegmentR\x07segment\x12n\n\x19segment_label_annotations\x18\x02 \x03(\x0b\x32\x32.google.cloud.videointelligence.v1.LabelAnnotationR\x17segmentLabelAnnotations\x12\x7f\n\"segment_presence_label_annotations\x18\x17 \x03(\x0b\x32\x32.google.cloud.videointelligence.v1.LabelAnnotationR\x1fsegmentPresenceLabelAnnotations\x12h\n\x16shot_label_annotations\x18\x03 \x03(\x0b\x32\x32.google.cloud.videointelligence.v1.LabelAnnotationR\x14shotLabelAnnotations\x12y\n\x1fshot_presence_label_annotations\x18\x18 \x03(\x0b\x32\x32.google.cloud.videointelligence.v1.LabelAnnotationR\x1cshotPresenceLabelAnnotations\x12j\n\x17\x66rame_label_annotations\x18\x04 \x03(\x0b\x32\x32.google.cloud.videointelligence.v1.LabelAnnotationR\x15\x66rameLabelAnnotations\x12`\n\x10\x66\x61\x63\x65_annotations\x18\x05 \x03(\x0b\x32\x31.google.cloud.videointelligence.v1.FaceAnnotationB\x02\x18\x01R\x0f\x66\x61\x63\x65\x41nnotations\x12x\n\x1a\x66\x61\x63\x65_detection_annotations\x18\r \x03(\x0b\x32:.google.cloud.videointelligence.v1.FaceDetectionAnnotationR\x18\x66\x61\x63\x65\x44\x65tectionAnnotations\x12Z\n\x10shot_annotations\x18\x06 \x03(\x0b\x32/.google.cloud.videointelligence.v1.VideoSegmentR\x0fshotAnnotations\x12m\n\x13\x65xplicit_annotation\x18\x07 \x01(\x0b\x32<.google.cloud.videointelligence.v1.ExplicitContentAnnotationR\x12\x65xplicitAnnotation\x12k\n\x15speech_transcriptions\x18\x0b \x03(\x0b\x32\x36.google.cloud.videointelligence.v1.SpeechTranscriptionR\x14speechTranscriptions\x12\\\n\x10text_annotations\x18\x0c \x03(\x0b\x32\x31.google.cloud.videointelligence.v1.TextAnnotationR\x0ftextAnnotations\x12j\n\x12object_annotations\x18\x0e \x03(\x0b\x32;.google.cloud.videointelligence.v1.ObjectTrackingAnnotationR\x11objectAnnotations\x12~\n\x1clogo_recognition_annotations\x18\x13 \x03(\x0b\x32<.google.cloud.videointelligence.v1.LogoRecognitionAnnotationR\x1alogoRecognitionAnnotations\x12~\n\x1cperson_detection_annotations\x18\x14 \x03(\x0b\x32<.google.cloud.videointelligence.v1.PersonDetectionAnnotationR\x1apersonDetectionAnnotations\x12(\n\x05\x65rror\x18\t \x01(\x0b\x32\x12.google.rpc.StatusR\x05\x65rror\"\x81\x01\n\x15\x41nnotateVideoResponse\x12h\n\x12\x61nnotation_results\x18\x01 \x03(\x0b\x32\x39.google.cloud.videointelligence.v1.VideoAnnotationResultsR\x11\x61nnotationResults\"\xea\x02\n\x17VideoAnnotationProgress\x12\x1b\n\tinput_uri\x18\x01 \x01(\tR\x08inputUri\x12)\n\x10progress_percent\x18\x02 \x01(\x05R\x0fprogressPercent\x12\x39\n\nstart_time\x18\x03 \x01(\x0b\x32\x1a.google.protobuf.TimestampR\tstartTime\x12;\n\x0bupdate_time\x18\x04 \x01(\x0b\x32\x1a.google.protobuf.TimestampR\nupdateTime\x12\x44\n\x07\x66\x65\x61ture\x18\x05 \x01(\x0e\x32*.google.cloud.videointelligence.v1.FeatureR\x07\x66\x65\x61ture\x12I\n\x07segment\x18\x06 \x01(\x0b\x32/.google.cloud.videointelligence.v1.VideoSegmentR\x07segment\"\x84\x01\n\x15\x41nnotateVideoProgress\x12k\n\x13\x61nnotation_progress\x18\x01 \x03(\x0b\x32:.google.cloud.videointelligence.v1.VideoAnnotationProgressR\x12\x61nnotationProgress\"\xbc\x04\n\x19SpeechTranscriptionConfig\x12)\n\rlanguage_code\x18\x01 \x01(\tB\x04\xe2\x41\x01\x02R\x0clanguageCode\x12/\n\x10max_alternatives\x18\x02 \x01(\x05\x42\x04\xe2\x41\x01\x01R\x0fmaxAlternatives\x12/\n\x10\x66ilter_profanity\x18\x03 \x01(\x08\x42\x04\xe2\x41\x01\x01R\x0f\x66ilterProfanity\x12_\n\x0fspeech_contexts\x18\x04 \x03(\x0b\x32\x30.google.cloud.videointelligence.v1.SpeechContextB\x04\xe2\x41\x01\x01R\x0espeechContexts\x12\x46\n\x1c\x65nable_automatic_punctuation\x18\x05 \x01(\x08\x42\x04\xe2\x41\x01\x01R\x1a\x65nableAutomaticPunctuation\x12\'\n\x0c\x61udio_tracks\x18\x06 \x03(\x05\x42\x04\xe2\x41\x01\x01R\x0b\x61udioTracks\x12\x42\n\x1a\x65nable_speaker_diarization\x18\x07 \x01(\x08\x42\x04\xe2\x41\x01\x01R\x18\x65nableSpeakerDiarization\x12@\n\x19\x64iarization_speaker_count\x18\x08 \x01(\x05\x42\x04\xe2\x41\x01\x01R\x17\x64iarizationSpeakerCount\x12:\n\x16\x65nable_word_confidence\x18\t \x01(\x08\x42\x04\xe2\x41\x01\x01R\x14\x65nableWordConfidence\"/\n\rSpeechContext\x12\x1e\n\x07phrases\x18\x01 \x03(\tB\x04\xe2\x41\x01\x01R\x07phrases\"\xa5\x01\n\x13SpeechTranscription\x12\x63\n\x0c\x61lternatives\x18\x01 \x03(\x0b\x32?.google.cloud.videointelligence.v1.SpeechRecognitionAlternativeR\x0c\x61lternatives\x12)\n\rlanguage_code\x18\x02 \x01(\tB\x04\xe2\x41\x01\x03R\x0clanguageCode\"\xad\x01\n\x1cSpeechRecognitionAlternative\x12\x1e\n\ntranscript\x18\x01 \x01(\tR\ntranscript\x12$\n\nconfidence\x18\x02 \x01(\x02\x42\x04\xe2\x41\x01\x03R\nconfidence\x12G\n\x05words\x18\x03 \x03(\x0b\x32+.google.cloud.videointelligence.v1.WordInfoB\x04\xe2\x41\x01\x03R\x05words\"\xdb\x01\n\x08WordInfo\x12\x38\n\nstart_time\x18\x01 \x01(\x0b\x32\x19.google.protobuf.DurationR\tstartTime\x12\x34\n\x08\x65nd_time\x18\x02 \x01(\x0b\x32\x19.google.protobuf.DurationR\x07\x65ndTime\x12\x12\n\x04word\x18\x03 \x01(\tR\x04word\x12$\n\nconfidence\x18\x04 \x01(\x02\x42\x04\xe2\x41\x01\x03R\nconfidence\x12%\n\x0bspeaker_tag\x18\x05 \x01(\x05\x42\x04\xe2\x41\x01\x03R\nspeakerTag\".\n\x10NormalizedVertex\x12\x0c\n\x01x\x18\x01 \x01(\x02R\x01x\x12\x0c\n\x01y\x18\x02 \x01(\x02R\x01y\"i\n\x16NormalizedBoundingPoly\x12O\n\x08vertices\x18\x01 \x03(\x0b\x32\x33.google.cloud.videointelligence.v1.NormalizedVertexR\x08vertices\"\xbe\x01\n\x0bTextSegment\x12I\n\x07segment\x18\x01 \x01(\x0b\x32/.google.cloud.videointelligence.v1.VideoSegmentR\x07segment\x12\x1e\n\nconfidence\x18\x02 \x01(\x02R\nconfidence\x12\x44\n\x06\x66rames\x18\x03 \x03(\x0b\x32,.google.cloud.videointelligence.v1.TextFrameR\x06\x66rames\"\xb4\x01\n\tTextFrame\x12k\n\x14rotated_bounding_box\x18\x01 \x01(\x0b\x32\x39.google.cloud.videointelligence.v1.NormalizedBoundingPolyR\x12rotatedBoundingBox\x12:\n\x0btime_offset\x18\x02 \x01(\x0b\x32\x19.google.protobuf.DurationR\ntimeOffset\"\x8a\x01\n\x0eTextAnnotation\x12\x12\n\x04text\x18\x01 \x01(\tR\x04text\x12J\n\x08segments\x18\x02 \x03(\x0b\x32..google.cloud.videointelligence.v1.TextSegmentR\x08segments\x12\x18\n\x07version\x18\x03 \x01(\tR\x07version\"\xc3\x01\n\x13ObjectTrackingFrame\x12p\n\x17normalized_bounding_box\x18\x01 \x01(\x0b\x32\x38.google.cloud.videointelligence.v1.NormalizedBoundingBoxR\x15normalizedBoundingBox\x12:\n\x0btime_offset\x18\x02 \x01(\x0b\x32\x19.google.protobuf.DurationR\ntimeOffset\"\xdf\x02\n\x18ObjectTrackingAnnotation\x12K\n\x07segment\x18\x03 \x01(\x0b\x32/.google.cloud.videointelligence.v1.VideoSegmentH\x00R\x07segment\x12\x1b\n\x08track_id\x18\x05 \x01(\x03H\x00R\x07trackId\x12\x41\n\x06\x65ntity\x18\x01 \x01(\x0b\x32).google.cloud.videointelligence.v1.EntityR\x06\x65ntity\x12\x1e\n\nconfidence\x18\x04 \x01(\x02R\nconfidence\x12N\n\x06\x66rames\x18\x02 \x03(\x0b\x32\x36.google.cloud.videointelligence.v1.ObjectTrackingFrameR\x06\x66rames\x12\x18\n\x07version\x18\x06 \x01(\tR\x07versionB\x0c\n\ntrack_info\"\xed\x01\n\x19LogoRecognitionAnnotation\x12\x41\n\x06\x65ntity\x18\x01 \x01(\x0b\x32).google.cloud.videointelligence.v1.EntityR\x06\x65ntity\x12@\n\x06tracks\x18\x02 \x03(\x0b\x32(.google.cloud.videointelligence.v1.TrackR\x06tracks\x12K\n\x08segments\x18\x03 \x03(\x0b\x32/.google.cloud.videointelligence.v1.VideoSegmentR\x08segments*\xf5\x01\n\x07\x46\x65\x61ture\x12\x17\n\x13\x46\x45\x41TURE_UNSPECIFIED\x10\x00\x12\x13\n\x0fLABEL_DETECTION\x10\x01\x12\x19\n\x15SHOT_CHANGE_DETECTION\x10\x02\x12\x1e\n\x1a\x45XPLICIT_CONTENT_DETECTION\x10\x03\x12\x12\n\x0e\x46\x41\x43\x45_DETECTION\x10\x04\x12\x18\n\x14SPEECH_TRANSCRIPTION\x10\x06\x12\x12\n\x0eTEXT_DETECTION\x10\x07\x12\x13\n\x0fOBJECT_TRACKING\x10\t\x12\x14\n\x10LOGO_RECOGNITION\x10\x0c\x12\x14\n\x10PERSON_DETECTION\x10\x0e*r\n\x12LabelDetectionMode\x12$\n LABEL_DETECTION_MODE_UNSPECIFIED\x10\x00\x12\r\n\tSHOT_MODE\x10\x01\x12\x0e\n\nFRAME_MODE\x10\x02\x12\x17\n\x13SHOT_AND_FRAME_MODE\x10\x03*t\n\nLikelihood\x12\x1a\n\x16LIKELIHOOD_UNSPECIFIED\x10\x00\x12\x11\n\rVERY_UNLIKELY\x10\x01\x12\x0c\n\x08UNLIKELY\x10\x02\x12\x0c\n\x08POSSIBLE\x10\x03\x12\n\n\x06LIKELY\x10\x04\x12\x0f\n\x0bVERY_LIKELY\x10\x05\x32\xc0\x02\n\x18VideoIntelligenceService\x12\xcd\x01\n\rAnnotateVideo\x12\x37.google.cloud.videointelligence.v1.AnnotateVideoRequest\x1a\x1d.google.longrunning.Operation\"d\xca\x41.\n\x15\x41nnotateVideoResponse\x12\x15\x41nnotateVideoProgress\xda\x41\x12input_uri,features\x82\xd3\xe4\x93\x02\x18\"\x13/v1/videos:annotate:\x01*\x1aT\xca\x41 videointelligence.googleapis.com\xd2\x41.https://www.googleapis.com/auth/cloud-platformB\x8b\x02\n%com.google.cloud.videointelligence.v1B\x1dVideoIntelligenceServiceProtoP\x01ZRgoogle.golang.org/genproto/googleapis/cloud/videointelligence/v1;videointelligence\xaa\x02!Google.Cloud.VideoIntelligence.V1\xca\x02!Google\\Cloud\\VideoIntelligence\\V1\xea\x02$Google::Cloud::VideoIntelligence::V1b\x06proto3')

_FEATURE = DESCRIPTOR.enum_types_by_name['Feature']
Feature = enum_type_wrapper.EnumTypeWrapper(_FEATURE)
_LABELDETECTIONMODE = DESCRIPTOR.enum_types_by_name['LabelDetectionMode']
LabelDetectionMode = enum_type_wrapper.EnumTypeWrapper(_LABELDETECTIONMODE)
_LIKELIHOOD = DESCRIPTOR.enum_types_by_name['Likelihood']
Likelihood = enum_type_wrapper.EnumTypeWrapper(_LIKELIHOOD)
FEATURE_UNSPECIFIED = 0
LABEL_DETECTION = 1
SHOT_CHANGE_DETECTION = 2
EXPLICIT_CONTENT_DETECTION = 3
FACE_DETECTION = 4
SPEECH_TRANSCRIPTION = 6
TEXT_DETECTION = 7
OBJECT_TRACKING = 9
LOGO_RECOGNITION = 12
PERSON_DETECTION = 14
LABEL_DETECTION_MODE_UNSPECIFIED = 0
SHOT_MODE = 1
FRAME_MODE = 2
SHOT_AND_FRAME_MODE = 3
LIKELIHOOD_UNSPECIFIED = 0
VERY_UNLIKELY = 1
UNLIKELY = 2
POSSIBLE = 3
LIKELY = 4
VERY_LIKELY = 5


_ANNOTATEVIDEOREQUEST = DESCRIPTOR.message_types_by_name['AnnotateVideoRequest']
_VIDEOCONTEXT = DESCRIPTOR.message_types_by_name['VideoContext']
_LABELDETECTIONCONFIG = DESCRIPTOR.message_types_by_name['LabelDetectionConfig']
_SHOTCHANGEDETECTIONCONFIG = DESCRIPTOR.message_types_by_name['ShotChangeDetectionConfig']
_OBJECTTRACKINGCONFIG = DESCRIPTOR.message_types_by_name['ObjectTrackingConfig']
_FACEDETECTIONCONFIG = DESCRIPTOR.message_types_by_name['FaceDetectionConfig']
_PERSONDETECTIONCONFIG = DESCRIPTOR.message_types_by_name['PersonDetectionConfig']
_EXPLICITCONTENTDETECTIONCONFIG = DESCRIPTOR.message_types_by_name['ExplicitContentDetectionConfig']
_TEXTDETECTIONCONFIG = DESCRIPTOR.message_types_by_name['TextDetectionConfig']
_VIDEOSEGMENT = DESCRIPTOR.message_types_by_name['VideoSegment']
_LABELSEGMENT = DESCRIPTOR.message_types_by_name['LabelSegment']
_LABELFRAME = DESCRIPTOR.message_types_by_name['LabelFrame']
_ENTITY = DESCRIPTOR.message_types_by_name['Entity']
_LABELANNOTATION = DESCRIPTOR.message_types_by_name['LabelAnnotation']
_EXPLICITCONTENTFRAME = DESCRIPTOR.message_types_by_name['ExplicitContentFrame']
_EXPLICITCONTENTANNOTATION = DESCRIPTOR.message_types_by_name['ExplicitContentAnnotation']
_NORMALIZEDBOUNDINGBOX = DESCRIPTOR.message_types_by_name['NormalizedBoundingBox']
_FACEDETECTIONANNOTATION = DESCRIPTOR.message_types_by_name['FaceDetectionAnnotation']
_PERSONDETECTIONANNOTATION = DESCRIPTOR.message_types_by_name['PersonDetectionAnnotation']
_FACESEGMENT = DESCRIPTOR.message_types_by_name['FaceSegment']
_FACEFRAME = DESCRIPTOR.message_types_by_name['FaceFrame']
_FACEANNOTATION = DESCRIPTOR.message_types_by_name['FaceAnnotation']
_TIMESTAMPEDOBJECT = DESCRIPTOR.message_types_by_name['TimestampedObject']
_TRACK = DESCRIPTOR.message_types_by_name['Track']
_DETECTEDATTRIBUTE = DESCRIPTOR.message_types_by_name['DetectedAttribute']
_DETECTEDLANDMARK = DESCRIPTOR.message_types_by_name['DetectedLandmark']
_VIDEOANNOTATIONRESULTS = DESCRIPTOR.message_types_by_name['VideoAnnotationResults']
_ANNOTATEVIDEORESPONSE = DESCRIPTOR.message_types_by_name['AnnotateVideoResponse']
_VIDEOANNOTATIONPROGRESS = DESCRIPTOR.message_types_by_name['VideoAnnotationProgress']
_ANNOTATEVIDEOPROGRESS = DESCRIPTOR.message_types_by_name['AnnotateVideoProgress']
_SPEECHTRANSCRIPTIONCONFIG = DESCRIPTOR.message_types_by_name['SpeechTranscriptionConfig']
_SPEECHCONTEXT = DESCRIPTOR.message_types_by_name['SpeechContext']
_SPEECHTRANSCRIPTION = DESCRIPTOR.message_types_by_name['SpeechTranscription']
_SPEECHRECOGNITIONALTERNATIVE = DESCRIPTOR.message_types_by_name['SpeechRecognitionAlternative']
_WORDINFO = DESCRIPTOR.message_types_by_name['WordInfo']
_NORMALIZEDVERTEX = DESCRIPTOR.message_types_by_name['NormalizedVertex']
_NORMALIZEDBOUNDINGPOLY = DESCRIPTOR.message_types_by_name['NormalizedBoundingPoly']
_TEXTSEGMENT = DESCRIPTOR.message_types_by_name['TextSegment']
_TEXTFRAME = DESCRIPTOR.message_types_by_name['TextFrame']
_TEXTANNOTATION = DESCRIPTOR.message_types_by_name['TextAnnotation']
_OBJECTTRACKINGFRAME = DESCRIPTOR.message_types_by_name['ObjectTrackingFrame']
_OBJECTTRACKINGANNOTATION = DESCRIPTOR.message_types_by_name['ObjectTrackingAnnotation']
_LOGORECOGNITIONANNOTATION = DESCRIPTOR.message_types_by_name['LogoRecognitionAnnotation']
AnnotateVideoRequest = _reflection.GeneratedProtocolMessageType('AnnotateVideoRequest', (_message.Message,), {
  'DESCRIPTOR' : _ANNOTATEVIDEOREQUEST,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.AnnotateVideoRequest)
  })
_sym_db.RegisterMessage(AnnotateVideoRequest)

VideoContext = _reflection.GeneratedProtocolMessageType('VideoContext', (_message.Message,), {
  'DESCRIPTOR' : _VIDEOCONTEXT,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.VideoContext)
  })
_sym_db.RegisterMessage(VideoContext)

LabelDetectionConfig = _reflection.GeneratedProtocolMessageType('LabelDetectionConfig', (_message.Message,), {
  'DESCRIPTOR' : _LABELDETECTIONCONFIG,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.LabelDetectionConfig)
  })
_sym_db.RegisterMessage(LabelDetectionConfig)

ShotChangeDetectionConfig = _reflection.GeneratedProtocolMessageType('ShotChangeDetectionConfig', (_message.Message,), {
  'DESCRIPTOR' : _SHOTCHANGEDETECTIONCONFIG,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.ShotChangeDetectionConfig)
  })
_sym_db.RegisterMessage(ShotChangeDetectionConfig)

ObjectTrackingConfig = _reflection.GeneratedProtocolMessageType('ObjectTrackingConfig', (_message.Message,), {
  'DESCRIPTOR' : _OBJECTTRACKINGCONFIG,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.ObjectTrackingConfig)
  })
_sym_db.RegisterMessage(ObjectTrackingConfig)

FaceDetectionConfig = _reflection.GeneratedProtocolMessageType('FaceDetectionConfig', (_message.Message,), {
  'DESCRIPTOR' : _FACEDETECTIONCONFIG,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.FaceDetectionConfig)
  })
_sym_db.RegisterMessage(FaceDetectionConfig)

PersonDetectionConfig = _reflection.GeneratedProtocolMessageType('PersonDetectionConfig', (_message.Message,), {
  'DESCRIPTOR' : _PERSONDETECTIONCONFIG,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.PersonDetectionConfig)
  })
_sym_db.RegisterMessage(PersonDetectionConfig)

ExplicitContentDetectionConfig = _reflection.GeneratedProtocolMessageType('ExplicitContentDetectionConfig', (_message.Message,), {
  'DESCRIPTOR' : _EXPLICITCONTENTDETECTIONCONFIG,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.ExplicitContentDetectionConfig)
  })
_sym_db.RegisterMessage(ExplicitContentDetectionConfig)

TextDetectionConfig = _reflection.GeneratedProtocolMessageType('TextDetectionConfig', (_message.Message,), {
  'DESCRIPTOR' : _TEXTDETECTIONCONFIG,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.TextDetectionConfig)
  })
_sym_db.RegisterMessage(TextDetectionConfig)

VideoSegment = _reflection.GeneratedProtocolMessageType('VideoSegment', (_message.Message,), {
  'DESCRIPTOR' : _VIDEOSEGMENT,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.VideoSegment)
  })
_sym_db.RegisterMessage(VideoSegment)

LabelSegment = _reflection.GeneratedProtocolMessageType('LabelSegment', (_message.Message,), {
  'DESCRIPTOR' : _LABELSEGMENT,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.LabelSegment)
  })
_sym_db.RegisterMessage(LabelSegment)

LabelFrame = _reflection.GeneratedProtocolMessageType('LabelFrame', (_message.Message,), {
  'DESCRIPTOR' : _LABELFRAME,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.LabelFrame)
  })
_sym_db.RegisterMessage(LabelFrame)

Entity = _reflection.GeneratedProtocolMessageType('Entity', (_message.Message,), {
  'DESCRIPTOR' : _ENTITY,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.Entity)
  })
_sym_db.RegisterMessage(Entity)

LabelAnnotation = _reflection.GeneratedProtocolMessageType('LabelAnnotation', (_message.Message,), {
  'DESCRIPTOR' : _LABELANNOTATION,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.LabelAnnotation)
  })
_sym_db.RegisterMessage(LabelAnnotation)

ExplicitContentFrame = _reflection.GeneratedProtocolMessageType('ExplicitContentFrame', (_message.Message,), {
  'DESCRIPTOR' : _EXPLICITCONTENTFRAME,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.ExplicitContentFrame)
  })
_sym_db.RegisterMessage(ExplicitContentFrame)

ExplicitContentAnnotation = _reflection.GeneratedProtocolMessageType('ExplicitContentAnnotation', (_message.Message,), {
  'DESCRIPTOR' : _EXPLICITCONTENTANNOTATION,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.ExplicitContentAnnotation)
  })
_sym_db.RegisterMessage(ExplicitContentAnnotation)

NormalizedBoundingBox = _reflection.GeneratedProtocolMessageType('NormalizedBoundingBox', (_message.Message,), {
  'DESCRIPTOR' : _NORMALIZEDBOUNDINGBOX,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.NormalizedBoundingBox)
  })
_sym_db.RegisterMessage(NormalizedBoundingBox)

FaceDetectionAnnotation = _reflection.GeneratedProtocolMessageType('FaceDetectionAnnotation', (_message.Message,), {
  'DESCRIPTOR' : _FACEDETECTIONANNOTATION,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.FaceDetectionAnnotation)
  })
_sym_db.RegisterMessage(FaceDetectionAnnotation)

PersonDetectionAnnotation = _reflection.GeneratedProtocolMessageType('PersonDetectionAnnotation', (_message.Message,), {
  'DESCRIPTOR' : _PERSONDETECTIONANNOTATION,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.PersonDetectionAnnotation)
  })
_sym_db.RegisterMessage(PersonDetectionAnnotation)

FaceSegment = _reflection.GeneratedProtocolMessageType('FaceSegment', (_message.Message,), {
  'DESCRIPTOR' : _FACESEGMENT,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.FaceSegment)
  })
_sym_db.RegisterMessage(FaceSegment)

FaceFrame = _reflection.GeneratedProtocolMessageType('FaceFrame', (_message.Message,), {
  'DESCRIPTOR' : _FACEFRAME,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.FaceFrame)
  })
_sym_db.RegisterMessage(FaceFrame)

FaceAnnotation = _reflection.GeneratedProtocolMessageType('FaceAnnotation', (_message.Message,), {
  'DESCRIPTOR' : _FACEANNOTATION,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.FaceAnnotation)
  })
_sym_db.RegisterMessage(FaceAnnotation)

TimestampedObject = _reflection.GeneratedProtocolMessageType('TimestampedObject', (_message.Message,), {
  'DESCRIPTOR' : _TIMESTAMPEDOBJECT,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.TimestampedObject)
  })
_sym_db.RegisterMessage(TimestampedObject)

Track = _reflection.GeneratedProtocolMessageType('Track', (_message.Message,), {
  'DESCRIPTOR' : _TRACK,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.Track)
  })
_sym_db.RegisterMessage(Track)

DetectedAttribute = _reflection.GeneratedProtocolMessageType('DetectedAttribute', (_message.Message,), {
  'DESCRIPTOR' : _DETECTEDATTRIBUTE,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.DetectedAttribute)
  })
_sym_db.RegisterMessage(DetectedAttribute)

DetectedLandmark = _reflection.GeneratedProtocolMessageType('DetectedLandmark', (_message.Message,), {
  'DESCRIPTOR' : _DETECTEDLANDMARK,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.DetectedLandmark)
  })
_sym_db.RegisterMessage(DetectedLandmark)

VideoAnnotationResults = _reflection.GeneratedProtocolMessageType('VideoAnnotationResults', (_message.Message,), {
  'DESCRIPTOR' : _VIDEOANNOTATIONRESULTS,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.VideoAnnotationResults)
  })
_sym_db.RegisterMessage(VideoAnnotationResults)

AnnotateVideoResponse = _reflection.GeneratedProtocolMessageType('AnnotateVideoResponse', (_message.Message,), {
  'DESCRIPTOR' : _ANNOTATEVIDEORESPONSE,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.AnnotateVideoResponse)
  })
_sym_db.RegisterMessage(AnnotateVideoResponse)

VideoAnnotationProgress = _reflection.GeneratedProtocolMessageType('VideoAnnotationProgress', (_message.Message,), {
  'DESCRIPTOR' : _VIDEOANNOTATIONPROGRESS,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.VideoAnnotationProgress)
  })
_sym_db.RegisterMessage(VideoAnnotationProgress)

AnnotateVideoProgress = _reflection.GeneratedProtocolMessageType('AnnotateVideoProgress', (_message.Message,), {
  'DESCRIPTOR' : _ANNOTATEVIDEOPROGRESS,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.AnnotateVideoProgress)
  })
_sym_db.RegisterMessage(AnnotateVideoProgress)

SpeechTranscriptionConfig = _reflection.GeneratedProtocolMessageType('SpeechTranscriptionConfig', (_message.Message,), {
  'DESCRIPTOR' : _SPEECHTRANSCRIPTIONCONFIG,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.SpeechTranscriptionConfig)
  })
_sym_db.RegisterMessage(SpeechTranscriptionConfig)

SpeechContext = _reflection.GeneratedProtocolMessageType('SpeechContext', (_message.Message,), {
  'DESCRIPTOR' : _SPEECHCONTEXT,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.SpeechContext)
  })
_sym_db.RegisterMessage(SpeechContext)

SpeechTranscription = _reflection.GeneratedProtocolMessageType('SpeechTranscription', (_message.Message,), {
  'DESCRIPTOR' : _SPEECHTRANSCRIPTION,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.SpeechTranscription)
  })
_sym_db.RegisterMessage(SpeechTranscription)

SpeechRecognitionAlternative = _reflection.GeneratedProtocolMessageType('SpeechRecognitionAlternative', (_message.Message,), {
  'DESCRIPTOR' : _SPEECHRECOGNITIONALTERNATIVE,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.SpeechRecognitionAlternative)
  })
_sym_db.RegisterMessage(SpeechRecognitionAlternative)

WordInfo = _reflection.GeneratedProtocolMessageType('WordInfo', (_message.Message,), {
  'DESCRIPTOR' : _WORDINFO,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.WordInfo)
  })
_sym_db.RegisterMessage(WordInfo)

NormalizedVertex = _reflection.GeneratedProtocolMessageType('NormalizedVertex', (_message.Message,), {
  'DESCRIPTOR' : _NORMALIZEDVERTEX,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.NormalizedVertex)
  })
_sym_db.RegisterMessage(NormalizedVertex)

NormalizedBoundingPoly = _reflection.GeneratedProtocolMessageType('NormalizedBoundingPoly', (_message.Message,), {
  'DESCRIPTOR' : _NORMALIZEDBOUNDINGPOLY,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.NormalizedBoundingPoly)
  })
_sym_db.RegisterMessage(NormalizedBoundingPoly)

TextSegment = _reflection.GeneratedProtocolMessageType('TextSegment', (_message.Message,), {
  'DESCRIPTOR' : _TEXTSEGMENT,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.TextSegment)
  })
_sym_db.RegisterMessage(TextSegment)

TextFrame = _reflection.GeneratedProtocolMessageType('TextFrame', (_message.Message,), {
  'DESCRIPTOR' : _TEXTFRAME,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.TextFrame)
  })
_sym_db.RegisterMessage(TextFrame)

TextAnnotation = _reflection.GeneratedProtocolMessageType('TextAnnotation', (_message.Message,), {
  'DESCRIPTOR' : _TEXTANNOTATION,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.TextAnnotation)
  })
_sym_db.RegisterMessage(TextAnnotation)

ObjectTrackingFrame = _reflection.GeneratedProtocolMessageType('ObjectTrackingFrame', (_message.Message,), {
  'DESCRIPTOR' : _OBJECTTRACKINGFRAME,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.ObjectTrackingFrame)
  })
_sym_db.RegisterMessage(ObjectTrackingFrame)

ObjectTrackingAnnotation = _reflection.GeneratedProtocolMessageType('ObjectTrackingAnnotation', (_message.Message,), {
  'DESCRIPTOR' : _OBJECTTRACKINGANNOTATION,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.ObjectTrackingAnnotation)
  })
_sym_db.RegisterMessage(ObjectTrackingAnnotation)

LogoRecognitionAnnotation = _reflection.GeneratedProtocolMessageType('LogoRecognitionAnnotation', (_message.Message,), {
  'DESCRIPTOR' : _LOGORECOGNITIONANNOTATION,
  '__module__' : 'google.cloud.videointelligence.v1.video_intelligence_pb2'
  # @@protoc_insertion_point(class_scope:google.cloud.videointelligence.v1.LogoRecognitionAnnotation)
  })
_sym_db.RegisterMessage(LogoRecognitionAnnotation)

_VIDEOINTELLIGENCESERVICE = DESCRIPTOR.services_by_name['VideoIntelligenceService']
if _descriptor._USE_C_DESCRIPTORS == False:

  DESCRIPTOR._options = None
  DESCRIPTOR._serialized_options = b'\n%com.google.cloud.videointelligence.v1B\035VideoIntelligenceServiceProtoP\001ZRgoogle.golang.org/genproto/googleapis/cloud/videointelligence/v1;videointelligence\252\002!Google.Cloud.VideoIntelligence.V1\312\002!Google\\Cloud\\VideoIntelligence\\V1\352\002$Google::Cloud::VideoIntelligence::V1'
  _ANNOTATEVIDEOREQUEST.fields_by_name['features']._options = None
  _ANNOTATEVIDEOREQUEST.fields_by_name['features']._serialized_options = b'\342A\001\002'
  _ANNOTATEVIDEOREQUEST.fields_by_name['output_uri']._options = None
  _ANNOTATEVIDEOREQUEST.fields_by_name['output_uri']._serialized_options = b'\342A\001\001'
  _ANNOTATEVIDEOREQUEST.fields_by_name['location_id']._options = None
  _ANNOTATEVIDEOREQUEST.fields_by_name['location_id']._serialized_options = b'\342A\001\001'
  _FACEFRAME._options = None
  _FACEFRAME._serialized_options = b'\030\001'
  _FACEANNOTATION._options = None
  _FACEANNOTATION._serialized_options = b'\030\001'
  _TIMESTAMPEDOBJECT.fields_by_name['attributes']._options = None
  _TIMESTAMPEDOBJECT.fields_by_name['attributes']._serialized_options = b'\342A\001\001'
  _TIMESTAMPEDOBJECT.fields_by_name['landmarks']._options = None
  _TIMESTAMPEDOBJECT.fields_by_name['landmarks']._serialized_options = b'\342A\001\001'
  _TRACK.fields_by_name['attributes']._options = None
  _TRACK.fields_by_name['attributes']._serialized_options = b'\342A\001\001'
  _TRACK.fields_by_name['confidence']._options = None
  _TRACK.fields_by_name['confidence']._serialized_options = b'\342A\001\001'
  _VIDEOANNOTATIONRESULTS.fields_by_name['face_annotations']._options = None
  _VIDEOANNOTATIONRESULTS.fields_by_name['face_annotations']._serialized_options = b'\030\001'
  _SPEECHTRANSCRIPTIONCONFIG.fields_by_name['language_code']._options = None
  _SPEECHTRANSCRIPTIONCONFIG.fields_by_name['language_code']._serialized_options = b'\342A\001\002'
  _SPEECHTRANSCRIPTIONCONFIG.fields_by_name['max_alternatives']._options = None
  _SPEECHTRANSCRIPTIONCONFIG.fields_by_name['max_alternatives']._serialized_options = b'\342A\001\001'
  _SPEECHTRANSCRIPTIONCONFIG.fields_by_name['filter_profanity']._options = None
  _SPEECHTRANSCRIPTIONCONFIG.fields_by_name['filter_profanity']._serialized_options = b'\342A\001\001'
  _SPEECHTRANSCRIPTIONCONFIG.fields_by_name['speech_contexts']._options = None
  _SPEECHTRANSCRIPTIONCONFIG.fields_by_name['speech_contexts']._serialized_options = b'\342A\001\001'
  _SPEECHTRANSCRIPTIONCONFIG.fields_by_name['enable_automatic_punctuation']._options = None
  _SPEECHTRANSCRIPTIONCONFIG.fields_by_name['enable_automatic_punctuation']._serialized_options = b'\342A\001\001'
  _SPEECHTRANSCRIPTIONCONFIG.fields_by_name['audio_tracks']._options = None
  _SPEECHTRANSCRIPTIONCONFIG.fields_by_name['audio_tracks']._serialized_options = b'\342A\001\001'
  _SPEECHTRANSCRIPTIONCONFIG.fields_by_name['enable_speaker_diarization']._options = None
  _SPEECHTRANSCRIPTIONCONFIG.fields_by_name['enable_speaker_diarization']._serialized_options = b'\342A\001\001'
  _SPEECHTRANSCRIPTIONCONFIG.fields_by_name['diarization_speaker_count']._options = None
  _SPEECHTRANSCRIPTIONCONFIG.fields_by_name['diarization_speaker_count']._serialized_options = b'\342A\001\001'
  _SPEECHTRANSCRIPTIONCONFIG.fields_by_name['enable_word_confidence']._options = None
  _SPEECHTRANSCRIPTIONCONFIG.fields_by_name['enable_word_confidence']._serialized_options = b'\342A\001\001'
  _SPEECHCONTEXT.fields_by_name['phrases']._options = None
  _SPEECHCONTEXT.fields_by_name['phrases']._serialized_options = b'\342A\001\001'
  _SPEECHTRANSCRIPTION.fields_by_name['language_code']._options = None
  _SPEECHTRANSCRIPTION.fields_by_name['language_code']._serialized_options = b'\342A\001\003'
  _SPEECHRECOGNITIONALTERNATIVE.fields_by_name['confidence']._options = None
  _SPEECHRECOGNITIONALTERNATIVE.fields_by_name['confidence']._serialized_options = b'\342A\001\003'
  _SPEECHRECOGNITIONALTERNATIVE.fields_by_name['words']._options = None
  _SPEECHRECOGNITIONALTERNATIVE.fields_by_name['words']._serialized_options = b'\342A\001\003'
  _WORDINFO.fields_by_name['confidence']._options = None
  _WORDINFO.fields_by_name['confidence']._serialized_options = b'\342A\001\003'
  _WORDINFO.fields_by_name['speaker_tag']._options = None
  _WORDINFO.fields_by_name['speaker_tag']._serialized_options = b'\342A\001\003'
  _VIDEOINTELLIGENCESERVICE._options = None
  _VIDEOINTELLIGENCESERVICE._serialized_options = b'\312A videointelligence.googleapis.com\322A.https://www.googleapis.com/auth/cloud-platform'
  _VIDEOINTELLIGENCESERVICE.methods_by_name['AnnotateVideo']._options = None
  _VIDEOINTELLIGENCESERVICE.methods_by_name['AnnotateVideo']._serialized_options = b'\312A.\n\025AnnotateVideoResponse\022\025AnnotateVideoProgress\332A\022input_uri,features\202\323\344\223\002\030\"\023/v1/videos:annotate:\001*'
  _FEATURE._serialized_start=10569
  _FEATURE._serialized_end=10814
  _LABELDETECTIONMODE._serialized_start=10816
  _LABELDETECTIONMODE._serialized_end=10930
  _LIKELIHOOD._serialized_start=10932
  _LIKELIHOOD._serialized_end=11048
  _ANNOTATEVIDEOREQUEST._serialized_start=313
  _ANNOTATEVIDEOREQUEST._serialized_end=641
  _VIDEOCONTEXT._serialized_start=644
  _VIDEOCONTEXT._serialized_end=1683
  _LABELDETECTIONCONFIG._serialized_start=1686
  _LABELDETECTIONCONFIG._serialized_end=2004
  _SHOTCHANGEDETECTIONCONFIG._serialized_start=2006
  _SHOTCHANGEDETECTIONCONFIG._serialized_end=2055
  _OBJECTTRACKINGCONFIG._serialized_start=2057
  _OBJECTTRACKINGCONFIG._serialized_end=2101
  _FACEDETECTIONCONFIG._serialized_start=2104
  _FACEDETECTIONCONFIG._serialized_end=2248
  _PERSONDETECTIONCONFIG._serialized_start=2251
  _PERSONDETECTIONCONFIG._serialized_end=2429
  _EXPLICITCONTENTDETECTIONCONFIG._serialized_start=2431
  _EXPLICITCONTENTDETECTIONCONFIG._serialized_end=2485
  _TEXTDETECTIONCONFIG._serialized_start=2487
  _TEXTDETECTIONCONFIG._serialized_end=2569
  _VIDEOSEGMENT._serialized_start=2572
  _VIDEOSEGMENT._serialized_end=2724
  _LABELSEGMENT._serialized_start=2726
  _LABELSEGMENT._serialized_end=2847
  _LABELFRAME._serialized_start=2849
  _LABELFRAME._serialized_end=2953
  _ENTITY._serialized_start=2955
  _ENTITY._serialized_end=3063
  _LABELANNOTATION._serialized_start=3066
  _LABELANNOTATION._serialized_end=3412
  _EXPLICITCONTENTFRAME._serialized_start=3415
  _EXPLICITCONTENTFRAME._serialized_end=3599
  _EXPLICITCONTENTANNOTATION._serialized_start=3602
  _EXPLICITCONTENTANNOTATION._serialized_end=3736
  _NORMALIZEDBOUNDINGBOX._serialized_start=3738
  _NORMALIZEDBOUNDINGBOX._serialized_end=3845
  _FACEDETECTIONANNOTATION._serialized_start=3848
  _FACEDETECTIONANNOTATION._serialized_end=3995
  _PERSONDETECTIONANNOTATION._serialized_start=3997
  _PERSONDETECTIONANNOTATION._serialized_end=4116
  _FACESEGMENT._serialized_start=4118
  _FACESEGMENT._serialized_end=4206
  _FACEFRAME._serialized_start=4209
  _FACEFRAME._serialized_end=4402
  _FACEANNOTATION._serialized_start=4405
  _FACEANNOTATION._serialized_end=4601
  _TIMESTAMPEDOBJECT._serialized_start=4604
  _TIMESTAMPEDOBJECT._serialized_end=4978
  _TRACK._serialized_start=4981
  _TRACK._serialized_end=5296
  _DETECTEDATTRIBUTE._serialized_start=5298
  _DETECTEDATTRIBUTE._serialized_end=5391
  _DETECTEDLANDMARK._serialized_start=5394
  _DETECTEDLANDMARK._serialized_end=5539
  _VIDEOANNOTATIONRESULTS._serialized_start=5542
  _VIDEOANNOTATIONRESULTS._serialized_end=7280
  _ANNOTATEVIDEORESPONSE._serialized_start=7283
  _ANNOTATEVIDEORESPONSE._serialized_end=7412
  _VIDEOANNOTATIONPROGRESS._serialized_start=7415
  _VIDEOANNOTATIONPROGRESS._serialized_end=7777
  _ANNOTATEVIDEOPROGRESS._serialized_start=7780
  _ANNOTATEVIDEOPROGRESS._serialized_end=7912
  _SPEECHTRANSCRIPTIONCONFIG._serialized_start=7915
  _SPEECHTRANSCRIPTIONCONFIG._serialized_end=8487
  _SPEECHCONTEXT._serialized_start=8489
  _SPEECHCONTEXT._serialized_end=8536
  _SPEECHTRANSCRIPTION._serialized_start=8539
  _SPEECHTRANSCRIPTION._serialized_end=8704
  _SPEECHRECOGNITIONALTERNATIVE._serialized_start=8707
  _SPEECHRECOGNITIONALTERNATIVE._serialized_end=8880
  _WORDINFO._serialized_start=8883
  _WORDINFO._serialized_end=9102
  _NORMALIZEDVERTEX._serialized_start=9104
  _NORMALIZEDVERTEX._serialized_end=9150
  _NORMALIZEDBOUNDINGPOLY._serialized_start=9152
  _NORMALIZEDBOUNDINGPOLY._serialized_end=9257
  _TEXTSEGMENT._serialized_start=9260
  _TEXTSEGMENT._serialized_end=9450
  _TEXTFRAME._serialized_start=9453
  _TEXTFRAME._serialized_end=9633
  _TEXTANNOTATION._serialized_start=9636
  _TEXTANNOTATION._serialized_end=9774
  _OBJECTTRACKINGFRAME._serialized_start=9777
  _OBJECTTRACKINGFRAME._serialized_end=9972
  _OBJECTTRACKINGANNOTATION._serialized_start=9975
  _OBJECTTRACKINGANNOTATION._serialized_end=10326
  _LOGORECOGNITIONANNOTATION._serialized_start=10329
  _LOGORECOGNITIONANNOTATION._serialized_end=10566
  _VIDEOINTELLIGENCESERVICE._serialized_start=11051
  _VIDEOINTELLIGENCESERVICE._serialized_end=11371
# @@protoc_insertion_point(module_scope)
